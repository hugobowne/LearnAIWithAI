[
    {
        "id": "147b2b8a-19a9-4b3b-b834-76a056210f26",
        "timestamp": "2025-04-21T14:50:25.093323",
        "question": "what kind of prerequisite knowledge should a software engineer have about AI",
        "response": "Based on the provided sections of the workshop transcript, there is no specific mention of prerequisite knowledge for software engineers regarding AI.",
        "num_chunks": 5,
        "context_tokens": 2338,
        "completion_tokens": 25,
        "embedding_tokens": 7680,
        "total_tokens": 10043,
        "latency": 0.7418529987335205,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"62f331ec-ae85-48f1-9bac-64911382137c\", \"position\": 48, \"relevance\": 1.0, \"tokens\": 442, \"timestamp\": \"01:28:11.060\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:28:11.060]\\nPhilip Kiely: We're gonna talk about what it takes to run influence in production. We're gonna talk about the journey of going from some of the things that you may be learning about and prototyping in this course to how you can maybe apply this stuff either in your day job,\\n\\nor if you start a startup as you scale or if you start a side project\\nPhilip Kiely: and it goes super viral. Actually, one of our biggest customers kind of started that way. Then, yeah, this also becomes, very, very relevant.\\n\\nPhilip Kiely: I had a little sneak peek at the at the lesson plan for today that that Hugo put together,\\n\\nand it sounds like a lot of the last hour hour and a half was about how to build AI products going from objective to data to model development model evaluation\\nPhilip Kiely: and talking about how that sort of workflow has changed. Going from an Ml.\\n\\nWorld to an AI world\\nPhilip Kiely: so base. 10 kind of comes in at the end of that. At the end of that cycle to take the thing that you've built and scale it to the entire world.\\n\\nPhilip Kiely: Sorry I should not have eaten very dry popcorn right before giving a a public talk.\\n\\nPhilip Kiely: So as we think about, you know how AI tools are being consumed in these applications today they're kind of 2 extremes. One extreme is you just outsource everything you go with a closed source shared endpoint like Openai or anthropic. You don't think about the model. You don't think about the infrastructure. You don't think about anything other than how many tokens you'\\n\\nre consuming and how much every single one of those tokens costs\\nPhilip Kiely: on the complete other end of the spectrum. You can do everything yourself. You can get your own Gpus, set up your own model influence servers load your own model weights and wire up your own infrastructure. Do everything yourself. What we're gonna talk about today is kind of a middle path where you get most of the control of the Diy with most of the ease of the, you know, low overhead, close source stuff.\"}, {\"id\": \"1f138528-0d28-47d5-84cd-dccd1192b1a9\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}, {\"id\": \"dfd265bc-b905-43a1-81d5-5c486900a544\", \"position\": 22, \"relevance\": 1.0, \"tokens\": 401, \"timestamp\": \"00:48:18.740\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:48:18.740]\\nAnd\\nhugo bowne-anderson: the answer, the answers come in the in the process that we're here to teach you about in this entire course. And one thing to understand is kind of the flow of the system.\\n\\nSo\\nhugo bowne-anderson: we have our upstream prompt and context being sent to an Llm. Then we have the Llm output, and this being consumed downstream in a variety of ways.\\n\\nhugo bowne-anderson: So what type of principles do we need to really think about then. And another way to frame what we're doing here is, of course, we're using tools the entire time. But we're not tool focused. We're, we're principle focused.\\n\\nAnd\\nhugo bowne-anderson: one of the reasons that'\\n\\ns the case is\\nhugo bowne-anderson: we wanna help you develop skills and adopt tools that we'\\n\\nll be around in\\nhugo bowne-anderson: several years. And I honestly can't guarantee you whether Langchain or Llama Index or crew, AI or any of these things will be around to be honest. But what Stefan and myself and a lot of our community are taking a bet on is that the principles that we learned building machine learning software for years and have started to use building Llm powered software, they will stick around.\\n\\nAnd so\\nhugo bowne-anderson: the 1st principle to recognize is upstream. You have these Api calls you have input and output. And you have knobs. You can tweak there. Right? You have system and user prompts. You have context, right? You have structured outputs, and you have a variety of knobs, such as temperature and top P, which we'll get to later this week.\\n\\nhugo bowne-anderson: Another principle and this is a foundational principle. All of these are is that Llms are non-deterministic.\"}, {\"id\": \"b4751b83-811f-43e0-b1d5-a7288c9a766d\", \"position\": 24, \"relevance\": 1.0, \"tokens\": 482, \"timestamp\": \"00:52:20.970\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:52:20.970]\\nhugo bowne-anderson: and then perhaps you monitor for a while, figure out what's up, make some small changes, whatever it is. And then you start working on the next version, and there will be version releases. Then, right? So you will start working again and iterating.\\n\\nhugo bowne-anderson: based on what you how you see your software is performing. But the point is that you're iterating on the next version of it as opposed to having something continuously changing and continuously iterating.\\n\\nhugo bowne-anderson:\\n\\nSo we have software specs\\nhugo bowne-anderson: for Llm. Powered applications right? And this is an iterative process that spans development and production. You have software specs, you build, you deploy your value, you monitor and evaluate, including all of these things that I really I mentioned at the start of this workshop which we'll get into in this course.\\n\\nhugo bowne-anderson:\\n\\nSo\\nhugo bowne-anderson: the question I said at the start, how do we get out of aic a a Oc AI poc, I actually should change that because someone said someone actually said to me, they didn't know what a proof of concept was, and they thought I was using the term person of color purgatory.\\n\\nAnd I I definitely have never intended that so I probably should should change that\\nhugo bowne-anderson: So the 1st challenge non-determinism. How do we deal with that? We log inputs and outputs. We evaluate logs. We iterate on prompts and context, we use Api knobs to reduce variance.\\n\\nhugo bowne-anderson: How about the challenge of hallucinations?\\n\\nhugo bowne-anderson: Well, similarly, we log inputs and outputs in dev and prod, we use domain specific expertise to evaluate output. In both, we build systems and processes to automate assessments such as unit tests and data sets. So testing sets product feedback hooks. Similarly, for for evaluation.\\n\\nhugo bowne-anderson: for iteration, we build a software development lifecycle that enables you to quickly build, deploy, monitor and evaluate. And in terms of business value. We really need to align outputs with business metric and optimize workflows to achieve measurable return on investment.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"6ffac1dd-ded2-4c0e-8a99-ea61d378584c\", \"position\": 18, \"relevance\": 1.0, \"tokens\": 437, \"timestamp\": \"00:40:43.000\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:40:43.000]\\nhugo bowne-anderson: in Ml, you collect real world examples, label by hand, train model on labor data, evaluate on held outset iterate based on performance. Okay, now, there are lots of challenges with Llms.\\n\\nBut\\nhugo bowne-anderson: at the start you get labeled data. It isn't real world data. But you get labeled data for free. You can build your like data flywheel really, really, quickly. So you synthesize realistic queries from personas. You can do that pre-launch label some outputs by hand.\\n\\nhugo bowne-anderson: you prompt the model tune prompts, and the system set up. Whether you're changing your embeddings or whatever it is you evaluate using your Mve, which is your test set and your automated Eval. Then you iterate, based on performance and use your evaluation to guide improvement.\\n\\nSo\\nhugo bowne-anderson: modulo differences. Both workflows are eerily similar. They're grounded in test sets, iteration and failure analysis. And those are the types of things. It's not sexy, right? But you'll get way more. You'\\n\\nll build far better apps if you get comfortable looking at spreadsheets and doing pivot tables of failure modes and building\\nhugo bowne-anderson: multi agentic systems with crew. AI, we're going to do both in this course right? But to be very clear, those are the skills that we're very interested in teaching. So before we jump into Github.\\n\\nI just want to tell you a basic story\\nhugo bowne-anderson: about how Poc purgatory starts. It starts, for example, with llama indexes what they what they call their famous 5 line, quick start, or whatever right where this is. This is incredible, that I can have some data in a document. I do my import. I set up my data directory. I do it. I created essentially a local vector store, a query engine. I then query, get out my response and print it in.\\n\\nhugo bowne-anderson: you know.\"}]",
        "success": 1,
        "feedback_rating": null,
        "feedback_reason": null,
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information relevant to the question asked, as it does not address the specific topic of the workshop."
    },
    {
        "id": "df6c6a0e-af62-4846-9005-72358d2255b6",
        "timestamp": "2025-04-21T14:46:57.719760",
        "question": "which ML algorithms are used for the workshop",
        "response": "Based on the provided workshop transcript sections, there is no specific mention of which ML algorithms are used in the workshop.",
        "num_chunks": 5,
        "context_tokens": 2379,
        "completion_tokens": 24,
        "embedding_tokens": 7680,
        "total_tokens": 10083,
        "latency": 1.905447244644165,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"6cf7152a-b2b9-4f63-8504-74d8e7ea9be0\", \"position\": 56, \"relevance\": 1.0, \"tokens\": 461, \"timestamp\": \"01:46:58.890\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:46:58.890]\\nI just click the view repository link\\nPhilip Kiely: and I got into the trust examples. So this is, you know, hundreds and hundreds of model implementations that we've made. And this lets me start to get into the tensor. Otllm build configuration. So in this case, you know, I have details around like how many Gpus, I'm using my tensor parallel count. I have different plugins that I can turn it off and on different sequence lengths. I can also,\\n\\nI should have\\nPhilip Kiely: hold this one up ahead of time.\\n\\nPhilip Kiely: yeah. I can also, for example, find one that is using speculative decoding.\\n\\nSo\\nPhilip Kiely: I can, you know. Add a speculator model to this same kind of config.\\n\\nSo I can basically\\nPhilip Kiely: add a and and all all this, by the way, is in the documentation. I can add a smaller model and try and see how much performance lift. I get on. You know, one type of input versus another type, because speculative decoding is, of course, very dependent on the actual input that you're putting in here. So yes. So with with this, you can actually do a lot more to kind of experiment with these different models.\\n\\nPhilip Kiely: and and the different levers that are available to you in dedicated deployments. The other thing I would really encourage you to do is go beyond just language models and think about what you can build from more of a multimodal sense. I know this course is maybe called. I think Llm. Is in the title of this course, but there's a lot of great models outside of Llms.\\n\\nPhilip Kiely: whisper is, of course, a great model to play with for audio transcription. If you want to build rag and agents. We just published a bunch of new text embedding models. Using a new optimized embedding runtime, which is twice as fast as Tei or Vlm or other industry standards. So you can, you know,\\n\\nuse this for something like chroma or pinecone\\nPhilip Kiely: or Mongodb and build, you know, rag and agent type stuff. We have really great speech speech synthesis models. Where is it?\"}, {\"id\": \"8b1fca27-acc4-49a9-9b23-ce5c2b7b8a75\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}, {\"id\": \"6717843f-109b-4206-9798-e8b7d192a20b\", \"position\": 18, \"relevance\": 1.0, \"tokens\": 437, \"timestamp\": \"00:40:43.000\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:40:43.000]\\nhugo bowne-anderson: in Ml, you collect real world examples, label by hand, train model on labor data, evaluate on held outset iterate based on performance. Okay, now, there are lots of challenges with Llms.\\n\\nBut\\nhugo bowne-anderson: at the start you get labeled data. It isn't real world data. But you get labeled data for free. You can build your like data flywheel really, really, quickly. So you synthesize realistic queries from personas. You can do that pre-launch label some outputs by hand.\\n\\nhugo bowne-anderson: you prompt the model tune prompts, and the system set up. Whether you're changing your embeddings or whatever it is you evaluate using your Mve, which is your test set and your automated Eval. Then you iterate, based on performance and use your evaluation to guide improvement.\\n\\nSo\\nhugo bowne-anderson: modulo differences. Both workflows are eerily similar. They're grounded in test sets, iteration and failure analysis. And those are the types of things. It's not sexy, right? But you'll get way more. You'\\n\\nll build far better apps if you get comfortable looking at spreadsheets and doing pivot tables of failure modes and building\\nhugo bowne-anderson: multi agentic systems with crew. AI, we're going to do both in this course right? But to be very clear, those are the skills that we're very interested in teaching. So before we jump into Github.\\n\\nI just want to tell you a basic story\\nhugo bowne-anderson: about how Poc purgatory starts. It starts, for example, with llama indexes what they what they call their famous 5 line, quick start, or whatever right where this is. This is incredible, that I can have some data in a document. I do my import. I set up my data directory. I do it. I created essentially a local vector store, a query engine. I then query, get out my response and print it in.\\n\\nhugo bowne-anderson: you know.\"}, {\"id\": \"bc8575d2-22c2-4cb8-93be-8e5e239911de\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"cb23a5aa-c47d-413d-a221-2f7d599ca502\", \"position\": 17, \"relevance\": 1.0, \"tokens\": 460, \"timestamp\": \"00:38:30.480\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:38:30.480]\\nhugo bowne-anderson: You get the Mvp to give you responses, label them by hand, use the label data to build a basic evaluation harness, for example. And we'll get to all of this a test set and Llm. As a judge. And then we use the Mve to evaluate and improve your Mvp. I do want to. Just briefly, we'll get into this a lot later in the course, disambiguate Llm. As a judge. It's a term that people like. Oh, that must be, you know, really sophisticated.\\n\\nWhatever\\nhugo bowne-anderson: the truth is, they can be, and should be as you go on. But essentially what you're doing is you've got a bunch of traces you want to evaluate in some way. You've done a bunch hand labeling as a human that doesn't scale. So you give an Llm.\\n\\nA prompt\\nhugo bowne-anderson: and a bunch of perhaps positive and negative examples and some heuristics for evaluating, and you get it to perform the evaluation for you, and of course something we'll get to is then how to align. One of the most important things is aligning the Lm. As a judge with your own evaluation. But that's kind of just a brief detour on that. I do want to say.\\n\\nhugo bowne-anderson: Evaluation driven development isn't. New people have been building Ml. Software. Well, I've been doing it for years. If you tell me that the original Google search didn't use evaluation driven development. I'd say what? What the heck you're talking about? Because clearly they were using in like highly sophisticated monitoring and evaluation in in order to rapidly iterate on on that product.\\n\\nSo\\nhugo bowne-anderson: essentially in machine learning, we've had Mvps and collected data. Then we've labeled responses by hand. Then we use the labeled data to build a basic evaluation system. But in this case it's a test set right. And then we use this Mve to evaluate and improve your Mvp. So just to compare Eval and building with Llms versus traditional. Ml.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "question should clarify if there is a specific ML topic the course mentors are talking about",
        "feedback_notes": null,
        "feedback_user": "Ilona",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "17effa4e-b77b-4e94-b3d4-4c1cc4d15b59",
        "timestamp": "2025-04-21T08:37:43.998876",
        "question": "who are the instructors",
        "response": "The instructors mentioned in the workshop transcript sections are Hugo Bowne-Anderson, Stefan Krawczyk, Jeff Pidcock, Nathan Danielson, and William Horton.",
        "num_chunks": 5,
        "context_tokens": 2552,
        "completion_tokens": 36,
        "embedding_tokens": 7680,
        "total_tokens": 10268,
        "latency": 1.5086393356323242,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"07a71ddd-94f7-4d04-8b86-4fb1fb30d833\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"07722d9b-d468-4a38-b98c-095e22cd81c0\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}, {\"id\": \"c92ae3a3-15d2-4b44-8eb5-2f20b77e19df\", \"position\": 0, \"relevance\": 1.0, \"tokens\": 487, \"timestamp\": \"00:00:14.050\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:00:14.050]\\nhugo bowne-anderson: All right. Welcome everyone. Hugo Bowen Anderson, here so excited to be kicking off workshop. One of building Llm. Powered applications for data, scientists, software engineers, and whoever else wants to get on this rocket ship together, love that. I can see a bunch of friendly faces already. We'll get to this.\\n\\nBut\\nhugo bowne-anderson: if you're able to turn your camera on, I, personally would really appreciate it, and I can tell you it makes me a better teacher as well to see a bunch of faces, and to see all the, all the engagement as well, and only if you're able to, of course, and generally microphones off when not speaking as well.\\n\\nhugo bowne-anderson: I'm I'm so excited to have you all here already, seeing what you all are up to in the discord in the forms you filled in really appreciate you filling in the onboarding form as well. We'\\n\\nve got a bunch of really serious builders who seem a lot of fun also so really excited to get to know you all\\nhugo bowne-anderson: as well. So my name is Hugo Band Anderson. I've worked in data, science and machine learning, and what now we call AI for far out 15 years now. So I feel a bit old to to be honest. I've worked in building, in education, in consulting and and devrel. Also a lot of work in devrel for open, open source stuff.\\n\\nhugo bowne-anderson: so like my, I think my, my.\\n\\nhugo bowne-anderson: my background really has been in doing scientific research using the Pi data stack that then turned into software stuff. So that's really where I come from. In the past couple of years I've been building a lot with generative AI and helping a lot of other people to build also.\\n\\nhugo bowne-anderson: But that really brings up my my background is in scientific research, in doing stuff, in notebooks, in doing my best to productionize stuff without throwing it over the wall to software engineers, which is one of the reasons I teamed up with with Stefan, who is my co-instructor and colleague and friend here, so I'll just hand it over to Stefan to say a few words.\"}, {\"id\": \"e42d40d4-716d-44d4-83b0-a829516c3c9b\", \"position\": 14, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:31:23.130\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:31:23.130]\\nbut sometimes we\\nhugo bowne-anderson: really get and get into it. But zoom cut. Cut up that video so so many times that I'm needing to stitch certain things back together. So a little bit about what I call shared commitments. I don't want to get to like consultancy or whatever, but I do. I do just want to make clear you all. Do you? Right? For sure. We we want you here to bring everything that you are. But I do want to say this course does work best when everyone's engaged and present, so, if possible.\\n\\nhugo bowne-anderson: keep your camera on. Helps us teach better when we can see who we're working with. Keep your mic off unless you're speaking.\\n\\nhugo bowne-anderson: Ask questions early and often. We love participation. On top of that.\\n\\nhugo bowne-anderson: It's very rare that questions in a course like this are uncorrelated. What I mean by that is, if you have a question almost guaranteed. Several other people have the same, if not a related question. So you're doing everyone a favor and help each other out on discord as well. You're building with awesome peers.\\n\\nI just do want to give a shout out to\\nhugo bowne-anderson: to Greg Gandenberger, did I pronounce that correctly, Greg, close enough.\\n\\ngreg: You got it? Yep.\\n\\nhugo bowne-anderson: Awesome who's already been helping out and getting people fixed up with with bugs in my end example, which are invisible bugs. In fact, among other things, Greg has already issued 2 pull requests to the repository we'll get to, and that is so cool, so please do as much as time permits, but engage with each other and and help each other out.\\n\\nSo\\nhugo bowne-anderson: really, really fantastic to have you all here.\\n\\nAnd\\nhugo bowne-anderson: wow! This slide still scares me, but it's it's real, it's it's real pain.\\n\\nAnd for some reason my\\nhugo bowne-anderson: screen isn't quite rendering everything it's slightly bigger than it it should be.\\n\\nBut what I want to say is that\\nhugo bowne-anderson: if you think about as you see here.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"d7386ded-e30c-40a6-9368-46f25672064a\", \"position\": 8, \"relevance\": 1.0, \"tokens\": 497, \"timestamp\": \"00:19:54.940\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:19:54.940]\\nSo\\nhugo bowne-anderson: I hinted at this. But what this course isn't, it is not a deep dive into every Llm. Tool or trend. Of course we'll be doing. We'll be doing a bunch on agents actually, in the second half of the course, and rag and embeddings and more. But the focus is on workflows, not tools, I honestly think, and I'm happy to chat about those and message about those to be honest. But you will have enough resources on that. What we're teaching is what we'\\n\\nve really noticed is a huge gap\\nhugo bowne-anderson: in education around this stuff. This is not a plug and play AI recipe book. They don't even exist. If someone tries to tell you that or sell you that I'd love to hear it. What you'll learn is how to iterate, debug and adapt not just follow step by step. Templates. Okay, once again, this is not some, you know. Hyper, scaled, load balance, multi agent, guide. This course is about getting you moving, not solving every scaling challenge,\\n\\nbut really approaching the workflow\\nhugo bowne-anderson: of how to get things in production and then keep iterating on them.\\n\\nhugo bowne-anderson: So I'm gonna put this. This is incredibly important. This is an onboarding form that actually 25 of you have completed already. And I'm so happy with with that number so far. Usually, I try to say I try to give a form of 5 to 10\\u00a0min, but I honestly think if you all take 10 to 15\\u00a0min to complete this form. It will make this workshop and community really, really special. Okay.\\n\\nhugo bowne-anderson: so and so I just saw Jeff's note. That's in discord. That's that is brilliant.\\n\\nhugo bowne-anderson: And so I do think the the more we know about you and your interests, just because there are 5 of us now as as well. Right and geographically distributed, so the more we can we can be of help.\\n\\nhugo bowne-anderson: Jeff. Nathan has shared the course Wiki page, which we'll get to in a second,\\n\\nand part of that is\\nhugo bowne-anderson: the compute credit access form. Now I'\"}]",
        "success": 1,
        "feedback_rating": "FAIL",
        "feedback_reason": "Yeah, it got the instructors correct, but then added the builders in residents who would like to distinguish those two. There are also spelling errors, but that's probably something to figure out... in the transcripts.",
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information relevant to the question asked, as it does not specify what is different about evaluating LLM apps based on the workshop transcript."
    },
    {
        "id": "91f8fc84-23c8-49dd-9c07-a03d8cd331e4",
        "timestamp": "2025-04-16T23:15:30.110888",
        "question": "What's the recipe for fettuccini alfredo?",
        "response": "I'm sorry, but I couldn't find any information about the recipe for fettuccini alfredo in the provided workshop transcript sections.",
        "num_chunks": 5,
        "context_tokens": 2458,
        "completion_tokens": 30,
        "embedding_tokens": 7680,
        "total_tokens": 10168,
        "latency": 1.4786903858184814,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"9485441f-d5f7-4f9a-ae22-e1d79ef78e2e\", \"position\": 39, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"01:14:32.840\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:14:32.840]\\nhugo bowne-anderson: Oh, yeah, oh, this is great.\\n\\nhugo bowne-anderson:\\n\\nAnd I actually mean that because I love when the demo gods\\nhugo bowne-anderson: don't shine on one, but it's it'\\n\\ns helpful for\\nhugo bowne-anderson: everyone, I mean. That's what do they call it? A teachable moment or something.\\n\\nhugo bowne-anderson: so let's do this again.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: what?\\n\\nhugo bowne-anderson: What is happening here? I mean, legit. This is the type of question. People go into rag systems and say, What is what is this right? How are embedding? Is going to deal with that?\\n\\nhugo bowne-anderson: What is happening here?\\n\\nhugo bowne-anderson: The individual has been involved in various. They've been a key figure.\\n\\nhugo bowne-anderson: That's not too bad to a kind of a silly question.\\n\\nhugo bowne-anderson: then, who is this? I'm just. I'm gonna do 2 queries so that we can then just look at them. How how we can, Andrew in. Okay, good. So I'\\n\\nm gonna kill this app\\nhugo bowne-anderson:\\n\\nand what I want to show you is\\nhugo bowne-anderson: because we've logged into a local sqlite database, and that's what I deleted before we'\\n\\nve got our\\nhugo bowne-anderson: database here. Now we can't display it right? But what I want to do to look into it is a really cool tool that Simon Willison has built, which I encourage you all to to check out called data set with a ETTE at the end. And I'm just gonna say,\\n\\ndata set that database and it spins up a server that allows me to\\nhugo bowne-anderson: quickly look at everything that just occurred. So yeah, I'm going to look at interactions. 2 rows in one table.\\n\\nhugo bowne-anderson: Pdf, name uploaded? Pdf, probably need to change that. Then we have the query.\\n\\nhugo bowne-anderson: this query, what is happening here? The response.\"}, {\"id\": \"72bae55f-ffd6-4aec-bf61-4788d37ea026\", \"position\": 38, \"relevance\": 1.0, \"tokens\": 497, \"timestamp\": \"01:12:59.773\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:12:59.773]\\nhugo bowne-anderson: Now that we've closed this app, I don't know what happened there. I've got no visibility into it, and I can't share it with you. So after giving something something a front end, I do very much encourage everyone to add some basic logging to your system, and it once again, in doing an Mvp. This can be incredibly simple, right? And in this python 3 app log.\\n\\nWe do so by\\nhugo bowne-anderson: just creating a local sqlite database. You can even do it just to Json, if you want, I decided to go a bit more. I'm a huge fan of sqlite to be honest. But where? So that means in 82 lines of code, we've got our.\\n\\nhugo bowne-anderson: you know, rag system. We'\\n\\nve got our front end\\nhugo bowne-anderson: and we have some logging, basic logging as well. So let's now just have a look at how that works, and then I'll show you ways to think about the logging, or how how to introspect into it.\\n\\nhugo bowne-anderson: So the other thing I didn't mention before is that if you use share is equal to true in launch for gradio, you can create a public link. So when William actually created a gradio app for us to play around with. Recently, that was hosted on modal when preparing some of this course. He just shared. He put share is equal to true, and that meant I could access from Australia. The app he'd just built, which I do. I don'\\n\\nt want to like\\nhugo bowne-anderson: get too too serious. But I the fact that William in DC. Can spin this up, and I can access it. And immediately in Sydney, Australia is absolutely absolutely wild. So I'm gonna ask.\\n\\nhugo bowne-anderson: who is this person?\\n\\nAnd what do they\\nhugo bowne-anderson: do? Our pasta has a great question. What? What model am I using? And I'm actually using Openai. Gpt. 4. 0, I think it's actually once again, though, whatever the default in llama index is, I don't know. Like, maybe that changed then, right? And I don't know.\"}, {\"id\": \"bca5fe46-dab8-4a37-b0de-87145d661c1f\", \"position\": 22, \"relevance\": 1.0, \"tokens\": 401, \"timestamp\": \"00:48:18.740\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:48:18.740]\\nAnd\\nhugo bowne-anderson: the answer, the answers come in the in the process that we're here to teach you about in this entire course. And one thing to understand is kind of the flow of the system.\\n\\nSo\\nhugo bowne-anderson: we have our upstream prompt and context being sent to an Llm. Then we have the Llm output, and this being consumed downstream in a variety of ways.\\n\\nhugo bowne-anderson: So what type of principles do we need to really think about then. And another way to frame what we're doing here is, of course, we're using tools the entire time. But we're not tool focused. We're, we're principle focused.\\n\\nAnd\\nhugo bowne-anderson: one of the reasons that'\\n\\ns the case is\\nhugo bowne-anderson: we wanna help you develop skills and adopt tools that we'\\n\\nll be around in\\nhugo bowne-anderson: several years. And I honestly can't guarantee you whether Langchain or Llama Index or crew, AI or any of these things will be around to be honest. But what Stefan and myself and a lot of our community are taking a bet on is that the principles that we learned building machine learning software for years and have started to use building Llm powered software, they will stick around.\\n\\nAnd so\\nhugo bowne-anderson: the 1st principle to recognize is upstream. You have these Api calls you have input and output. And you have knobs. You can tweak there. Right? You have system and user prompts. You have context, right? You have structured outputs, and you have a variety of knobs, such as temperature and top P, which we'll get to later this week.\\n\\nhugo bowne-anderson: Another principle and this is a foundational principle. All of these are is that Llms are non-deterministic.\"}, {\"id\": \"7790f083-4acf-4371-ae14-34a4c785f663\", \"position\": 25, \"relevance\": 1.0, \"tokens\": 432, \"timestamp\": \"00:54:14.400\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:54:14.400]\\nSo\\nhugo bowne-anderson: without further ado, I would love to jump into Github. I would I have spoken for a while, so I would love if there's been any, any comments in discord that could be relevant. Jeff, William, Nathan Stefan, or anything else anyone would like to add, I really I welcome it.\\n\\nStefan Krawczyk: Nothing needs to be, I guess, raised in terms of, I guess, just to reiterate what Hugo has been saying so or at least one of the themes you come to understand this course is really, you gotta look at your data right? And so and so this will be one of the key things that hopefully we'll we'll drill into you as the course goes. But.\\n\\nhugo bowne-anderson: Yeah. But Jeff.\\n\\nStefan Krawczyk: William, or Nathan, or anything.\\n\\nhugo bowne-anderson: I just did want to add, though you do want to look at your data. But something I've learned from you, Stefan, is how much once you've done that, how you can start automating pieces of that right? And so speaking to your workshop next week, but doing the scientific approach, then robustifying it, so to speak.\\n\\nhugo bowne-anderson: But yeah, Hugo.\\n\\nNathan Danielsen: So 1 1 quick question you that was raised in discord. What did you mean by fine tuning isn't really useful use these days? William gave a good initial answer. But what's your can you? And upon that, just a little bit more.\\n\\nhugo bowne-anderson: So did I say? Fine tuning isn't really useful these days, cause if I I would, that sounds like something I I would say.\\n\\nWhat I mean is that most of the time\\nhugo bowne-anderson: you need? You think you need to fine tune. You can do other things such as prompt your way out of it.\\n\\nhugo bowne-anderson: There are cases, for example.\"}, {\"id\": \"a25925cb-94e5-4fb5-ac21-350caf0f92d0\", \"position\": 41, \"relevance\": 1.0, \"tokens\": 474, \"timestamp\": \"01:17:53.730\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:17:53.730]\\nSo\\nhugo bowne-anderson: what we've just built. Okay.\\n\\nhugo bowne-anderson: we've built a user interacts with a front end. Ui, okay? And then there'\\n\\ns some form of context\\nhugo bowne-anderson: enrichment. And perhaps that arrow should be going here. Now, I'm really thinking about it. But anyway, we've got llama index doing the context enrichment. Well, no, we are feeding everything to Llama Index ourselves, I suppose. And then it's interacting with an element Api, to give us a result. Then we're logging locally to sqlite. And then we'\\n\\nre looking at our data in data set\\nhugo bowne-anderson: we can also do it in excel. We can do it in Csv. Or wherever we want, or we can spin up. Our own custom bespoke Json viewer now, as I said, and I'\\n\\nll put this\\nhugo bowne-anderson: in notion.\\n\\nAnd in the discord channel\\nhugo bowne-anderson: Homework isn't mandatory. Nothing's mandatory. Here we're here to, you know, help you learn and build as much as much as you want. I would encourage anyone who's serious about this stuff, though, to do something along the lines following, and maybe several of you are way ahead of this. So if that's the case, no worries at all.\\n\\nBut I would encourage you\\nhugo bowne-anderson: to rip out llama index from this process. Okay, because it's doing too much abstraction, too much heavy lifting. So rip it out and then take the data, the Pdf. Or whatever it is, and put it, send it straight to an Llm. With a prompt of your own choosing. Okay, you may even want to look up llama indexes documentation and see what prompt it'\\n\\ns sending\\nhugo bowne-anderson: to the user. I think last time I tried to look it up.\\n\\nhugo bowne-anderson: I just couldn't find it. I think Stefan found it at some point, though maybe you want to use Hamel's tool to intercept the prompt, and I don't know but I would encourage you, because, in fact.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "Did not hallucinate. Said it didn't know",
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "59c1f620-d7d1-4563-8bc4-00e4744f35e6",
        "timestamp": "2025-04-16T23:13:27.073900",
        "question": "Please explain the main steps to build an LLM-as-a-judge tool for automating evaluation?",
        "response": "The main steps to build an LLM-as-a-judge tool for automating evaluation are as follows:\n\n1. Build a minimum viable product (MVP) with synthetic user queries.\n2. Get the MVP to generate responses.\n3. Label the responses by hand.\n4. Use the labeled data to build a basic evaluation harness, which is a script used to evaluate the system.\n5. Use the MVP and the evaluation harness to evaluate and improve the MVP.\n6. Align the LLM-as-a-judge with your own evaluation.\n7. Continuously iterate and improve the system based on the evaluation results.\n\nPlease note that this is a brief overview, and more details and techniques will be covered in the course.",
        "num_chunks": 5,
        "context_tokens": 2402,
        "completion_tokens": 145,
        "embedding_tokens": 7680,
        "total_tokens": 10227,
        "latency": 2.388603925704956,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"62826e9d-feab-4a10-ba30-cd25ee9034b8\", \"position\": 17, \"relevance\": 1.0, \"tokens\": 460, \"timestamp\": \"00:38:30.480\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:38:30.480]\\nhugo bowne-anderson: You get the Mvp to give you responses, label them by hand, use the label data to build a basic evaluation harness, for example. And we'll get to all of this a test set and Llm. As a judge. And then we use the Mve to evaluate and improve your Mvp. I do want to. Just briefly, we'll get into this a lot later in the course, disambiguate Llm. As a judge. It's a term that people like. Oh, that must be, you know, really sophisticated.\\n\\nWhatever\\nhugo bowne-anderson: the truth is, they can be, and should be as you go on. But essentially what you're doing is you've got a bunch of traces you want to evaluate in some way. You've done a bunch hand labeling as a human that doesn't scale. So you give an Llm.\\n\\nA prompt\\nhugo bowne-anderson: and a bunch of perhaps positive and negative examples and some heuristics for evaluating, and you get it to perform the evaluation for you, and of course something we'll get to is then how to align. One of the most important things is aligning the Lm. As a judge with your own evaluation. But that's kind of just a brief detour on that. I do want to say.\\n\\nhugo bowne-anderson: Evaluation driven development isn't. New people have been building Ml. Software. Well, I've been doing it for years. If you tell me that the original Google search didn't use evaluation driven development. I'd say what? What the heck you're talking about? Because clearly they were using in like highly sophisticated monitoring and evaluation in in order to rapidly iterate on on that product.\\n\\nSo\\nhugo bowne-anderson: essentially in machine learning, we've had Mvps and collected data. Then we've labeled responses by hand. Then we use the labeled data to build a basic evaluation system. But in this case it's a test set right. And then we use this Mve to evaluate and improve your Mvp. So just to compare Eval and building with Llms versus traditional. Ml.\"}, {\"id\": \"5b61cef0-3e5e-442a-961e-5b47a62b8261\", \"position\": 21, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:46:30.010\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:46:30.010]\\nI do want to just take a quick\\nhugo bowne-anderson: detour when we're talking about.\\n\\nhugo bowne-anderson:\\n\\nYou know\\nhugo bowne-anderson: what we get use out of all of these things, for the conversational aspect of Llms is fantastic. I use it all the time. But in my humble estimation most roi will involve automation, not conversations. So, for example, an app that consumes Linkedin profiles finds relevant candidates for a position automates emails to them. That's 1 example that the demo I just showed you perhaps could could be used for.\\n\\nAnd this brings me to my point of and our point of\\nhugo bowne-anderson: really thinking about what we want to evaluate. Okay, so what's cool, you can ask, is the information extracts from Linkedin? Correct? That's a cool question to ask and important, that needs to be satisfied. But remember, we're trying to scale human behavior so, and we want it to result in the same outcomes. But better right? So the next question you might ask, do the emails generated resemble the emails domain experts sent previously.\\n\\nhugo bowne-anderson: also a good question to ask, and who would have thought trying to get a domain expert involved would be so so useful.\\n\\nBut it turns out it is now\\nhugo bowne-anderson: at a very macro level,\\n\\nthough\\nhugo bowne-anderson: you really want to know? Do the emails result in hiring good candidates? And is it more efficient and more cost effective than our previous system right? And it's actually not even clear how long these cycles are.\\n\\nSo making sure that we in the end tie these macro level\\nhugo bowne-anderson: business evaluations to the micro level Llm calls is super important.\\n\\nhugo bowne-anderson: So that brings us back to this. How do we? How do we evaluate a system like this? I don't know what the actual prompt sent to the Llm. Was. How do I give feedback on on system performance? How can I see data and traces and conversations? How can we iterate quickly on this? Mvp.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"3070bdfe-25b6-41d9-8230-d7d015f839aa\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"7110d747-2ab3-495d-9c4f-92793c8c6ea7\", \"position\": 16, \"relevance\": 1.0, \"tokens\": 402, \"timestamp\": \"00:36:47.170\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:36:47.170]\\nhugo bowne-anderson: not because the system is bad and at all right. So that's what we're here to really talk about. I do want to frame most things in terms of evaluation, driven development, although we'll we'll dovetail out of a lot of different different topics. Okay.\\n\\nhugo bowne-anderson:\\n\\nso\\nhugo bowne-anderson: our way out is Edd, evaluation, driven development. Where you have a iterative loop right where you build, you monitor, you evaluate, you improve now.\\n\\nhugo bowne-anderson: even before launching a product. And this is something we'll talk about as the course goes on. You can, you can build a synthetic data set and evaluation harnesses to help you even before real users exist. And if you don't know what an evaluation harness is, don't worry about it. It's essentially a script, something reproducible that you use to evaluate your system. So one example I like to give is.\\n\\nhugo bowne-anderson: I was working on something recently where we were using Gpt. 4.0 Mini, and then Google released Gemini 2.5. And we wanted to play around with it. And it was like, Okay, I'm going to switch this out. But how do I even know beyond vibes that it'\\n\\ns going to be\\nhugo bowne-anderson: good or not? So if you have a basic harness with a few tests, measuring latency and cost and things of business interest as well. This can get you a long way. So at the start, I actually encourage people to build what I call an Mve. So for any Mvp minimum viable product, you have an Mve a minimum viable evaluation as well. Right?\\n\\nhugo bowne-anderson: So just thinking through kind of how this happens. You have an Mvp, you have synthetic user queries.\"}, {\"id\": \"7a9e0a07-e971-4875-ad48-e08f094383f4\", \"position\": 56, \"relevance\": 1.0, \"tokens\": 461, \"timestamp\": \"01:46:58.890\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:46:58.890]\\nI just click the view repository link\\nPhilip Kiely: and I got into the trust examples. So this is, you know, hundreds and hundreds of model implementations that we've made. And this lets me start to get into the tensor. Otllm build configuration. So in this case, you know, I have details around like how many Gpus, I'm using my tensor parallel count. I have different plugins that I can turn it off and on different sequence lengths. I can also,\\n\\nI should have\\nPhilip Kiely: hold this one up ahead of time.\\n\\nPhilip Kiely: yeah. I can also, for example, find one that is using speculative decoding.\\n\\nSo\\nPhilip Kiely: I can, you know. Add a speculator model to this same kind of config.\\n\\nSo I can basically\\nPhilip Kiely: add a and and all all this, by the way, is in the documentation. I can add a smaller model and try and see how much performance lift. I get on. You know, one type of input versus another type, because speculative decoding is, of course, very dependent on the actual input that you're putting in here. So yes. So with with this, you can actually do a lot more to kind of experiment with these different models.\\n\\nPhilip Kiely: and and the different levers that are available to you in dedicated deployments. The other thing I would really encourage you to do is go beyond just language models and think about what you can build from more of a multimodal sense. I know this course is maybe called. I think Llm. Is in the title of this course, but there's a lot of great models outside of Llms.\\n\\nPhilip Kiely: whisper is, of course, a great model to play with for audio transcription. If you want to build rag and agents. We just published a bunch of new text embedding models. Using a new optimized embedding runtime, which is twice as fast as Tei or Vlm or other industry standards. So you can, you know,\\n\\nuse this for something like chroma or pinecone\\nPhilip Kiely: or Mongodb and build, you know, rag and agent type stuff. We have really great speech speech synthesis models. Where is it?\"}]",
        "success": 1,
        "feedback_rating": null,
        "feedback_reason": null,
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "af9ea09c-99d5-4f57-9d27-222623dccb08",
        "timestamp": "2025-04-14T23:46:41.368738",
        "question": "How long is the course?",
        "response": "The length of the course is not mentioned in the provided sections of the workshop transcript.",
        "num_chunks": 5,
        "context_tokens": 2318,
        "completion_tokens": 18,
        "embedding_tokens": 7680,
        "total_tokens": 10016,
        "latency": 0.7254869937896729,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"b32284a9-e388-4e62-ab5a-577bb7f5fa0a\", \"position\": 8, \"relevance\": 1.0, \"tokens\": 497, \"timestamp\": \"00:19:54.940\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:19:54.940]\\nSo\\nhugo bowne-anderson: I hinted at this. But what this course isn't, it is not a deep dive into every Llm. Tool or trend. Of course we'll be doing. We'll be doing a bunch on agents actually, in the second half of the course, and rag and embeddings and more. But the focus is on workflows, not tools, I honestly think, and I'm happy to chat about those and message about those to be honest. But you will have enough resources on that. What we're teaching is what we'\\n\\nve really noticed is a huge gap\\nhugo bowne-anderson: in education around this stuff. This is not a plug and play AI recipe book. They don't even exist. If someone tries to tell you that or sell you that I'd love to hear it. What you'll learn is how to iterate, debug and adapt not just follow step by step. Templates. Okay, once again, this is not some, you know. Hyper, scaled, load balance, multi agent, guide. This course is about getting you moving, not solving every scaling challenge,\\n\\nbut really approaching the workflow\\nhugo bowne-anderson: of how to get things in production and then keep iterating on them.\\n\\nhugo bowne-anderson: So I'm gonna put this. This is incredibly important. This is an onboarding form that actually 25 of you have completed already. And I'm so happy with with that number so far. Usually, I try to say I try to give a form of 5 to 10\\u00a0min, but I honestly think if you all take 10 to 15\\u00a0min to complete this form. It will make this workshop and community really, really special. Okay.\\n\\nhugo bowne-anderson: so and so I just saw Jeff's note. That's in discord. That's that is brilliant.\\n\\nhugo bowne-anderson: And so I do think the the more we know about you and your interests, just because there are 5 of us now as as well. Right and geographically distributed, so the more we can we can be of help.\\n\\nhugo bowne-anderson: Jeff. Nathan has shared the course Wiki page, which we'll get to in a second,\\n\\nand part of that is\\nhugo bowne-anderson: the compute credit access form. Now I'\"}, {\"id\": \"ef779e8c-b2d9-4856-970f-8c60c38c5666\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}, {\"id\": \"88e456b3-4e17-44ab-8486-17a6534857d4\", \"position\": 62, \"relevance\": 1.0, \"tokens\": 302, \"timestamp\": \"01:59:06.670\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:59:06.670]\\nPhilip Kiely: Thank you so much for having me. Thanks everyone for your time today.\\n\\nhugo bowne-anderson: Such a pleasure. Thanks, Philip.\\n\\nhugo bowne-anderson: and everyone else. It's it's time to time to wrap up. I just want to give Philip one more round of applause.\\n\\nGreat\\nhugo bowne-anderson: It is time to wrap up. We do have 2. As as I mentioned before, we have an just an onboarding form. A lot of you have completed it, but if you're if you haven't, and able to, this will allow us, it'll let us know where you are. What you're interested in, and it will allow us to set up the office hours that that we're going to with our wonderful builders in residence as well.\\n\\nOnce again I will share with you\\nhugo bowne-anderson: the feedback form. A bunch of you have already provided a lot of valuable feedback in there, which we'll use to iterate quickly on how we, how we teach and how we approach this course. I'm going to share that in the discord chat also.\\n\\nhugo bowne-anderson: So it's there. But that's it for today, and we'll see you on discord, and we'll see you in 46\\u00a0h for the next workshop as well. So thanks everyone, and thanks for a great 1st session.\"}, {\"id\": \"7cf7c651-a920-42c5-8d8d-d948cf6b3a7a\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"a295cef7-fac1-4c40-a509-784338996dd1\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}]",
        "success": 1,
        "feedback_rating": null,
        "feedback_reason": null,
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "975168aa-c28a-4cc0-b324-b79fd06883fa",
        "timestamp": "2025-04-14T23:42:53.027791",
        "question": "What's Different about Evaluating LLM Apps?",
        "response": "The workshop transcript mentions that evaluating LLM (Language Model) apps is different from traditional software development because LLM-powered software brings in a lot of data from the real world and its behavior is non-deterministic. Therefore, the evaluation process for LLM apps involves building quickly, deploying, monitoring, evaluating, and iterating rapidly. The evaluation-driven development (EDD) approach is emphasized, where the iterative loop of building, monitoring, evaluating, and improving is followed. The transcript also mentions the importance of thinking about unit tests, versioning, continuous integration, tracing, and observability when evaluating LLM apps.",
        "num_chunks": 5,
        "context_tokens": 2332,
        "completion_tokens": 124,
        "embedding_tokens": 7680,
        "total_tokens": 10136,
        "latency": 2.5053489208221436,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"eff86101-401c-49c4-84cf-499aba5b9a4f\", \"position\": 17, \"relevance\": 1.0, \"tokens\": 460, \"timestamp\": \"00:38:30.480\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:38:30.480]\\nhugo bowne-anderson: You get the Mvp to give you responses, label them by hand, use the label data to build a basic evaluation harness, for example. And we'll get to all of this a test set and Llm. As a judge. And then we use the Mve to evaluate and improve your Mvp. I do want to. Just briefly, we'll get into this a lot later in the course, disambiguate Llm. As a judge. It's a term that people like. Oh, that must be, you know, really sophisticated.\\n\\nWhatever\\nhugo bowne-anderson: the truth is, they can be, and should be as you go on. But essentially what you're doing is you've got a bunch of traces you want to evaluate in some way. You've done a bunch hand labeling as a human that doesn't scale. So you give an Llm.\\n\\nA prompt\\nhugo bowne-anderson: and a bunch of perhaps positive and negative examples and some heuristics for evaluating, and you get it to perform the evaluation for you, and of course something we'll get to is then how to align. One of the most important things is aligning the Lm. As a judge with your own evaluation. But that's kind of just a brief detour on that. I do want to say.\\n\\nhugo bowne-anderson: Evaluation driven development isn't. New people have been building Ml. Software. Well, I've been doing it for years. If you tell me that the original Google search didn't use evaluation driven development. I'd say what? What the heck you're talking about? Because clearly they were using in like highly sophisticated monitoring and evaluation in in order to rapidly iterate on on that product.\\n\\nSo\\nhugo bowne-anderson: essentially in machine learning, we've had Mvps and collected data. Then we've labeled responses by hand. Then we use the labeled data to build a basic evaluation system. But in this case it's a test set right. And then we use this Mve to evaluate and improve your Mvp. So just to compare Eval and building with Llms versus traditional. Ml.\"}, {\"id\": \"454b873b-bbf8-4ef2-8ee1-9da8a777bf29\", \"position\": 21, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:46:30.010\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:46:30.010]\\nI do want to just take a quick\\nhugo bowne-anderson: detour when we're talking about.\\n\\nhugo bowne-anderson:\\n\\nYou know\\nhugo bowne-anderson: what we get use out of all of these things, for the conversational aspect of Llms is fantastic. I use it all the time. But in my humble estimation most roi will involve automation, not conversations. So, for example, an app that consumes Linkedin profiles finds relevant candidates for a position automates emails to them. That's 1 example that the demo I just showed you perhaps could could be used for.\\n\\nAnd this brings me to my point of and our point of\\nhugo bowne-anderson: really thinking about what we want to evaluate. Okay, so what's cool, you can ask, is the information extracts from Linkedin? Correct? That's a cool question to ask and important, that needs to be satisfied. But remember, we're trying to scale human behavior so, and we want it to result in the same outcomes. But better right? So the next question you might ask, do the emails generated resemble the emails domain experts sent previously.\\n\\nhugo bowne-anderson: also a good question to ask, and who would have thought trying to get a domain expert involved would be so so useful.\\n\\nBut it turns out it is now\\nhugo bowne-anderson: at a very macro level,\\n\\nthough\\nhugo bowne-anderson: you really want to know? Do the emails result in hiring good candidates? And is it more efficient and more cost effective than our previous system right? And it's actually not even clear how long these cycles are.\\n\\nSo making sure that we in the end tie these macro level\\nhugo bowne-anderson: business evaluations to the micro level Llm calls is super important.\\n\\nhugo bowne-anderson: So that brings us back to this. How do we? How do we evaluate a system like this? I don't know what the actual prompt sent to the Llm. Was. How do I give feedback on on system performance? How can I see data and traces and conversations? How can we iterate quickly on this? Mvp.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"4afe9b98-71d2-408e-a843-72cf99bbb1f9\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"75be418d-32f3-44d3-89cb-110b60668121\", \"position\": 22, \"relevance\": 1.0, \"tokens\": 401, \"timestamp\": \"00:48:18.740\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:48:18.740]\\nAnd\\nhugo bowne-anderson: the answer, the answers come in the in the process that we're here to teach you about in this entire course. And one thing to understand is kind of the flow of the system.\\n\\nSo\\nhugo bowne-anderson: we have our upstream prompt and context being sent to an Llm. Then we have the Llm output, and this being consumed downstream in a variety of ways.\\n\\nhugo bowne-anderson: So what type of principles do we need to really think about then. And another way to frame what we're doing here is, of course, we're using tools the entire time. But we're not tool focused. We're, we're principle focused.\\n\\nAnd\\nhugo bowne-anderson: one of the reasons that'\\n\\ns the case is\\nhugo bowne-anderson: we wanna help you develop skills and adopt tools that we'\\n\\nll be around in\\nhugo bowne-anderson: several years. And I honestly can't guarantee you whether Langchain or Llama Index or crew, AI or any of these things will be around to be honest. But what Stefan and myself and a lot of our community are taking a bet on is that the principles that we learned building machine learning software for years and have started to use building Llm powered software, they will stick around.\\n\\nAnd so\\nhugo bowne-anderson: the 1st principle to recognize is upstream. You have these Api calls you have input and output. And you have knobs. You can tweak there. Right? You have system and user prompts. You have context, right? You have structured outputs, and you have a variety of knobs, such as temperature and top P, which we'll get to later this week.\\n\\nhugo bowne-anderson: Another principle and this is a foundational principle. All of these are is that Llms are non-deterministic.\"}, {\"id\": \"b26fe73f-2853-48f3-85a7-9dd432743d9a\", \"position\": 16, \"relevance\": 1.0, \"tokens\": 402, \"timestamp\": \"00:36:47.170\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:36:47.170]\\nhugo bowne-anderson: not because the system is bad and at all right. So that's what we're here to really talk about. I do want to frame most things in terms of evaluation, driven development, although we'll we'll dovetail out of a lot of different different topics. Okay.\\n\\nhugo bowne-anderson:\\n\\nso\\nhugo bowne-anderson: our way out is Edd, evaluation, driven development. Where you have a iterative loop right where you build, you monitor, you evaluate, you improve now.\\n\\nhugo bowne-anderson: even before launching a product. And this is something we'll talk about as the course goes on. You can, you can build a synthetic data set and evaluation harnesses to help you even before real users exist. And if you don't know what an evaluation harness is, don't worry about it. It's essentially a script, something reproducible that you use to evaluate your system. So one example I like to give is.\\n\\nhugo bowne-anderson: I was working on something recently where we were using Gpt. 4.0 Mini, and then Google released Gemini 2.5. And we wanted to play around with it. And it was like, Okay, I'm going to switch this out. But how do I even know beyond vibes that it'\\n\\ns going to be\\nhugo bowne-anderson: good or not? So if you have a basic harness with a few tests, measuring latency and cost and things of business interest as well. This can get you a long way. So at the start, I actually encourage people to build what I call an Mve. So for any Mvp minimum viable product, you have an Mve a minimum viable evaluation as well. Right?\\n\\nhugo bowne-anderson: So just thinking through kind of how this happens. You have an Mvp, you have synthetic user queries.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "Pretty good job summarizing evaluation techniques",
        "feedback_notes": null,
        "feedback_user": "Lee",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information or context related to the question asked, making it unhelpful and irrelevant."
    },
    {
        "id": "c3526f33-b4f9-4a84-956d-bc695e40b287",
        "timestamp": "2025-04-14T23:42:16.067966",
        "question": "Tell me more about evaluating LLM Apps",
        "response": "Evaluating LLM apps involves a process of building, deploying, monitoring, and iterating rapidly. The workshop emphasizes the importance of evaluation-driven development in the context of LLM-powered software. It is necessary to monitor not only the performance of individual LLM calls but also how they relate to the business metrics that need to be met. The workshop also mentions the use of labeled data to build a basic evaluation system and the role of LLM as a judge in evaluating traces. The goal is to align the macro-level business evaluations with the micro-level LLM calls. The workshop foreshadows a session on prompt engineering and versioning, which will further explore evaluation in the LLM software development lifecycle.",
        "num_chunks": 5,
        "context_tokens": 2387,
        "completion_tokens": 141,
        "embedding_tokens": 7680,
        "total_tokens": 10208,
        "latency": 5.267953157424927,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"eff86101-401c-49c4-84cf-499aba5b9a4f\", \"position\": 17, \"relevance\": 1.0, \"tokens\": 460, \"timestamp\": \"00:38:30.480\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:38:30.480]\\nhugo bowne-anderson: You get the Mvp to give you responses, label them by hand, use the label data to build a basic evaluation harness, for example. And we'll get to all of this a test set and Llm. As a judge. And then we use the Mve to evaluate and improve your Mvp. I do want to. Just briefly, we'll get into this a lot later in the course, disambiguate Llm. As a judge. It's a term that people like. Oh, that must be, you know, really sophisticated.\\n\\nWhatever\\nhugo bowne-anderson: the truth is, they can be, and should be as you go on. But essentially what you're doing is you've got a bunch of traces you want to evaluate in some way. You've done a bunch hand labeling as a human that doesn't scale. So you give an Llm.\\n\\nA prompt\\nhugo bowne-anderson: and a bunch of perhaps positive and negative examples and some heuristics for evaluating, and you get it to perform the evaluation for you, and of course something we'll get to is then how to align. One of the most important things is aligning the Lm. As a judge with your own evaluation. But that's kind of just a brief detour on that. I do want to say.\\n\\nhugo bowne-anderson: Evaluation driven development isn't. New people have been building Ml. Software. Well, I've been doing it for years. If you tell me that the original Google search didn't use evaluation driven development. I'd say what? What the heck you're talking about? Because clearly they were using in like highly sophisticated monitoring and evaluation in in order to rapidly iterate on on that product.\\n\\nSo\\nhugo bowne-anderson: essentially in machine learning, we've had Mvps and collected data. Then we've labeled responses by hand. Then we use the labeled data to build a basic evaluation system. But in this case it's a test set right. And then we use this Mve to evaluate and improve your Mvp. So just to compare Eval and building with Llms versus traditional. Ml.\"}, {\"id\": \"454b873b-bbf8-4ef2-8ee1-9da8a777bf29\", \"position\": 21, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:46:30.010\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:46:30.010]\\nI do want to just take a quick\\nhugo bowne-anderson: detour when we're talking about.\\n\\nhugo bowne-anderson:\\n\\nYou know\\nhugo bowne-anderson: what we get use out of all of these things, for the conversational aspect of Llms is fantastic. I use it all the time. But in my humble estimation most roi will involve automation, not conversations. So, for example, an app that consumes Linkedin profiles finds relevant candidates for a position automates emails to them. That's 1 example that the demo I just showed you perhaps could could be used for.\\n\\nAnd this brings me to my point of and our point of\\nhugo bowne-anderson: really thinking about what we want to evaluate. Okay, so what's cool, you can ask, is the information extracts from Linkedin? Correct? That's a cool question to ask and important, that needs to be satisfied. But remember, we're trying to scale human behavior so, and we want it to result in the same outcomes. But better right? So the next question you might ask, do the emails generated resemble the emails domain experts sent previously.\\n\\nhugo bowne-anderson: also a good question to ask, and who would have thought trying to get a domain expert involved would be so so useful.\\n\\nBut it turns out it is now\\nhugo bowne-anderson: at a very macro level,\\n\\nthough\\nhugo bowne-anderson: you really want to know? Do the emails result in hiring good candidates? And is it more efficient and more cost effective than our previous system right? And it's actually not even clear how long these cycles are.\\n\\nSo making sure that we in the end tie these macro level\\nhugo bowne-anderson: business evaluations to the micro level Llm calls is super important.\\n\\nhugo bowne-anderson: So that brings us back to this. How do we? How do we evaluate a system like this? I don't know what the actual prompt sent to the Llm. Was. How do I give feedback on on system performance? How can I see data and traces and conversations? How can we iterate quickly on this? Mvp.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"4afe9b98-71d2-408e-a843-72cf99bbb1f9\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"75be418d-32f3-44d3-89cb-110b60668121\", \"position\": 22, \"relevance\": 1.0, \"tokens\": 401, \"timestamp\": \"00:48:18.740\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:48:18.740]\\nAnd\\nhugo bowne-anderson: the answer, the answers come in the in the process that we're here to teach you about in this entire course. And one thing to understand is kind of the flow of the system.\\n\\nSo\\nhugo bowne-anderson: we have our upstream prompt and context being sent to an Llm. Then we have the Llm output, and this being consumed downstream in a variety of ways.\\n\\nhugo bowne-anderson: So what type of principles do we need to really think about then. And another way to frame what we're doing here is, of course, we're using tools the entire time. But we're not tool focused. We're, we're principle focused.\\n\\nAnd\\nhugo bowne-anderson: one of the reasons that'\\n\\ns the case is\\nhugo bowne-anderson: we wanna help you develop skills and adopt tools that we'\\n\\nll be around in\\nhugo bowne-anderson: several years. And I honestly can't guarantee you whether Langchain or Llama Index or crew, AI or any of these things will be around to be honest. But what Stefan and myself and a lot of our community are taking a bet on is that the principles that we learned building machine learning software for years and have started to use building Llm powered software, they will stick around.\\n\\nAnd so\\nhugo bowne-anderson: the 1st principle to recognize is upstream. You have these Api calls you have input and output. And you have knobs. You can tweak there. Right? You have system and user prompts. You have context, right? You have structured outputs, and you have a variety of knobs, such as temperature and top P, which we'll get to later this week.\\n\\nhugo bowne-anderson: Another principle and this is a foundational principle. All of these are is that Llms are non-deterministic.\"}, {\"id\": \"4174c007-f5f3-4c13-8869-25c48d18c741\", \"position\": 42, \"relevance\": 1.0, \"tokens\": 459, \"timestamp\": \"01:19:59.150\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:19:59.150]\\nhugo bowne-anderson: when we're looking at our data, I don't even know what the bloody prompt is and part of my language. But in Australia. That's barely a swear word, a cuss word, by the way, but I actually don't know what the prompt is. So how do I even know how to evaluate this this system. Right?\\n\\nSo I very much encourage you all to\\nhugo bowne-anderson: rip out llama index and rebuild the app where you don't like. You don't even need a front end. Ui, it's fun to use something in gradio. But pull it out and look at your data and see what type of responses you get and and how it compares as well.\\n\\nhugo bowne-anderson:\\n\\nSo\\nhugo bowne-anderson: in the next session, just foreshadowing slightly which is Workshop 2, we'\\n\\nll be doing a lot on prompt engineering in the Llm software development lifecycle and thinking through how we\\nhugo bowne-anderson: essentially how we start to think about evaluation when changing prompts and versioning. And and these types of things. We have a wonderful guest, speaker, Charles Fry, from from Modal about building AI powered apps on on modal. I actually also encourage you all very much to his guest. Talk last time really blew me away. So much. So I mean, I had him on a podcast to chat about it as well. This is the one page where the embed just didn't work,\\n\\nfor\\nhugo bowne-anderson: whatever reason.\\n\\nhugo bowne-anderson: And also, by the way, oh, yeah, I used sorry I used the new Gpt to create funny covers for everyone. So this is unlisted. So I would appreciate it. If you don't share these videos. These are really, for course, attendees also.\\n\\nhugo bowne-anderson: and as part of the value. But he gave a wonderful talk about what we all, as Llm. Developers need to know about gpus and hardware, so I do encourage you all time permitting to check that out, so he'll be giving a guest talk,\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "Did a pretty good job summarizing the slides",
        "feedback_notes": null,
        "feedback_user": "Lee",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, as it does not specify what the question was or what the response was."
    },
    {
        "id": "4f31306f-4a07-4d7b-96c0-89877a1e2449",
        "timestamp": "2025-04-14T23:41:40.020764",
        "question": "I mean synthetically generated questions",
        "response": "I'm sorry, but I couldn't find any information about synthetically generated questions in the provided sections of the workshop transcript.",
        "num_chunks": 5,
        "context_tokens": 2495,
        "completion_tokens": 26,
        "embedding_tokens": 7680,
        "total_tokens": 10201,
        "latency": 2.3770806789398193,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"454b873b-bbf8-4ef2-8ee1-9da8a777bf29\", \"position\": 21, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:46:30.010\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:46:30.010]\\nI do want to just take a quick\\nhugo bowne-anderson: detour when we're talking about.\\n\\nhugo bowne-anderson:\\n\\nYou know\\nhugo bowne-anderson: what we get use out of all of these things, for the conversational aspect of Llms is fantastic. I use it all the time. But in my humble estimation most roi will involve automation, not conversations. So, for example, an app that consumes Linkedin profiles finds relevant candidates for a position automates emails to them. That's 1 example that the demo I just showed you perhaps could could be used for.\\n\\nAnd this brings me to my point of and our point of\\nhugo bowne-anderson: really thinking about what we want to evaluate. Okay, so what's cool, you can ask, is the information extracts from Linkedin? Correct? That's a cool question to ask and important, that needs to be satisfied. But remember, we're trying to scale human behavior so, and we want it to result in the same outcomes. But better right? So the next question you might ask, do the emails generated resemble the emails domain experts sent previously.\\n\\nhugo bowne-anderson: also a good question to ask, and who would have thought trying to get a domain expert involved would be so so useful.\\n\\nBut it turns out it is now\\nhugo bowne-anderson: at a very macro level,\\n\\nthough\\nhugo bowne-anderson: you really want to know? Do the emails result in hiring good candidates? And is it more efficient and more cost effective than our previous system right? And it's actually not even clear how long these cycles are.\\n\\nSo making sure that we in the end tie these macro level\\nhugo bowne-anderson: business evaluations to the micro level Llm calls is super important.\\n\\nhugo bowne-anderson: So that brings us back to this. How do we? How do we evaluate a system like this? I don't know what the actual prompt sent to the Llm. Was. How do I give feedback on on system performance? How can I see data and traces and conversations? How can we iterate quickly on this? Mvp.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"a4953c09-eaa5-42da-ace5-c39f449a5d0c\", \"position\": 33, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"01:06:24.430\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:06:24.430]\\nhugo bowne-anderson: I? Clearly, yeah, I had the wrong name. Then I used the same name. You can't get a 5\\n\\nline\\nhugo bowne-anderson: app with Gemini. Sadly, but essentially, we do the same thing. We load the documents,\\n\\ncreate the store\\nhugo bowne-anderson: define Gemini 1.5 as the model we're using. Pass it to the engine, get out the response, print it. And so it'\\n\\ns actually\\nhugo bowne-anderson: it's exactly the same app.\\n\\nBut using Gemini\\nhugo bowne-anderson: 1.5 pro. So let's see what that does.\\n\\nhugo bowne-anderson: And literally, I've done this before. But I honestly, you know, this is cool.\\n\\nhugo bowne-anderson: Okay. The information's looking pretty good, can anyone? Although it doesn't.\\n\\nhugo bowne-anderson: it, it should say, is in California or something. Probably. Can anyone see an issue with this.\\n\\nhugo bowne-anderson: This is nonsense, right?\\n\\nhugo bowne-anderson: I've asked for Json, and it gives me Markdown.\\n\\nhugo bowne-anderson: It actually gives it. So it doesn't quite give me proper proper json right? With these these back ticks at the start.\\n\\nhugo bowne-anderson: which is, which is concerning, of course, we can do structured output and that type of stuff. And that's how we would do it. But so we get the right output. But we don't quite get the structure that that we want, which is pretty pretty interesting. And I know it's early next week we're we're doing a lot on structured outputs as well. Okay, so let me just clear this in the 3rd app.\\n\\nI thought to try it\\nhugo bowne-anderson: with Claude. Now, the other thing that's cheeky, you can see I'\\n\\nve\\nhugo bowne-anderson: chosen the generative responses. But llama index is still using Openai embeddings under the hood. I think I don't even know right. No, I actually do know. But you wouldn't right unless you tried to figure it out.\"}, {\"id\": \"b26fe73f-2853-48f3-85a7-9dd432743d9a\", \"position\": 16, \"relevance\": 1.0, \"tokens\": 402, \"timestamp\": \"00:36:47.170\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:36:47.170]\\nhugo bowne-anderson: not because the system is bad and at all right. So that's what we're here to really talk about. I do want to frame most things in terms of evaluation, driven development, although we'll we'll dovetail out of a lot of different different topics. Okay.\\n\\nhugo bowne-anderson:\\n\\nso\\nhugo bowne-anderson: our way out is Edd, evaluation, driven development. Where you have a iterative loop right where you build, you monitor, you evaluate, you improve now.\\n\\nhugo bowne-anderson: even before launching a product. And this is something we'll talk about as the course goes on. You can, you can build a synthetic data set and evaluation harnesses to help you even before real users exist. And if you don't know what an evaluation harness is, don't worry about it. It's essentially a script, something reproducible that you use to evaluate your system. So one example I like to give is.\\n\\nhugo bowne-anderson: I was working on something recently where we were using Gpt. 4.0 Mini, and then Google released Gemini 2.5. And we wanted to play around with it. And it was like, Okay, I'm going to switch this out. But how do I even know beyond vibes that it'\\n\\ns going to be\\nhugo bowne-anderson: good or not? So if you have a basic harness with a few tests, measuring latency and cost and things of business interest as well. This can get you a long way. So at the start, I actually encourage people to build what I call an Mve. So for any Mvp minimum viable product, you have an Mve a minimum viable evaluation as well. Right?\\n\\nhugo bowne-anderson: So just thinking through kind of how this happens. You have an Mvp, you have synthetic user queries.\"}, {\"id\": \"d5857637-9989-4909-8c68-7420e12b28a5\", \"position\": 23, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"00:50:35.220\", \"speaker\": \"William Horton\", \"text\": \"[TIMESTAMP: 00:50:35.220]\\nSame inputs\\nhugo bowne-anderson: can result in different outputs. This is an issue for software. Not only that, of course, is rarely. Do you even have the same inputs when you deploy to to users. The types of things you'll see are absolutely wild. You could, I talked about generating synthetic data to mimic users hands down. If you've ever built a conversational software product, you know the types of wild, wild stuff. That people will say that you could never,\\n\\nnever even think of\\nhugo bowne-anderson: I do love. I haven't done this,\\n\\nbut I do know people who who essentially found\\nhugo bowne-anderson: what they call free Gpt. Maybe you all have done this as well. But you can, you know.\\n\\nhugo bowne-anderson: find a product that has a chat bot, or something that actually allows you to just chat with Chat Gbt within it. Essentially, because I haven't put up proper guardrails right? But people will put input in to do all types of things. Now.\\n\\nhugo bowne-anderson: one of the most important principles is.\\n\\nhugo bowne-anderson: and I almost feel silly having to say this, but you'd be amazed how few people think about this robustly and do it. You need to log and monitor and trace. You need to capture your data in a human readable form as well. And then you need to evaluate, evaluate early evaluate.\\n\\nOften you need to look at your data\\nhugo bowne-anderson: and results in quantify performance. This will be a combination of domain expertise, binary classification and then classifying failure modes. And then you want to iterate. So iterate quickly, using prompt engineering, perhaps fine tuning, changing business logic. The reason, I say, perhaps fine tuning is. I think it probably isn't necessary in most cases anymore. But there are some in which it is so. As I mentioned at the start.\\n\\nhugo bowne-anderson: We have our traditional software development lifecycle, which is, I say, straightforward. It's relatively straightforward compared to Llm. Powered software. That's the real statement I want to make don't get traditional software can be horribly challenging to build. But you do start with specs. You build, you test, you deploy.\"}, {\"id\": \"1b89fc10-9191-405f-a697-591f4adc7f53\", \"position\": 10, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"00:24:51.560\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:24:51.560]\\nhugo bowne-anderson: replicate. But this is actually one of my favorite platforms. It has oop.\\n\\nhugo bowne-anderson: Let me just do this.\\n\\nhugo bowne-anderson: Let's go to explore.\\n\\nhugo bowne-anderson: You'll see they've got. Well, they've clearly just got all the llama models up now, but they've got all types of fun stuff that they Update all the time, and so you can make videos, generate images. It's a lot of multimodal stuff, so we won't necessarily use it for the Llm stuff. Upscale images. Use a face to make images, generate speech, use handy tools, and with my morning coffee, sometimes I come and just look at, look at, replicate, and and see what's up, what new models they have.\\n\\nhugo bowne-anderson: and I.\\n\\nhugo bowne-anderson: If I need to introduce hugging face, there may be an issue. You may be in the wrong course. No, I'm joking, but hugging face is giving everyone 6 months subscription to hugging face pro, which will allow us to use gpus and scale a bit more. As well learn prompting. They published the prompt report which was really the 1\\n\\nst comprehensive\\nhugo bowne-anderson: report on prompting techniques. They did it with Openai, with a bunch of with 20 different organizations, and they'll be coming to give a talk about prompt engineering in the software development lifecycle and prompt injection attacks. But they're giving. They've got a wonderful educational platform. They'll be giving 3 months of plus access and then prodigy. I don't know if you know prodigy, but it's human in the loop annotation, fine-tuning and Nlp. Workflow building from Innis, Montani and Matthew Honnibal,\\n\\nwho built Spacey\\nhugo bowne-anderson: and and maintain it. So that's all to say we have instructions for getting most of them, I think, replicate. For example. Yes, I need. There are a couple which I still need to just follow up on several things, but we'll sort all of those out in the near future, but most of them have instructions on how to do. Get them. So, please.\"}]",
        "success": 1,
        "feedback_rating": "FAIL",
        "feedback_reason": "There's a slide that talks about synthetic question generation",
        "feedback_notes": null,
        "feedback_user": "Lee",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information about the question asked, as it seems to be a placeholder or an error message."
    },
    {
        "id": "e8df5db7-37a6-4135-a5da-55a10b130a64",
        "timestamp": "2025-04-14T23:41:28.007277",
        "question": "I mean synthetic data generated questions",
        "response": "The workshop transcript sections do not provide information about synthetic data generated questions.",
        "num_chunks": 5,
        "context_tokens": 2446,
        "completion_tokens": 15,
        "embedding_tokens": 7680,
        "total_tokens": 10141,
        "latency": 1.575282335281372,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"b26fe73f-2853-48f3-85a7-9dd432743d9a\", \"position\": 16, \"relevance\": 1.0, \"tokens\": 402, \"timestamp\": \"00:36:47.170\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:36:47.170]\\nhugo bowne-anderson: not because the system is bad and at all right. So that's what we're here to really talk about. I do want to frame most things in terms of evaluation, driven development, although we'll we'll dovetail out of a lot of different different topics. Okay.\\n\\nhugo bowne-anderson:\\n\\nso\\nhugo bowne-anderson: our way out is Edd, evaluation, driven development. Where you have a iterative loop right where you build, you monitor, you evaluate, you improve now.\\n\\nhugo bowne-anderson: even before launching a product. And this is something we'll talk about as the course goes on. You can, you can build a synthetic data set and evaluation harnesses to help you even before real users exist. And if you don't know what an evaluation harness is, don't worry about it. It's essentially a script, something reproducible that you use to evaluate your system. So one example I like to give is.\\n\\nhugo bowne-anderson: I was working on something recently where we were using Gpt. 4.0 Mini, and then Google released Gemini 2.5. And we wanted to play around with it. And it was like, Okay, I'm going to switch this out. But how do I even know beyond vibes that it'\\n\\ns going to be\\nhugo bowne-anderson: good or not? So if you have a basic harness with a few tests, measuring latency and cost and things of business interest as well. This can get you a long way. So at the start, I actually encourage people to build what I call an Mve. So for any Mvp minimum viable product, you have an Mve a minimum viable evaluation as well. Right?\\n\\nhugo bowne-anderson: So just thinking through kind of how this happens. You have an Mvp, you have synthetic user queries.\"}, {\"id\": \"2c32b67b-e14d-4a60-822f-802f77643d9d\", \"position\": 18, \"relevance\": 1.0, \"tokens\": 437, \"timestamp\": \"00:40:43.000\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:40:43.000]\\nhugo bowne-anderson: in Ml, you collect real world examples, label by hand, train model on labor data, evaluate on held outset iterate based on performance. Okay, now, there are lots of challenges with Llms.\\n\\nBut\\nhugo bowne-anderson: at the start you get labeled data. It isn't real world data. But you get labeled data for free. You can build your like data flywheel really, really, quickly. So you synthesize realistic queries from personas. You can do that pre-launch label some outputs by hand.\\n\\nhugo bowne-anderson: you prompt the model tune prompts, and the system set up. Whether you're changing your embeddings or whatever it is you evaluate using your Mve, which is your test set and your automated Eval. Then you iterate, based on performance and use your evaluation to guide improvement.\\n\\nSo\\nhugo bowne-anderson: modulo differences. Both workflows are eerily similar. They're grounded in test sets, iteration and failure analysis. And those are the types of things. It's not sexy, right? But you'll get way more. You'\\n\\nll build far better apps if you get comfortable looking at spreadsheets and doing pivot tables of failure modes and building\\nhugo bowne-anderson: multi agentic systems with crew. AI, we're going to do both in this course right? But to be very clear, those are the skills that we're very interested in teaching. So before we jump into Github.\\n\\nI just want to tell you a basic story\\nhugo bowne-anderson: about how Poc purgatory starts. It starts, for example, with llama indexes what they what they call their famous 5 line, quick start, or whatever right where this is. This is incredible, that I can have some data in a document. I do my import. I set up my data directory. I do it. I created essentially a local vector store, a query engine. I then query, get out my response and print it in.\\n\\nhugo bowne-anderson: you know.\"}, {\"id\": \"d5857637-9989-4909-8c68-7420e12b28a5\", \"position\": 23, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"00:50:35.220\", \"speaker\": \"William Horton\", \"text\": \"[TIMESTAMP: 00:50:35.220]\\nSame inputs\\nhugo bowne-anderson: can result in different outputs. This is an issue for software. Not only that, of course, is rarely. Do you even have the same inputs when you deploy to to users. The types of things you'll see are absolutely wild. You could, I talked about generating synthetic data to mimic users hands down. If you've ever built a conversational software product, you know the types of wild, wild stuff. That people will say that you could never,\\n\\nnever even think of\\nhugo bowne-anderson: I do love. I haven't done this,\\n\\nbut I do know people who who essentially found\\nhugo bowne-anderson: what they call free Gpt. Maybe you all have done this as well. But you can, you know.\\n\\nhugo bowne-anderson: find a product that has a chat bot, or something that actually allows you to just chat with Chat Gbt within it. Essentially, because I haven't put up proper guardrails right? But people will put input in to do all types of things. Now.\\n\\nhugo bowne-anderson: one of the most important principles is.\\n\\nhugo bowne-anderson: and I almost feel silly having to say this, but you'd be amazed how few people think about this robustly and do it. You need to log and monitor and trace. You need to capture your data in a human readable form as well. And then you need to evaluate, evaluate early evaluate.\\n\\nOften you need to look at your data\\nhugo bowne-anderson: and results in quantify performance. This will be a combination of domain expertise, binary classification and then classifying failure modes. And then you want to iterate. So iterate quickly, using prompt engineering, perhaps fine tuning, changing business logic. The reason, I say, perhaps fine tuning is. I think it probably isn't necessary in most cases anymore. But there are some in which it is so. As I mentioned at the start.\\n\\nhugo bowne-anderson: We have our traditional software development lifecycle, which is, I say, straightforward. It's relatively straightforward compared to Llm. Powered software. That's the real statement I want to make don't get traditional software can be horribly challenging to build. But you do start with specs. You build, you test, you deploy.\"}, {\"id\": \"9ba847dd-5840-465a-8c18-e54cc4921ff1\", \"position\": 39, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"01:14:32.840\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:14:32.840]\\nhugo bowne-anderson: Oh, yeah, oh, this is great.\\n\\nhugo bowne-anderson:\\n\\nAnd I actually mean that because I love when the demo gods\\nhugo bowne-anderson: don't shine on one, but it's it'\\n\\ns helpful for\\nhugo bowne-anderson: everyone, I mean. That's what do they call it? A teachable moment or something.\\n\\nhugo bowne-anderson: so let's do this again.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: what?\\n\\nhugo bowne-anderson: What is happening here? I mean, legit. This is the type of question. People go into rag systems and say, What is what is this right? How are embedding? Is going to deal with that?\\n\\nhugo bowne-anderson: What is happening here?\\n\\nhugo bowne-anderson: The individual has been involved in various. They've been a key figure.\\n\\nhugo bowne-anderson: That's not too bad to a kind of a silly question.\\n\\nhugo bowne-anderson: then, who is this? I'm just. I'm gonna do 2 queries so that we can then just look at them. How how we can, Andrew in. Okay, good. So I'\\n\\nm gonna kill this app\\nhugo bowne-anderson:\\n\\nand what I want to show you is\\nhugo bowne-anderson: because we've logged into a local sqlite database, and that's what I deleted before we'\\n\\nve got our\\nhugo bowne-anderson: database here. Now we can't display it right? But what I want to do to look into it is a really cool tool that Simon Willison has built, which I encourage you all to to check out called data set with a ETTE at the end. And I'm just gonna say,\\n\\ndata set that database and it spins up a server that allows me to\\nhugo bowne-anderson: quickly look at everything that just occurred. So yeah, I'm going to look at interactions. 2 rows in one table.\\n\\nhugo bowne-anderson: Pdf, name uploaded? Pdf, probably need to change that. Then we have the query.\\n\\nhugo bowne-anderson: this query, what is happening here? The response.\"}, {\"id\": \"454b873b-bbf8-4ef2-8ee1-9da8a777bf29\", \"position\": 21, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:46:30.010\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:46:30.010]\\nI do want to just take a quick\\nhugo bowne-anderson: detour when we're talking about.\\n\\nhugo bowne-anderson:\\n\\nYou know\\nhugo bowne-anderson: what we get use out of all of these things, for the conversational aspect of Llms is fantastic. I use it all the time. But in my humble estimation most roi will involve automation, not conversations. So, for example, an app that consumes Linkedin profiles finds relevant candidates for a position automates emails to them. That's 1 example that the demo I just showed you perhaps could could be used for.\\n\\nAnd this brings me to my point of and our point of\\nhugo bowne-anderson: really thinking about what we want to evaluate. Okay, so what's cool, you can ask, is the information extracts from Linkedin? Correct? That's a cool question to ask and important, that needs to be satisfied. But remember, we're trying to scale human behavior so, and we want it to result in the same outcomes. But better right? So the next question you might ask, do the emails generated resemble the emails domain experts sent previously.\\n\\nhugo bowne-anderson: also a good question to ask, and who would have thought trying to get a domain expert involved would be so so useful.\\n\\nBut it turns out it is now\\nhugo bowne-anderson: at a very macro level,\\n\\nthough\\nhugo bowne-anderson: you really want to know? Do the emails result in hiring good candidates? And is it more efficient and more cost effective than our previous system right? And it's actually not even clear how long these cycles are.\\n\\nSo making sure that we in the end tie these macro level\\nhugo bowne-anderson: business evaluations to the micro level Llm calls is super important.\\n\\nhugo bowne-anderson: So that brings us back to this. How do we? How do we evaluate a system like this? I don't know what the actual prompt sent to the Llm. Was. How do I give feedback on on system performance? How can I see data and traces and conversations? How can we iterate quickly on this? Mvp.\\n\\nhugo bowne-anderson:\"}]",
        "success": 1,
        "feedback_rating": null,
        "feedback_reason": null,
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "d2d0f5e6-85e8-47ac-b4f9-b7b356133fcd",
        "timestamp": "2025-04-14T23:41:10.433737",
        "question": "Tell me more about Synthetic ",
        "response": "I'm sorry, but I couldn't find any information about Synthetic in the provided workshop transcript sections.",
        "num_chunks": 5,
        "context_tokens": 2504,
        "completion_tokens": 21,
        "embedding_tokens": 7680,
        "total_tokens": 10205,
        "latency": 1.8771839141845703,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"6bdaea5e-7f5e-4298-ae84-c395e49a96f9\", \"position\": 56, \"relevance\": 1.0, \"tokens\": 461, \"timestamp\": \"01:46:58.890\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:46:58.890]\\nI just click the view repository link\\nPhilip Kiely: and I got into the trust examples. So this is, you know, hundreds and hundreds of model implementations that we've made. And this lets me start to get into the tensor. Otllm build configuration. So in this case, you know, I have details around like how many Gpus, I'm using my tensor parallel count. I have different plugins that I can turn it off and on different sequence lengths. I can also,\\n\\nI should have\\nPhilip Kiely: hold this one up ahead of time.\\n\\nPhilip Kiely: yeah. I can also, for example, find one that is using speculative decoding.\\n\\nSo\\nPhilip Kiely: I can, you know. Add a speculator model to this same kind of config.\\n\\nSo I can basically\\nPhilip Kiely: add a and and all all this, by the way, is in the documentation. I can add a smaller model and try and see how much performance lift. I get on. You know, one type of input versus another type, because speculative decoding is, of course, very dependent on the actual input that you're putting in here. So yes. So with with this, you can actually do a lot more to kind of experiment with these different models.\\n\\nPhilip Kiely: and and the different levers that are available to you in dedicated deployments. The other thing I would really encourage you to do is go beyond just language models and think about what you can build from more of a multimodal sense. I know this course is maybe called. I think Llm. Is in the title of this course, but there's a lot of great models outside of Llms.\\n\\nPhilip Kiely: whisper is, of course, a great model to play with for audio transcription. If you want to build rag and agents. We just published a bunch of new text embedding models. Using a new optimized embedding runtime, which is twice as fast as Tei or Vlm or other industry standards. So you can, you know,\\n\\nuse this for something like chroma or pinecone\\nPhilip Kiely: or Mongodb and build, you know, rag and agent type stuff. We have really great speech speech synthesis models. Where is it?\"}, {\"id\": \"1b89fc10-9191-405f-a697-591f4adc7f53\", \"position\": 10, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"00:24:51.560\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:24:51.560]\\nhugo bowne-anderson: replicate. But this is actually one of my favorite platforms. It has oop.\\n\\nhugo bowne-anderson: Let me just do this.\\n\\nhugo bowne-anderson: Let's go to explore.\\n\\nhugo bowne-anderson: You'll see they've got. Well, they've clearly just got all the llama models up now, but they've got all types of fun stuff that they Update all the time, and so you can make videos, generate images. It's a lot of multimodal stuff, so we won't necessarily use it for the Llm stuff. Upscale images. Use a face to make images, generate speech, use handy tools, and with my morning coffee, sometimes I come and just look at, look at, replicate, and and see what's up, what new models they have.\\n\\nhugo bowne-anderson: and I.\\n\\nhugo bowne-anderson: If I need to introduce hugging face, there may be an issue. You may be in the wrong course. No, I'm joking, but hugging face is giving everyone 6 months subscription to hugging face pro, which will allow us to use gpus and scale a bit more. As well learn prompting. They published the prompt report which was really the 1\\n\\nst comprehensive\\nhugo bowne-anderson: report on prompting techniques. They did it with Openai, with a bunch of with 20 different organizations, and they'll be coming to give a talk about prompt engineering in the software development lifecycle and prompt injection attacks. But they're giving. They've got a wonderful educational platform. They'll be giving 3 months of plus access and then prodigy. I don't know if you know prodigy, but it's human in the loop annotation, fine-tuning and Nlp. Workflow building from Innis, Montani and Matthew Honnibal,\\n\\nwho built Spacey\\nhugo bowne-anderson: and and maintain it. So that's all to say we have instructions for getting most of them, I think, replicate. For example. Yes, I need. There are a couple which I still need to just follow up on several things, but we'll sort all of those out in the near future, but most of them have instructions on how to do. Get them. So, please.\"}, {\"id\": \"d5857637-9989-4909-8c68-7420e12b28a5\", \"position\": 23, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"00:50:35.220\", \"speaker\": \"William Horton\", \"text\": \"[TIMESTAMP: 00:50:35.220]\\nSame inputs\\nhugo bowne-anderson: can result in different outputs. This is an issue for software. Not only that, of course, is rarely. Do you even have the same inputs when you deploy to to users. The types of things you'll see are absolutely wild. You could, I talked about generating synthetic data to mimic users hands down. If you've ever built a conversational software product, you know the types of wild, wild stuff. That people will say that you could never,\\n\\nnever even think of\\nhugo bowne-anderson: I do love. I haven't done this,\\n\\nbut I do know people who who essentially found\\nhugo bowne-anderson: what they call free Gpt. Maybe you all have done this as well. But you can, you know.\\n\\nhugo bowne-anderson: find a product that has a chat bot, or something that actually allows you to just chat with Chat Gbt within it. Essentially, because I haven't put up proper guardrails right? But people will put input in to do all types of things. Now.\\n\\nhugo bowne-anderson: one of the most important principles is.\\n\\nhugo bowne-anderson: and I almost feel silly having to say this, but you'd be amazed how few people think about this robustly and do it. You need to log and monitor and trace. You need to capture your data in a human readable form as well. And then you need to evaluate, evaluate early evaluate.\\n\\nOften you need to look at your data\\nhugo bowne-anderson: and results in quantify performance. This will be a combination of domain expertise, binary classification and then classifying failure modes. And then you want to iterate. So iterate quickly, using prompt engineering, perhaps fine tuning, changing business logic. The reason, I say, perhaps fine tuning is. I think it probably isn't necessary in most cases anymore. But there are some in which it is so. As I mentioned at the start.\\n\\nhugo bowne-anderson: We have our traditional software development lifecycle, which is, I say, straightforward. It's relatively straightforward compared to Llm. Powered software. That's the real statement I want to make don't get traditional software can be horribly challenging to build. But you do start with specs. You build, you test, you deploy.\"}, {\"id\": \"7353c2ea-c61a-40e1-8901-cb06cb66199a\", \"position\": 48, \"relevance\": 1.0, \"tokens\": 442, \"timestamp\": \"01:28:11.060\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:28:11.060]\\nPhilip Kiely: We're gonna talk about what it takes to run influence in production. We're gonna talk about the journey of going from some of the things that you may be learning about and prototyping in this course to how you can maybe apply this stuff either in your day job,\\n\\nor if you start a startup as you scale or if you start a side project\\nPhilip Kiely: and it goes super viral. Actually, one of our biggest customers kind of started that way. Then, yeah, this also becomes, very, very relevant.\\n\\nPhilip Kiely: I had a little sneak peek at the at the lesson plan for today that that Hugo put together,\\n\\nand it sounds like a lot of the last hour hour and a half was about how to build AI products going from objective to data to model development model evaluation\\nPhilip Kiely: and talking about how that sort of workflow has changed. Going from an Ml.\\n\\nWorld to an AI world\\nPhilip Kiely: so base. 10 kind of comes in at the end of that. At the end of that cycle to take the thing that you've built and scale it to the entire world.\\n\\nPhilip Kiely: Sorry I should not have eaten very dry popcorn right before giving a a public talk.\\n\\nPhilip Kiely: So as we think about, you know how AI tools are being consumed in these applications today they're kind of 2 extremes. One extreme is you just outsource everything you go with a closed source shared endpoint like Openai or anthropic. You don't think about the model. You don't think about the infrastructure. You don't think about anything other than how many tokens you'\\n\\nre consuming and how much every single one of those tokens costs\\nPhilip Kiely: on the complete other end of the spectrum. You can do everything yourself. You can get your own Gpus, set up your own model influence servers load your own model weights and wire up your own infrastructure. Do everything yourself. What we're gonna talk about today is kind of a middle path where you get most of the control of the Diy with most of the ease of the, you know, low overhead, close source stuff.\"}, {\"id\": \"d1bd8f1b-b3fa-49f5-8ede-0da335f2724b\", \"position\": 1, \"relevance\": 1.0, \"tokens\": 471, \"timestamp\": \"00:02:47.710\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 00:02:47.710]\\nStefan Krawczyk: Cool. Hi, everyone welcome so name Stefan Craftyk. I'm based in San Francisco. But by my judging by my accent, if you can tell, I'm from New Zealand, not Australia.\\n\\nSo\\nStefan Krawczyk: in terms of yeah, like my background effectively for the last 10 years has been around Mlops. So if you heard the term machine learning operations. That's kind of where I kind of cut a lot of my teeth in terms of helping data scientists and machine learning. Engineers in particular go from prototype to productionization. More recently, in the last few years I've been the CEO of a company called Dagworks, where we've been driving to open source projects called Hamilton and Burr,\\n\\nand the thesis around there is that the same\\nStefan Krawczyk: problems that you had with Mlops are the same ones you have with Gen. AI, specifically, you need to understand and observe a lot around your data. And once you know more about your data, you can actually improve your whatever apps you'\\n\\nre kind of building\\nStefan Krawczyk: news news for you guys. So like, I didn't introduce myself to the CEO, because, actually, the company's actually been absorbed by a large public company,\\n\\nso\\nStefan Krawczyk: can't talk about it. But all I can say is, I'm helping them with their kind of agent efforts. And so in particular, yeah, how to get to production. So I will have I'll be on discord mostly, but otherwise I'll have a few sessions throughout this course that will talk a little bit more about some of the production stuff. And so just to let you know this is, you know, this firsthand stuff.\\n\\nStefan Krawczyk: anything relevant I left out of my intro Hugo, or.\\n\\nhugo bowne-anderson: No, I'll just say on under friend Da. Stefan has told me where he's where he's he's working, and I hope we get to announce it throughout the course. Because he's a really incredible place as far as I'm I'm concerned, supporting cutting edge at agentic work. So it's really very, very exciting.\"}]",
        "success": 1,
        "feedback_rating": null,
        "feedback_reason": null,
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "561135b2-e1dd-4b0a-b673-0d91f5de68a1",
        "timestamp": "2025-04-14T23:40:33.021364",
        "question": "Tell me more about the speakers in this workshop",
        "response": "In this workshop, there are several speakers mentioned. \n\n1. Stefan Krawczyk: He will be giving a full workshop in the next week. He will be discussing testing and running tests in Dev and production for Llm-powered apps. He will also cover other related topics. However, he mentions that he needs to clear some legal and social matters before officially changing his LinkedIn status.\n\n2. Jeff Pidcock, Nathan Danielson, and William Horton: They are participants from cohort one of the course. They are experienced builders in the industry and have been invited back to kick off the builders in residence program. They will be working with the participants to help them build and answer their questions. They are geographically distributed, with Jeff in Sydney, William on the East coast in DC, and Nathan in Los Angeles.",
        "num_chunks": 5,
        "context_tokens": 2373,
        "completion_tokens": 166,
        "embedding_tokens": 7680,
        "total_tokens": 10219,
        "latency": 2.465562582015991,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"7bc4faeb-6a92-4e8e-8835-c15f568df455\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}, {\"id\": \"8858f61a-6386-4a2c-9023-de13b0d93843\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"d3305c0c-8683-4610-9b10-71fa99ba0887\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"a9c0db2e-7df2-41ae-842a-c4f9628a6963\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}, {\"id\": \"ffe6d5a3-56d7-455e-a405-6f608ade3442\", \"position\": 62, \"relevance\": 1.0, \"tokens\": 302, \"timestamp\": \"01:59:06.670\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:59:06.670]\\nPhilip Kiely: Thank you so much for having me. Thanks everyone for your time today.\\n\\nhugo bowne-anderson: Such a pleasure. Thanks, Philip.\\n\\nhugo bowne-anderson: and everyone else. It's it's time to time to wrap up. I just want to give Philip one more round of applause.\\n\\nGreat\\nhugo bowne-anderson: It is time to wrap up. We do have 2. As as I mentioned before, we have an just an onboarding form. A lot of you have completed it, but if you're if you haven't, and able to, this will allow us, it'll let us know where you are. What you're interested in, and it will allow us to set up the office hours that that we're going to with our wonderful builders in residence as well.\\n\\nOnce again I will share with you\\nhugo bowne-anderson: the feedback form. A bunch of you have already provided a lot of valuable feedback in there, which we'll use to iterate quickly on how we, how we teach and how we approach this course. I'm going to share that in the discord chat also.\\n\\nhugo bowne-anderson: So it's there. But that's it for today, and we'll see you on discord, and we'll see you in 46\\u00a0h for the next workshop as well. So thanks everyone, and thanks for a great 1st session.\"}]",
        "success": 1,
        "feedback_rating": "FAIL",
        "feedback_reason": "Didn't include Hugo!",
        "feedback_notes": null,
        "feedback_user": "Lee",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "1eed9d4c-39cb-45d6-b01b-81f4986ad1ab",
        "timestamp": "2025-04-14T23:39:54.066647",
        "question": "Tell me what questions or comments I should send you",
        "response": "I'm sorry, but I couldn't find any information in the provided sections about what questions or comments should be sent to Hugo Bowne-Anderson.",
        "num_chunks": 5,
        "context_tokens": 2544,
        "completion_tokens": 32,
        "embedding_tokens": 7680,
        "total_tokens": 10256,
        "latency": 2.3929574489593506,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"8c29a601-4c63-48a0-b63a-e60a187a2016\", \"position\": 44, \"relevance\": 1.0, \"tokens\": 474, \"timestamp\": \"01:24:11.480\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:24:11.480]\\nhugo bowne-anderson: awesome. I appreciate that. So Philip. I wonder, Philip, are you on the call yet? By any chance?\\n\\nhugo bowne-anderson: Okay, you should be here in a few minutes. But Philip Philip Keeley, who's devrel at base 10 really, really fascinating dude does a lot of technical documentation and technical writing as well as published around that. He'll be giving a talk in a few minutes on moving Llm. Apps from prototype to production with with base 10. Please do not forget to claim your $1,000 free free credit, which I'm so grateful for that I've been able to provide.\\n\\nAnd you just have a look at all the types of things they have\\nhugo bowne-anderson: on their platform that you can deploy with a couple of clicks. To be honest, I really would love, and I,\\n\\nhugo bowne-anderson: because we have a few minutes now.\\n\\nhugo bowne-anderson: I would actually really love.\\n\\nI have a feedback form\\nhugo bowne-anderson: for each workshop. And so what you'll see here.\\n\\nhugo bowne-anderson: you know you put your email in. How did you rate the pace? What did you like most? What could we improve? Was there anything unclear or confusing? If so, what any other feedback or suggestions? I'm going to put that in the discord right now, and if you wouldn't mind just taking a few minutes now to complete it, there's far more chance of you actually completing it now than there is afterwards. I just statistically. So yeah, let's just take. Don't take more than 3\\n\\nmin\\nhugo bowne-anderson: to jot down a few things there when you rate the pace of the session also. Do note, this is the 1st one. So for some people it may totally have been too slow, and I get that, but it was the 1st session. So why don't everyone can take a couple of minutes to do that? And then when Philip joins we'll jump into his talk.\\n\\nhugo bowne-anderson: Stefan, William, Nathan, while people are doing that I'm wondering.\"}, {\"id\": \"454b873b-bbf8-4ef2-8ee1-9da8a777bf29\", \"position\": 21, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:46:30.010\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:46:30.010]\\nI do want to just take a quick\\nhugo bowne-anderson: detour when we're talking about.\\n\\nhugo bowne-anderson:\\n\\nYou know\\nhugo bowne-anderson: what we get use out of all of these things, for the conversational aspect of Llms is fantastic. I use it all the time. But in my humble estimation most roi will involve automation, not conversations. So, for example, an app that consumes Linkedin profiles finds relevant candidates for a position automates emails to them. That's 1 example that the demo I just showed you perhaps could could be used for.\\n\\nAnd this brings me to my point of and our point of\\nhugo bowne-anderson: really thinking about what we want to evaluate. Okay, so what's cool, you can ask, is the information extracts from Linkedin? Correct? That's a cool question to ask and important, that needs to be satisfied. But remember, we're trying to scale human behavior so, and we want it to result in the same outcomes. But better right? So the next question you might ask, do the emails generated resemble the emails domain experts sent previously.\\n\\nhugo bowne-anderson: also a good question to ask, and who would have thought trying to get a domain expert involved would be so so useful.\\n\\nBut it turns out it is now\\nhugo bowne-anderson: at a very macro level,\\n\\nthough\\nhugo bowne-anderson: you really want to know? Do the emails result in hiring good candidates? And is it more efficient and more cost effective than our previous system right? And it's actually not even clear how long these cycles are.\\n\\nSo making sure that we in the end tie these macro level\\nhugo bowne-anderson: business evaluations to the micro level Llm calls is super important.\\n\\nhugo bowne-anderson: So that brings us back to this. How do we? How do we evaluate a system like this? I don't know what the actual prompt sent to the Llm. Was. How do I give feedback on on system performance? How can I see data and traces and conversations? How can we iterate quickly on this? Mvp.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"33280789-3e96-4a89-8a77-e415c7af7c9f\", \"position\": 45, \"relevance\": 1.0, \"tokens\": 488, \"timestamp\": \"01:25:38.330\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:25:38.330]\\nhugo bowne-anderson: Well, I was gonna talk about some things, but maybe we'll we'll wait because I don't. Wanna don't wanna distract people.\\n\\nhugo bowne-anderson: hey, Philip? Great to see you, man.\\n\\nPhilip Kiely: Hey, everyone.\\n\\nhugo bowne-anderson: We'll get started in a couple of minutes. I've just got everyone I'm taking a couple of minutes to complete a a survey about how? The 1\\n\\nst\\nhugo bowne-anderson: part of this workshop workshop when. But thank you so much for for joining. So we'll yeah just start in a minute.\\n\\nPhilip Kiely: Sounds good.\\n\\nhugo bowne-anderson: Where? Where are you, darling? Are you in the Bay Area.\\n\\nPhilip Kiely: Yeah, I'm right on embalcadero right now.\\n\\nhugo bowne-anderson: Must have been a wild, wild few days since Llama 4 dropped.\\n\\nPhilip Kiely: I I got back from jujitsu at about noon on on Saturday, you know, nice and tired and sweaty, and ready for a nice relaxing afternoon, and then I check my phone and boom, mama. 4 waits. And there went the weekend. But a lot of fun.\\n\\nhugo bowne-anderson: I'm sure. And yeah, congrats to you and the entire team for getting up, getting it up and running so quickly and getting your great Demos out. It's really, really impressive, inspiring stuff, man.\\n\\nPhilip Kiely: Thank you. It's what we do.\\n\\nhugo bowne-anderson:\\n\\nIt is\\nhugo bowne-anderson: so we'll just take 30 more seconds to give everyone a a chance to complete this. Would you mind actually giving my comment in discord a thumb up when you when you've completed it.\\n\\nhugo bowne-anderson: Nathan just wrote in discord, llama for Saturday. Exactly. That'\\n\\ns\\nhugo bowne-anderson: it. Beats deep. Seek Monday I'll tell you that.\\n\\nPhilip Kiely: I spent the day after Christmas. Implementing deep seek stuff and making deep seek content at my cousin's childhood bedroom at my aunt's house. Because that's where everyone else was having Boxing Day.\"}, {\"id\": \"b674449a-19e6-4f6f-bb31-728c52cde071\", \"position\": 58, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"01:52:08.230\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:52:08.230]\\nhugo bowne-anderson: That was. That was fantastic. We've got it. We've got several great questions in the chat which I'll get people to turn their mics on to ask themselves in a second. I also I've so I've had a wonderful experience with base 10 support. We're not offering support from base 10 in our discord. But my understanding is, if people ping support, they should be relatively quick in being able to help help with stuff.\\n\\nPhilip Kiely: Yeah, yeah. So we we try and give, you know, good support to everyone. Self service or enterprise. So yeah, absolutely stick with the stick with the support channel. Just, you know, like I said, we just we just did revamp docs. So hopefully, that's able to catch a bunch of stuff, but if not definitely, don't hesitate to hit us up. If it's something close or credit related, feel free to reach out to me directly.\\n\\nhugo bowne-anderson: Awesome. I really appreciate it, and of course we'll try to help help each other as well before before pinging you. Caleb Tutti has a great question, Caleb, would you mind just asking your question? Maybe you could just start by introducing yourself what what you do and and where you are, so we'll have a bit more context.\\n\\nCaleb Tutty: Sure. Yeah, Hi, I'm I'm Caleb. So I do. Consulting one of the projects that I work on is ASR into the legal domain.\\n\\nCaleb Tutty: and we we do. Yeah, sort of a number of different projects with sort of Llms. I I guess the question I was wondering about is, I guess, just looking at costs, and when it'\\n\\ns\\nCaleb Tutty: when it makes sense, maybe to have sort of a dedicated endpoint. Is it common with other customers to do batch workloads, maybe. Is this sort of infrastructure code kind of tools I saw you showed some gamble there to maybe sort of set up, do a batch job and then shut shut down. So the instance is that a common or good use case with base 10.\\n\\nPhilip Kiely: Yeah, that's a great question, Caleb,\"}, {\"id\": \"87d6ebd7-75bf-4d95-a218-987cf363e594\", \"position\": 34, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:07:54.020\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:07:54.020]\\nSo\\nhugo bowne-anderson: let's now see what Claude says.\\n\\nhugo bowne-anderson: Now,\\n\\nI just want to state\\nhugo bowne-anderson: what an amazing world we live in that. As I said, you know you get in demo hell here.\\n\\nhugo bowne-anderson: But the ability to like rapidly test 3 different state of the art models in a little system that are built in 15\\u00a0min.\\n\\nhugo bowne-anderson: Absolutely incredible. Right?\\n\\nAnd so here we have the same Json\\nhugo bowne-anderson: issue. Okay. Name is Andrew. Not great. I mean great name, love the name, but should be Andrew Ng. Here, it's got some good information. There. It's got his education location null again.\\n\\nSo\\nhugo bowne-anderson: what do I want to say about that.\\n\\nhugo bowne-anderson: What I really want to say is that the 1\\n\\nst app\\nhugo bowne-anderson: got the person wrong and said it was me. The second one didn't get a few things, got the name right? Got the person right? Didn't return the structured output that I wanted. The 3rd app had similar similar issues to the second. So we've already seen a difference in behavior here. Right? And this is.\\n\\nhugo bowne-anderson: as you all may be aware, this is the process I'm engaging in right now is kind of vibe checking my my models like just getting a sense for what I feel works and and what doesn't.\\n\\nAnd\\nhugo bowne-anderson: I apologize for not including this slide.\\n\\nBut I do want to show you one more slide\\nhugo bowne-anderson: on where we're moving which direction we're moving in for evaluation, driven development.\\n\\nhugo bowne-anderson: So this is why structure matters. I just did check by vibes, and I was like subjective feeling seems better. And but what I just did is inconsistent. It's non-reproducible. I haven't really got a historical baseline or anything quantifiable. It's hard to communicate results. Clearly, I mean, I just kind of it'\\n\\ns\\nhugo bowne-anderson: you know, it'\"}]",
        "success": 1,
        "feedback_rating": "FAIL",
        "feedback_reason": "Did not tell me what I should ask!",
        "feedback_notes": null,
        "feedback_user": "Lee",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information regarding the question asked, as it does not specify what the question was or what the response was. Therefore, it fails to be helpful, relevant, or direct."
    },
    {
        "id": "e854700f-1fd2-48f2-a5e7-3c21539caab9",
        "timestamp": "2025-04-14T23:38:02.053352",
        "question": "What are the workshop topics in this course?",
        "response": "The workshop topics in this course include:\n- Building software powered by machine learning and Llms\n- Foundations of Llm software and evaluation-driven development\n- Prompt engineering, embeddings, and fine-tuning business logic\n- Unit tests, versioning, and continuous integration when deploying\n- Tracing and general observability when monitoring and evaluating\n- Iteration, debugging, and adaptation in the workflow\n- Systematic evaluation of Llm outputs and defining metrics for success\n- Observability basics, debugging common Llm issues, and scaling observability\n- Testing and evaluation principles, not specific tools",
        "num_chunks": 5,
        "context_tokens": 2542,
        "completion_tokens": 121,
        "embedding_tokens": 7680,
        "total_tokens": 10343,
        "latency": 1.8324565887451172,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"4afe9b98-71d2-408e-a843-72cf99bbb1f9\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"002fca43-c0aa-47e3-9200-bfb53441d970\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"0c72b225-0ef3-4f73-99e4-c952d1d98426\", \"position\": 8, \"relevance\": 1.0, \"tokens\": 497, \"timestamp\": \"00:19:54.940\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:19:54.940]\\nSo\\nhugo bowne-anderson: I hinted at this. But what this course isn't, it is not a deep dive into every Llm. Tool or trend. Of course we'll be doing. We'll be doing a bunch on agents actually, in the second half of the course, and rag and embeddings and more. But the focus is on workflows, not tools, I honestly think, and I'm happy to chat about those and message about those to be honest. But you will have enough resources on that. What we're teaching is what we'\\n\\nve really noticed is a huge gap\\nhugo bowne-anderson: in education around this stuff. This is not a plug and play AI recipe book. They don't even exist. If someone tries to tell you that or sell you that I'd love to hear it. What you'll learn is how to iterate, debug and adapt not just follow step by step. Templates. Okay, once again, this is not some, you know. Hyper, scaled, load balance, multi agent, guide. This course is about getting you moving, not solving every scaling challenge,\\n\\nbut really approaching the workflow\\nhugo bowne-anderson: of how to get things in production and then keep iterating on them.\\n\\nhugo bowne-anderson: So I'm gonna put this. This is incredibly important. This is an onboarding form that actually 25 of you have completed already. And I'm so happy with with that number so far. Usually, I try to say I try to give a form of 5 to 10\\u00a0min, but I honestly think if you all take 10 to 15\\u00a0min to complete this form. It will make this workshop and community really, really special. Okay.\\n\\nhugo bowne-anderson: so and so I just saw Jeff's note. That's in discord. That's that is brilliant.\\n\\nhugo bowne-anderson: And so I do think the the more we know about you and your interests, just because there are 5 of us now as as well. Right and geographically distributed, so the more we can we can be of help.\\n\\nhugo bowne-anderson: Jeff. Nathan has shared the course Wiki page, which we'll get to in a second,\\n\\nand part of that is\\nhugo bowne-anderson: the compute credit access form. Now I'\"}, {\"id\": \"8858f61a-6386-4a2c-9023-de13b0d93843\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"a9c0db2e-7df2-41ae-842a-c4f9628a6963\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "Provided multi-bullet summarization of different topics",
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript, focusing on real-world data integration and non-deterministic behavior."
    },
    {
        "id": "8562f297-af05-42e8-af8c-0f6e4135ee99",
        "timestamp": "2025-04-14T23:37:38.700565",
        "question": "who is the intended audience for the workshop?",
        "response": "The intended audience for the workshop includes data scientists, software engineers, and anyone else who wants to learn about building Llm-powered applications.",
        "num_chunks": 5,
        "context_tokens": 2558,
        "completion_tokens": 28,
        "embedding_tokens": 7680,
        "total_tokens": 10266,
        "latency": 1.8370208740234375,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"8858f61a-6386-4a2c-9023-de13b0d93843\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"7bc4faeb-6a92-4e8e-8835-c15f568df455\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}, {\"id\": \"a9c0db2e-7df2-41ae-842a-c4f9628a6963\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}, {\"id\": \"d42ab0b2-decf-4ca5-92ed-683919b98d2b\", \"position\": 0, \"relevance\": 1.0, \"tokens\": 487, \"timestamp\": \"00:00:14.050\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:00:14.050]\\nhugo bowne-anderson: All right. Welcome everyone. Hugo Bowen Anderson, here so excited to be kicking off workshop. One of building Llm. Powered applications for data, scientists, software engineers, and whoever else wants to get on this rocket ship together, love that. I can see a bunch of friendly faces already. We'll get to this.\\n\\nBut\\nhugo bowne-anderson: if you're able to turn your camera on, I, personally would really appreciate it, and I can tell you it makes me a better teacher as well to see a bunch of faces, and to see all the, all the engagement as well, and only if you're able to, of course, and generally microphones off when not speaking as well.\\n\\nhugo bowne-anderson: I'm I'm so excited to have you all here already, seeing what you all are up to in the discord in the forms you filled in really appreciate you filling in the onboarding form as well. We'\\n\\nve got a bunch of really serious builders who seem a lot of fun also so really excited to get to know you all\\nhugo bowne-anderson: as well. So my name is Hugo Band Anderson. I've worked in data, science and machine learning, and what now we call AI for far out 15 years now. So I feel a bit old to to be honest. I've worked in building, in education, in consulting and and devrel. Also a lot of work in devrel for open, open source stuff.\\n\\nhugo bowne-anderson: so like my, I think my, my.\\n\\nhugo bowne-anderson: my background really has been in doing scientific research using the Pi data stack that then turned into software stuff. So that's really where I come from. In the past couple of years I've been building a lot with generative AI and helping a lot of other people to build also.\\n\\nhugo bowne-anderson: But that really brings up my my background is in scientific research, in doing stuff, in notebooks, in doing my best to productionize stuff without throwing it over the wall to software engineers, which is one of the reasons I teamed up with with Stefan, who is my co-instructor and colleague and friend here, so I'll just hand it over to Stefan to say a few words.\"}, {\"id\": \"d3305c0c-8683-4610-9b10-71fa99ba0887\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "Accurate characterization of the audience. \"LLM\" should be capitalized",
        "feedback_notes": null,
        "feedback_user": "Naoya",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "e3c5f068-1898-433a-9323-db96e5ef69bb",
        "timestamp": "2025-04-14T23:35:22.320474",
        "question": "Who were the instructors in this workshop?",
        "response": "The instructors in this workshop were Hugo Bowne-Anderson and Stefan Krawczyk.",
        "num_chunks": 5,
        "context_tokens": 2352,
        "completion_tokens": 20,
        "embedding_tokens": 7680,
        "total_tokens": 10052,
        "latency": 1.9057862758636477,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"d3305c0c-8683-4610-9b10-71fa99ba0887\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"ffe6d5a3-56d7-455e-a405-6f608ade3442\", \"position\": 62, \"relevance\": 1.0, \"tokens\": 302, \"timestamp\": \"01:59:06.670\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:59:06.670]\\nPhilip Kiely: Thank you so much for having me. Thanks everyone for your time today.\\n\\nhugo bowne-anderson: Such a pleasure. Thanks, Philip.\\n\\nhugo bowne-anderson: and everyone else. It's it's time to time to wrap up. I just want to give Philip one more round of applause.\\n\\nGreat\\nhugo bowne-anderson: It is time to wrap up. We do have 2. As as I mentioned before, we have an just an onboarding form. A lot of you have completed it, but if you're if you haven't, and able to, this will allow us, it'll let us know where you are. What you're interested in, and it will allow us to set up the office hours that that we're going to with our wonderful builders in residence as well.\\n\\nOnce again I will share with you\\nhugo bowne-anderson: the feedback form. A bunch of you have already provided a lot of valuable feedback in there, which we'll use to iterate quickly on how we, how we teach and how we approach this course. I'm going to share that in the discord chat also.\\n\\nhugo bowne-anderson: So it's there. But that's it for today, and we'll see you on discord, and we'll see you in 46\\u00a0h for the next workshop as well. So thanks everyone, and thanks for a great 1st session.\"}, {\"id\": \"d42ab0b2-decf-4ca5-92ed-683919b98d2b\", \"position\": 0, \"relevance\": 1.0, \"tokens\": 487, \"timestamp\": \"00:00:14.050\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:00:14.050]\\nhugo bowne-anderson: All right. Welcome everyone. Hugo Bowen Anderson, here so excited to be kicking off workshop. One of building Llm. Powered applications for data, scientists, software engineers, and whoever else wants to get on this rocket ship together, love that. I can see a bunch of friendly faces already. We'll get to this.\\n\\nBut\\nhugo bowne-anderson: if you're able to turn your camera on, I, personally would really appreciate it, and I can tell you it makes me a better teacher as well to see a bunch of faces, and to see all the, all the engagement as well, and only if you're able to, of course, and generally microphones off when not speaking as well.\\n\\nhugo bowne-anderson: I'm I'm so excited to have you all here already, seeing what you all are up to in the discord in the forms you filled in really appreciate you filling in the onboarding form as well. We'\\n\\nve got a bunch of really serious builders who seem a lot of fun also so really excited to get to know you all\\nhugo bowne-anderson: as well. So my name is Hugo Band Anderson. I've worked in data, science and machine learning, and what now we call AI for far out 15 years now. So I feel a bit old to to be honest. I've worked in building, in education, in consulting and and devrel. Also a lot of work in devrel for open, open source stuff.\\n\\nhugo bowne-anderson: so like my, I think my, my.\\n\\nhugo bowne-anderson: my background really has been in doing scientific research using the Pi data stack that then turned into software stuff. So that's really where I come from. In the past couple of years I've been building a lot with generative AI and helping a lot of other people to build also.\\n\\nhugo bowne-anderson: But that really brings up my my background is in scientific research, in doing stuff, in notebooks, in doing my best to productionize stuff without throwing it over the wall to software engineers, which is one of the reasons I teamed up with with Stefan, who is my co-instructor and colleague and friend here, so I'll just hand it over to Stefan to say a few words.\"}, {\"id\": \"8858f61a-6386-4a2c-9023-de13b0d93843\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"8aeb4046-d053-4ff6-ae05-bd234e174a17\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "It's correct and concise and no extraneous material.",
        "feedback_notes": null,
        "feedback_user": "hugo",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, making it unhelpful and irrelevant."
    },
    {
        "id": "d60fea0a-b3fa-4f25-a8d3-0588cdbab7d0",
        "timestamp": "2025-04-14T22:26:55.791664",
        "question": "What were the tools discussed in the workshop for building LLM-powered applications?",
        "response": "The tools discussed in the workshop for building LLM-powered applications are Google Drive (for slides and supporting material), GitHub and CodeSpaces (for code), Discord (for asynchronous chat and announcements), and Google Colab or VS Code (for code editing and execution).",
        "num_chunks": 5,
        "context_tokens": 2403,
        "completion_tokens": 53,
        "embedding_tokens": 7680,
        "total_tokens": 10136,
        "latency": 1.131829023361206,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"2e93c44e-f591-4422-bbd0-c27f5e7d20fb\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"af1c6da5-f122-4783-972b-0326074aeda3\", \"position\": 22, \"relevance\": 1.0, \"tokens\": 401, \"timestamp\": \"00:48:18.740\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:48:18.740]\\nAnd\\nhugo bowne-anderson: the answer, the answers come in the in the process that we're here to teach you about in this entire course. And one thing to understand is kind of the flow of the system.\\n\\nSo\\nhugo bowne-anderson: we have our upstream prompt and context being sent to an Llm. Then we have the Llm output, and this being consumed downstream in a variety of ways.\\n\\nhugo bowne-anderson: So what type of principles do we need to really think about then. And another way to frame what we're doing here is, of course, we're using tools the entire time. But we're not tool focused. We're, we're principle focused.\\n\\nAnd\\nhugo bowne-anderson: one of the reasons that'\\n\\ns the case is\\nhugo bowne-anderson: we wanna help you develop skills and adopt tools that we'\\n\\nll be around in\\nhugo bowne-anderson: several years. And I honestly can't guarantee you whether Langchain or Llama Index or crew, AI or any of these things will be around to be honest. But what Stefan and myself and a lot of our community are taking a bet on is that the principles that we learned building machine learning software for years and have started to use building Llm powered software, they will stick around.\\n\\nAnd so\\nhugo bowne-anderson: the 1st principle to recognize is upstream. You have these Api calls you have input and output. And you have knobs. You can tweak there. Right? You have system and user prompts. You have context, right? You have structured outputs, and you have a variety of knobs, such as temperature and top P, which we'll get to later this week.\\n\\nhugo bowne-anderson: Another principle and this is a foundational principle. All of these are is that Llms are non-deterministic.\"}, {\"id\": \"bb7b0f38-c870-4751-82a9-62583450c3e4\", \"position\": 56, \"relevance\": 1.0, \"tokens\": 461, \"timestamp\": \"01:46:58.890\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:46:58.890]\\nI just click the view repository link\\nPhilip Kiely: and I got into the trust examples. So this is, you know, hundreds and hundreds of model implementations that we've made. And this lets me start to get into the tensor. Otllm build configuration. So in this case, you know, I have details around like how many Gpus, I'm using my tensor parallel count. I have different plugins that I can turn it off and on different sequence lengths. I can also,\\n\\nI should have\\nPhilip Kiely: hold this one up ahead of time.\\n\\nPhilip Kiely: yeah. I can also, for example, find one that is using speculative decoding.\\n\\nSo\\nPhilip Kiely: I can, you know. Add a speculator model to this same kind of config.\\n\\nSo I can basically\\nPhilip Kiely: add a and and all all this, by the way, is in the documentation. I can add a smaller model and try and see how much performance lift. I get on. You know, one type of input versus another type, because speculative decoding is, of course, very dependent on the actual input that you're putting in here. So yes. So with with this, you can actually do a lot more to kind of experiment with these different models.\\n\\nPhilip Kiely: and and the different levers that are available to you in dedicated deployments. The other thing I would really encourage you to do is go beyond just language models and think about what you can build from more of a multimodal sense. I know this course is maybe called. I think Llm. Is in the title of this course, but there's a lot of great models outside of Llms.\\n\\nPhilip Kiely: whisper is, of course, a great model to play with for audio transcription. If you want to build rag and agents. We just published a bunch of new text embedding models. Using a new optimized embedding runtime, which is twice as fast as Tei or Vlm or other industry standards. So you can, you know,\\n\\nuse this for something like chroma or pinecone\\nPhilip Kiely: or Mongodb and build, you know, rag and agent type stuff. We have really great speech speech synthesis models. Where is it?\"}, {\"id\": \"e7199ecc-f5ce-46ed-b686-6cd932e00ca3\", \"position\": 11, \"relevance\": 1.0, \"tokens\": 445, \"timestamp\": \"00:26:25.726\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:26:25.726]\\nhugo bowne-anderson: Pretty, please do that.\\n\\nhugo bowne-anderson:\\n\\nand I just encourage you all to\\nhugo bowne-anderson: use. I mean, use these tools as much as you can while building during the course, because we're here to support and talk about them and and build with you. I do want to say I do appreciate. Everyone likely has more than full time, jobs and families, and all of these things or subsets of these. So I do understand, particularly in our line of work.\\n\\nTime is an incredibly precious\\nhugo bowne-anderson: resource.\\n\\nSo\\nhugo bowne-anderson: all that's to say is, if you don't have much time to build outside, that's totally cool. If you, if all you do is attend these workshops and nothing else. You'll get a huge amount out of the course if you keep building also, and keep in the discords, and then join the office. Hours and pods will set up, you'll get even even more so. I like to think the world's your oyster in proverbial oyster in a lot of ways.\\n\\nSo just getting started in terms of\\nhugo bowne-anderson: set up.\\n\\nhugo bowne-anderson: We use several tools, and my goal is to use as few tools as possible.\\n\\nI will rarely adopt a new tool\\nhugo bowne-anderson: if I don't have to. So in the past we used in the first.st So in the 1st cohort, we use Google drive. This is for slides supporting material. This type of stuff we use github and codespaces for code and also codespaces, feel free to clone the repository and do what you want with it, but we want to make sure that you can get set up and up and running as quickly as possible, and I'll introduce you to code spaces later. It'\\n\\ns kind of\\nhugo bowne-anderson: Google colab on steroids or Vs code superpowered in the browser. We use discord for the Async Chat announcements, and the Q.\"}, {\"id\": \"caea0788-5f81-42d2-abeb-51660c6ee262\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}]",
        "success": 1,
        "feedback_rating": "FAIL",
        "feedback_reason": "Absolute Fail",
        "feedback_notes": null,
        "feedback_user": "hugo",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "f3b7ddd4-408c-49dc-a12c-6d9057fb15e0",
        "timestamp": "2025-04-14T22:26:17.443586",
        "question": "What were the tools discussed in the workshop?",
        "response": "The tools discussed in the workshop were:\n- Zoom for recording and sharing the workshops\n- Discord for asynchronous chat, announcements, and Q&A\n- Google Drive for slides and supporting materials\n- GitHub and CodeSpaces for code\n- VS Code for coding in the browser",
        "num_chunks": 5,
        "context_tokens": 2465,
        "completion_tokens": 55,
        "embedding_tokens": 7680,
        "total_tokens": 10200,
        "latency": 1.4851510524749756,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"caea0788-5f81-42d2-abeb-51660c6ee262\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"e7199ecc-f5ce-46ed-b686-6cd932e00ca3\", \"position\": 11, \"relevance\": 1.0, \"tokens\": 445, \"timestamp\": \"00:26:25.726\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:26:25.726]\\nhugo bowne-anderson: Pretty, please do that.\\n\\nhugo bowne-anderson:\\n\\nand I just encourage you all to\\nhugo bowne-anderson: use. I mean, use these tools as much as you can while building during the course, because we're here to support and talk about them and and build with you. I do want to say I do appreciate. Everyone likely has more than full time, jobs and families, and all of these things or subsets of these. So I do understand, particularly in our line of work.\\n\\nTime is an incredibly precious\\nhugo bowne-anderson: resource.\\n\\nSo\\nhugo bowne-anderson: all that's to say is, if you don't have much time to build outside, that's totally cool. If you, if all you do is attend these workshops and nothing else. You'll get a huge amount out of the course if you keep building also, and keep in the discords, and then join the office. Hours and pods will set up, you'll get even even more so. I like to think the world's your oyster in proverbial oyster in a lot of ways.\\n\\nSo just getting started in terms of\\nhugo bowne-anderson: set up.\\n\\nhugo bowne-anderson: We use several tools, and my goal is to use as few tools as possible.\\n\\nI will rarely adopt a new tool\\nhugo bowne-anderson: if I don't have to. So in the past we used in the first.st So in the 1st cohort, we use Google drive. This is for slides supporting material. This type of stuff we use github and codespaces for code and also codespaces, feel free to clone the repository and do what you want with it, but we want to make sure that you can get set up and up and running as quickly as possible, and I'll introduce you to code spaces later. It'\\n\\ns kind of\\nhugo bowne-anderson: Google colab on steroids or Vs code superpowered in the browser. We use discord for the Async Chat announcements, and the Q.\"}, {\"id\": \"8ae2ac1b-e43c-492c-8ec6-ada1b8a10776\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}, {\"id\": \"2e93c44e-f591-4422-bbd0-c27f5e7d20fb\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"370c72a1-617e-4a73-b100-783c97ca11c0\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}]",
        "success": 1,
        "feedback_rating": "FAIL",
        "feedback_reason": "Look, technically this is right, but I was really thinking technical tools.Like to build LLM Powered apps.",
        "feedback_notes": null,
        "feedback_user": "hugo",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "f94e13b6-d3d1-42bd-891e-49852c75748b",
        "timestamp": "2025-04-14T07:19:18.486791",
        "question": "Was there a guest lecture in this workshop?",
        "response": "Yes, there was a mention of guest lectures in this workshop. The workshop instructor mentioned several guest lecturers, including Hamil Hussein from parlance labs, Eric Ma from Moderna, Ravin Kumar from Google Deepmind, and Ines Montani from Spacey.",
        "num_chunks": 5,
        "context_tokens": 2422,
        "completion_tokens": 55,
        "embedding_tokens": 7680,
        "total_tokens": 10157,
        "latency": 2.0847411155700684,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"08d8578a-b65f-43b9-aec1-dc87bdc19364\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}, {\"id\": \"9a87d03e-c1f5-47bf-bed8-bd5abd3b9206\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"d3d0305d-caac-45c4-b126-5f6eb609e584\", \"position\": 13, \"relevance\": 1.0, \"tokens\": 406, \"timestamp\": \"00:29:52.640\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:29:52.640]\\nI I wonder if I put\\nhugo bowne-anderson: yes, I did put the shared commitments there, so we'll go through that in a second, and we'll keep keep adding adding things here. And actually, one thing which I, some of you have asked about are the guest lectures from cohort one, and I've created a little guest lecture, Archive and there's there's actually one or 2 missing here, including William Horton, who gave a wonderful talk on, on thinking through when to launch,\\n\\nand how how to think about\\nhugo bowne-anderson: what metrics you want to measure before launch, and how sometimes that can be challenging, and how you really need to iterate on that. But these are all talks from the previous ones.\\n\\nAnd if you click on\\nhugo bowne-anderson: the page, let's click on Nathan's.\\n\\nhugo bowne-anderson: Yeah, we have an AI generated summary. We have a Youtube video. I'll put the slides in soon. Takeaways AI generated, and and so on. So in all honesty, this is the 1st time we've created something like this. So feedback, incredibly incredibly welcome. And by this I mean this type of document that links to different resources and Youtube videos and and that type of stuff. I'm really excited to have it grow with with all of you as well.\\n\\nhugo bowne-anderson:\\n\\nI\\nhugo bowne-anderson: I think that is pretty much it.\\n\\nJust before getting to\\nhugo bowne-anderson: content. Now, Williams, talk isn't like Williams.\\n\\nTalk is actually\\nhugo bowne-anderson: You remember? That was, that was a 2\\u00a0h session that turned into a 4\\u00a0h session and zoom. That also happens. By the way, and I will apologize for that. Y'all are not in like required to stick around,\"}, {\"id\": \"0ba8e212-e122-4e6a-9630-75f7dc408db6\", \"position\": 42, \"relevance\": 1.0, \"tokens\": 459, \"timestamp\": \"01:19:59.150\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:19:59.150]\\nhugo bowne-anderson: when we're looking at our data, I don't even know what the bloody prompt is and part of my language. But in Australia. That's barely a swear word, a cuss word, by the way, but I actually don't know what the prompt is. So how do I even know how to evaluate this this system. Right?\\n\\nSo I very much encourage you all to\\nhugo bowne-anderson: rip out llama index and rebuild the app where you don't like. You don't even need a front end. Ui, it's fun to use something in gradio. But pull it out and look at your data and see what type of responses you get and and how it compares as well.\\n\\nhugo bowne-anderson:\\n\\nSo\\nhugo bowne-anderson: in the next session, just foreshadowing slightly which is Workshop 2, we'\\n\\nll be doing a lot on prompt engineering in the Llm software development lifecycle and thinking through how we\\nhugo bowne-anderson: essentially how we start to think about evaluation when changing prompts and versioning. And and these types of things. We have a wonderful guest, speaker, Charles Fry, from from Modal about building AI powered apps on on modal. I actually also encourage you all very much to his guest. Talk last time really blew me away. So much. So I mean, I had him on a podcast to chat about it as well. This is the one page where the embed just didn't work,\\n\\nfor\\nhugo bowne-anderson: whatever reason.\\n\\nhugo bowne-anderson: And also, by the way, oh, yeah, I used sorry I used the new Gpt to create funny covers for everyone. So this is unlisted. So I would appreciate it. If you don't share these videos. These are really, for course, attendees also.\\n\\nhugo bowne-anderson: and as part of the value. But he gave a wonderful talk about what we all, as Llm. Developers need to know about gpus and hardware, so I do encourage you all time permitting to check that out, so he'll be giving a guest talk,\"}, {\"id\": \"32630332-8081-4b57-a958-dd8351ffde5c\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}]",
        "success": 1,
        "feedback_rating": "FAIL",
        "feedback_reason": "So actually, these are all great answers in a lot of ways, but it doesn't answer the question that was there actually a guest lecture. Those are in the course, not in this workshop and in this workshop we had Philip from base 10.",
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "56bab5dc-3ba7-4a74-a5cd-364d91f72baa",
        "timestamp": "2025-04-14T03:51:12.352042",
        "question": "What is the news that Stefan doesn't want people to share?",
        "response": "Stefan mentions that his company has been absorbed by a large public company, but he cannot talk about it.",
        "num_chunks": 5,
        "context_tokens": 2591,
        "completion_tokens": 24,
        "embedding_tokens": 7680,
        "total_tokens": 10295,
        "latency": 1.6923828125,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"b75e077e-561c-4c97-a4ee-6a18adeb6caa\", \"position\": 1, \"relevance\": 1.0, \"tokens\": 471, \"timestamp\": \"00:02:47.710\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 00:02:47.710]\\nStefan Krawczyk: Cool. Hi, everyone welcome so name Stefan Craftyk. I'm based in San Francisco. But by my judging by my accent, if you can tell, I'm from New Zealand, not Australia.\\n\\nSo\\nStefan Krawczyk: in terms of yeah, like my background effectively for the last 10 years has been around Mlops. So if you heard the term machine learning operations. That's kind of where I kind of cut a lot of my teeth in terms of helping data scientists and machine learning. Engineers in particular go from prototype to productionization. More recently, in the last few years I've been the CEO of a company called Dagworks, where we've been driving to open source projects called Hamilton and Burr,\\n\\nand the thesis around there is that the same\\nStefan Krawczyk: problems that you had with Mlops are the same ones you have with Gen. AI, specifically, you need to understand and observe a lot around your data. And once you know more about your data, you can actually improve your whatever apps you'\\n\\nre kind of building\\nStefan Krawczyk: news news for you guys. So like, I didn't introduce myself to the CEO, because, actually, the company's actually been absorbed by a large public company,\\n\\nso\\nStefan Krawczyk: can't talk about it. But all I can say is, I'm helping them with their kind of agent efforts. And so in particular, yeah, how to get to production. So I will have I'll be on discord mostly, but otherwise I'll have a few sessions throughout this course that will talk a little bit more about some of the production stuff. And so just to let you know this is, you know, this firsthand stuff.\\n\\nStefan Krawczyk: anything relevant I left out of my intro Hugo, or.\\n\\nhugo bowne-anderson: No, I'll just say on under friend Da. Stefan has told me where he's where he's he's working, and I hope we get to announce it throughout the course. Because he's a really incredible place as far as I'm I'm concerned, supporting cutting edge at agentic work. So it's really very, very exciting.\"}, {\"id\": \"b0297eec-66bb-4793-a31a-6b45a9e05af6\", \"position\": 51, \"relevance\": 1.0, \"tokens\": 485, \"timestamp\": \"01:34:58.800\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:34:58.800]\\nPhilip Kiely: I could go, you know, make a new open AI account and get my 1st influence. Call in like 5\\u00a0min flat.\\n\\nPhilip Kiely: and you only pay for the tokens you use. You don't have to think about cold start times. You don't have to think about paying per minute of hardware.\\n\\nPhilip Kiely: but there's a bunch of downsides that start to emerge as you get to scale one big one is just like no visibility or control over the model. So if you know, tomorrow they make a new model, and they want to deprecate the one you've been using. You're out of luck. If the models getting really expensive to serve and they decide to quantize it,\\n\\nand your use case happens to be the one that used those\\nPhilip Kiely: you know, outlier weights that just got smushed in. And now the model sucks too bad. There's not really anything you can do about it.\\n\\nPhilip Kiely: You also have limited privacy and compliance options. Honestly, they're getting a lot better with that all the shared Endpoint providers are now, you know, signing Baas, and you know, doing that kind of stuff. But you know you'd still get structurally less privacy and compliance options than you do with dedicated. Also, if you have, like regional compliance options, those can be a little bit more difficult to to comply with on a on a shared endpoint basis.\\n\\nPhilip Kiely: And the big issue is that, like everyone else, is using these things too. So if you know. I just have my app, and it's chugging along, and Hugo makes a better app, and it's, you know, going viral on Twitter and sending a ton of traffic to the shared endpoint. Then my app goes. You know my app gets slow or weight limited, or even the endpoint that I'm relying on goes down because of his traffic, not because of mine.\\n\\nPhilip Kiely: So yeah, those are. There's just like a a large number of of challenges with these shared inference endpoints, dedicated deployments. It's kind of the opposite. Like all of the bet. All of the downsides of shared inference endpoints are the benefits of dedicated deployments. They're private. They're secure. They're cost efficient at scale. They're highly reliable.\"}, {\"id\": \"051a14e2-90ae-48ec-9e74-3d4fc43334a2\", \"position\": 19, \"relevance\": 1.0, \"tokens\": 489, \"timestamp\": \"00:42:11.750\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:42:11.750]\\nhugo bowne-anderson: one line import and 5 lines of code. And and I can query documents that's incredibly powerful and don't get me wrong. I want us to keep doing that right. But the fallout from being able to do this is sorry. Okay. The response of this one was, Hugo is a dedicated, visionary, hardworking, and intelligent in. You see, it's already hallucinating. Okay,\\n\\nSo\\nhugo bowne-anderson: even in order to think about those things, what we can then do to go into demo hell a bit more. And this is what we'll do soon. Today. We can add a ui in 7 more lines of code, using gradio from hugging face, which I, which is one of my favorite tools for shipping product to friends, and even like William and Jeff and I have been spinning up like gradio interfaces with modal and rag and all of these types of things that the past week right? So we can do that relatively, straightforwardly. And then we end up with this.\\n\\nhugo bowne-anderson: So this is 5\\n\\nlines of code\\nhugo bowne-anderson: plus 7. So that's 12 lines of code that gives me this interface. Right?\\n\\nhugo bowne-anderson: And once again. We're going to build this in 10\\u00a0min, or something like that. I can drag and drop a Pdf of my Linkedin profile on it, and I think. Let's see what I ask it. Who is Hugo?\\n\\nhugo bowne-anderson: Hugo Bowne is a blah blah. Okay, that looks right to me. And and then I ask, who is Stefan?\\n\\nhugo bowne-anderson: I didn't know I did this.\\n\\nThen\\nhugo bowne-anderson: there is no information provided about Stefan in the context. So that is super cool. Right?\\n\\nhugo bowne-anderson: So just for clarity. I don't keep querying about myself because I'm solipsistic or narcissistic. I do it because I can tell whether the answer is correct or not. Right? So so I just showed you what happened with, who is Hugo? And who is Stefan worked?\\n\\nNow I just want to show you\\nhugo bowne-anderson:\"}, {\"id\": \"8a321314-8aaa-4c08-bb50-e834ad263aba\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"fcc46a89-6527-44a0-82fb-477439b7bb05\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "Factually correct.",
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, as it does not specify what the question was or what the response addressed."
    },
    {
        "id": "0d48c272-9679-4cf8-b699-771fc52c6b2a",
        "timestamp": "2025-04-14T03:50:54.080281",
        "question": "What is Stefan's secret?",
        "response": "The provided sections do not mention Stefan's secret.",
        "num_chunks": 5,
        "context_tokens": 2586,
        "completion_tokens": 11,
        "embedding_tokens": 7680,
        "total_tokens": 10277,
        "latency": 1.206827163696289,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"b75e077e-561c-4c97-a4ee-6a18adeb6caa\", \"position\": 1, \"relevance\": 1.0, \"tokens\": 471, \"timestamp\": \"00:02:47.710\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 00:02:47.710]\\nStefan Krawczyk: Cool. Hi, everyone welcome so name Stefan Craftyk. I'm based in San Francisco. But by my judging by my accent, if you can tell, I'm from New Zealand, not Australia.\\n\\nSo\\nStefan Krawczyk: in terms of yeah, like my background effectively for the last 10 years has been around Mlops. So if you heard the term machine learning operations. That's kind of where I kind of cut a lot of my teeth in terms of helping data scientists and machine learning. Engineers in particular go from prototype to productionization. More recently, in the last few years I've been the CEO of a company called Dagworks, where we've been driving to open source projects called Hamilton and Burr,\\n\\nand the thesis around there is that the same\\nStefan Krawczyk: problems that you had with Mlops are the same ones you have with Gen. AI, specifically, you need to understand and observe a lot around your data. And once you know more about your data, you can actually improve your whatever apps you'\\n\\nre kind of building\\nStefan Krawczyk: news news for you guys. So like, I didn't introduce myself to the CEO, because, actually, the company's actually been absorbed by a large public company,\\n\\nso\\nStefan Krawczyk: can't talk about it. But all I can say is, I'm helping them with their kind of agent efforts. And so in particular, yeah, how to get to production. So I will have I'll be on discord mostly, but otherwise I'll have a few sessions throughout this course that will talk a little bit more about some of the production stuff. And so just to let you know this is, you know, this firsthand stuff.\\n\\nStefan Krawczyk: anything relevant I left out of my intro Hugo, or.\\n\\nhugo bowne-anderson: No, I'll just say on under friend Da. Stefan has told me where he's where he's he's working, and I hope we get to announce it throughout the course. Because he's a really incredible place as far as I'm I'm concerned, supporting cutting edge at agentic work. So it's really very, very exciting.\"}, {\"id\": \"051a14e2-90ae-48ec-9e74-3d4fc43334a2\", \"position\": 19, \"relevance\": 1.0, \"tokens\": 489, \"timestamp\": \"00:42:11.750\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:42:11.750]\\nhugo bowne-anderson: one line import and 5 lines of code. And and I can query documents that's incredibly powerful and don't get me wrong. I want us to keep doing that right. But the fallout from being able to do this is sorry. Okay. The response of this one was, Hugo is a dedicated, visionary, hardworking, and intelligent in. You see, it's already hallucinating. Okay,\\n\\nSo\\nhugo bowne-anderson: even in order to think about those things, what we can then do to go into demo hell a bit more. And this is what we'll do soon. Today. We can add a ui in 7 more lines of code, using gradio from hugging face, which I, which is one of my favorite tools for shipping product to friends, and even like William and Jeff and I have been spinning up like gradio interfaces with modal and rag and all of these types of things that the past week right? So we can do that relatively, straightforwardly. And then we end up with this.\\n\\nhugo bowne-anderson: So this is 5\\n\\nlines of code\\nhugo bowne-anderson: plus 7. So that's 12 lines of code that gives me this interface. Right?\\n\\nhugo bowne-anderson: And once again. We're going to build this in 10\\u00a0min, or something like that. I can drag and drop a Pdf of my Linkedin profile on it, and I think. Let's see what I ask it. Who is Hugo?\\n\\nhugo bowne-anderson: Hugo Bowne is a blah blah. Okay, that looks right to me. And and then I ask, who is Stefan?\\n\\nhugo bowne-anderson: I didn't know I did this.\\n\\nThen\\nhugo bowne-anderson: there is no information provided about Stefan in the context. So that is super cool. Right?\\n\\nhugo bowne-anderson: So just for clarity. I don't keep querying about myself because I'm solipsistic or narcissistic. I do it because I can tell whether the answer is correct or not. Right? So so I just showed you what happened with, who is Hugo? And who is Stefan worked?\\n\\nNow I just want to show you\\nhugo bowne-anderson:\"}, {\"id\": \"8a15ede5-6ad6-4674-8db1-2372911fe2c6\", \"position\": 0, \"relevance\": 1.0, \"tokens\": 487, \"timestamp\": \"00:00:14.050\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:00:14.050]\\nhugo bowne-anderson: All right. Welcome everyone. Hugo Bowen Anderson, here so excited to be kicking off workshop. One of building Llm. Powered applications for data, scientists, software engineers, and whoever else wants to get on this rocket ship together, love that. I can see a bunch of friendly faces already. We'll get to this.\\n\\nBut\\nhugo bowne-anderson: if you're able to turn your camera on, I, personally would really appreciate it, and I can tell you it makes me a better teacher as well to see a bunch of faces, and to see all the, all the engagement as well, and only if you're able to, of course, and generally microphones off when not speaking as well.\\n\\nhugo bowne-anderson: I'm I'm so excited to have you all here already, seeing what you all are up to in the discord in the forms you filled in really appreciate you filling in the onboarding form as well. We'\\n\\nve got a bunch of really serious builders who seem a lot of fun also so really excited to get to know you all\\nhugo bowne-anderson: as well. So my name is Hugo Band Anderson. I've worked in data, science and machine learning, and what now we call AI for far out 15 years now. So I feel a bit old to to be honest. I've worked in building, in education, in consulting and and devrel. Also a lot of work in devrel for open, open source stuff.\\n\\nhugo bowne-anderson: so like my, I think my, my.\\n\\nhugo bowne-anderson: my background really has been in doing scientific research using the Pi data stack that then turned into software stuff. So that's really where I come from. In the past couple of years I've been building a lot with generative AI and helping a lot of other people to build also.\\n\\nhugo bowne-anderson: But that really brings up my my background is in scientific research, in doing stuff, in notebooks, in doing my best to productionize stuff without throwing it over the wall to software engineers, which is one of the reasons I teamed up with with Stefan, who is my co-instructor and colleague and friend here, so I'll just hand it over to Stefan to say a few words.\"}, {\"id\": \"fcc46a89-6527-44a0-82fb-477439b7bb05\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"8a321314-8aaa-4c08-bb50-e834ad263aba\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}]",
        "success": 1,
        "feedback_rating": null,
        "feedback_reason": null,
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, as it does not specify what the question was or what the response was."
    },
    {
        "id": "87f37b3b-2164-47c1-bdcc-fd8601d9b648",
        "timestamp": "2025-04-14T03:50:00.425023",
        "question": "List the \"builder's in residence\" who were former students in cohort 1.",
        "response": "The \"builder's in residence\" who were former students in cohort 1 are Jeff Pidcock, Nathan Danielson, and William Horton.",
        "num_chunks": 5,
        "context_tokens": 2296,
        "completion_tokens": 30,
        "embedding_tokens": 7680,
        "total_tokens": 10006,
        "latency": 1.6722722053527832,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"8a321314-8aaa-4c08-bb50-e834ad263aba\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"5b8080b1-d91c-4970-a002-00ba364150fb\", \"position\": 62, \"relevance\": 1.0, \"tokens\": 302, \"timestamp\": \"01:59:06.670\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:59:06.670]\\nPhilip Kiely: Thank you so much for having me. Thanks everyone for your time today.\\n\\nhugo bowne-anderson: Such a pleasure. Thanks, Philip.\\n\\nhugo bowne-anderson: and everyone else. It's it's time to time to wrap up. I just want to give Philip one more round of applause.\\n\\nGreat\\nhugo bowne-anderson: It is time to wrap up. We do have 2. As as I mentioned before, we have an just an onboarding form. A lot of you have completed it, but if you're if you haven't, and able to, this will allow us, it'll let us know where you are. What you're interested in, and it will allow us to set up the office hours that that we're going to with our wonderful builders in residence as well.\\n\\nOnce again I will share with you\\nhugo bowne-anderson: the feedback form. A bunch of you have already provided a lot of valuable feedback in there, which we'll use to iterate quickly on how we, how we teach and how we approach this course. I'm going to share that in the discord chat also.\\n\\nhugo bowne-anderson: So it's there. But that's it for today, and we'll see you on discord, and we'll see you in 46\\u00a0h for the next workshop as well. So thanks everyone, and thanks for a great 1st session.\"}, {\"id\": \"29f06a08-dc2f-449a-914b-bf685977f676\", \"position\": 11, \"relevance\": 1.0, \"tokens\": 445, \"timestamp\": \"00:26:25.726\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:26:25.726]\\nhugo bowne-anderson: Pretty, please do that.\\n\\nhugo bowne-anderson:\\n\\nand I just encourage you all to\\nhugo bowne-anderson: use. I mean, use these tools as much as you can while building during the course, because we're here to support and talk about them and and build with you. I do want to say I do appreciate. Everyone likely has more than full time, jobs and families, and all of these things or subsets of these. So I do understand, particularly in our line of work.\\n\\nTime is an incredibly precious\\nhugo bowne-anderson: resource.\\n\\nSo\\nhugo bowne-anderson: all that's to say is, if you don't have much time to build outside, that's totally cool. If you, if all you do is attend these workshops and nothing else. You'll get a huge amount out of the course if you keep building also, and keep in the discords, and then join the office. Hours and pods will set up, you'll get even even more so. I like to think the world's your oyster in proverbial oyster in a lot of ways.\\n\\nSo just getting started in terms of\\nhugo bowne-anderson: set up.\\n\\nhugo bowne-anderson: We use several tools, and my goal is to use as few tools as possible.\\n\\nI will rarely adopt a new tool\\nhugo bowne-anderson: if I don't have to. So in the past we used in the first.st So in the 1st cohort, we use Google drive. This is for slides supporting material. This type of stuff we use github and codespaces for code and also codespaces, feel free to clone the repository and do what you want with it, but we want to make sure that you can get set up and up and running as quickly as possible, and I'll introduce you to code spaces later. It'\\n\\ns kind of\\nhugo bowne-anderson: Google colab on steroids or Vs code superpowered in the browser. We use discord for the Async Chat announcements, and the Q.\"}, {\"id\": \"af4f7469-770a-4967-8b1b-473559080b0b\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}, {\"id\": \"8e040b3e-a532-4f75-b462-beecf0ea7508\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "It listed them correctly.",
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, as it does not specify what the question was or what the response was."
    },
    {
        "id": "62270a75-8d5e-4af3-9aa1-716a7cfd9009",
        "timestamp": "2025-04-13T19:32:04.780290",
        "question": "list the sections of the workshop and keep it under 100 words",
        "response": "The workshop transcript sections provided are as follows:\n\n1. Housekeeping: The instructor discusses the recording and sharing of workshop sessions, the use of Discord for communication, and encourages participants to explore and provide feedback on how to leverage Discord better.\n\n2. Time Management and Tools: The instructor emphasizes the importance of time management and introduces the tools used in the course, including Google Drive, GitHub, Discord, and Zoom. They also mention the course wiki as a resource for participants.\n\n3. Code Spaces: The instructor explains the use of Code Spaces, a tool similar to VS Code but in the browser, for setting up and running code. They mention the importance of setting up the environment before the workshop and provide a video tutorial for assistance.\n\n4. Next Week's Topic: The instructor briefly discusses the topic of the next workshop, which will focus on iteration, evaluation, and observability in language model outputs. They mention the emphasis on first principles and the flexibility to apply the concepts to different work environments.",
        "num_chunks": 5,
        "context_tokens": 2513,
        "completion_tokens": 200,
        "embedding_tokens": 7680,
        "total_tokens": 10393,
        "latency": 2.0857338905334473,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"c49ebade-0619-49f0-9434-50ae0e07224c\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"c504cfaf-e434-4f78-a778-00c88ed8b056\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}, {\"id\": \"40dc026c-2113-4b95-9028-00fbf3008a29\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}, {\"id\": \"6ec4577b-1f04-4c7e-988a-a1364ed21124\", \"position\": 11, \"relevance\": 1.0, \"tokens\": 445, \"timestamp\": \"00:26:25.726\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:26:25.726]\\nhugo bowne-anderson: Pretty, please do that.\\n\\nhugo bowne-anderson:\\n\\nand I just encourage you all to\\nhugo bowne-anderson: use. I mean, use these tools as much as you can while building during the course, because we're here to support and talk about them and and build with you. I do want to say I do appreciate. Everyone likely has more than full time, jobs and families, and all of these things or subsets of these. So I do understand, particularly in our line of work.\\n\\nTime is an incredibly precious\\nhugo bowne-anderson: resource.\\n\\nSo\\nhugo bowne-anderson: all that's to say is, if you don't have much time to build outside, that's totally cool. If you, if all you do is attend these workshops and nothing else. You'll get a huge amount out of the course if you keep building also, and keep in the discords, and then join the office. Hours and pods will set up, you'll get even even more so. I like to think the world's your oyster in proverbial oyster in a lot of ways.\\n\\nSo just getting started in terms of\\nhugo bowne-anderson: set up.\\n\\nhugo bowne-anderson: We use several tools, and my goal is to use as few tools as possible.\\n\\nI will rarely adopt a new tool\\nhugo bowne-anderson: if I don't have to. So in the past we used in the first.st So in the 1st cohort, we use Google drive. This is for slides supporting material. This type of stuff we use github and codespaces for code and also codespaces, feel free to clone the repository and do what you want with it, but we want to make sure that you can get set up and up and running as quickly as possible, and I'll introduce you to code spaces later. It'\\n\\ns kind of\\nhugo bowne-anderson: Google colab on steroids or Vs code superpowered in the browser. We use discord for the Async Chat announcements, and the Q.\"}, {\"id\": \"2e890de2-a6d4-4730-851d-ea4af21e88ef\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}]",
        "success": 1,
        "feedback_rating": "FAIL",
        "feedback_reason": "it missed important information like baseten section",
        "feedback_notes": "it was better by telling to keep under the max token limit that is likely to have this app, but it missed important information",
        "feedback_user": "Pastor",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "1a5c4211-c0a7-4af9-8024-f7380bb4dd3a",
        "timestamp": "2025-04-13T19:25:00.368422",
        "question": "breakdown into a list the sections discused in this workshop, keep it under 100 words",
        "response": "In this workshop, the following sections were discussed:\n\n1. Housekeeping: The workshop was recorded and would be shared later. The chat feature was turned off, and participants were encouraged to DM the instructors to join the Discord channel.\n\n2. Tools and Setup: The tools used in the course were mentioned, including Google Drive, GitHub, Discord, and Zoom. A course wiki was introduced, and participants were asked to keep it private.\n\n3. Code Spaces: Code Spaces, a tool similar to VS Code in the browser, was highlighted as a convenient way to set up and run code. Participants were encouraged to watch a video on setting up the environment beforehand.\n\n4. Next Week's Topic: The topic for the next workshop was mentioned, which would focus on iteration, evaluation, and observability. The importance of testing and evaluation principles, rather than specific tools, was emphasized.\n\nThe sections covered in this workshop were housekeeping, tools and setup, code spaces, and next week's topic.",
        "num_chunks": 5,
        "context_tokens": 2518,
        "completion_tokens": 200,
        "embedding_tokens": 7680,
        "total_tokens": 10398,
        "latency": 2.2748589515686035,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"17d2d848-6190-4904-b5e2-daa7f6019c1d\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}, {\"id\": \"2ecfdfdb-8d0d-411c-a51a-556b32cb1652\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"f173342d-43a6-45ed-a4f8-0a461afd6368\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}, {\"id\": \"7bb8b439-fd14-4d61-85f2-97e68d999d49\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"00c93a67-9165-473b-8ace-005e94ae5cd2\", \"position\": 11, \"relevance\": 1.0, \"tokens\": 445, \"timestamp\": \"00:26:25.726\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:26:25.726]\\nhugo bowne-anderson: Pretty, please do that.\\n\\nhugo bowne-anderson:\\n\\nand I just encourage you all to\\nhugo bowne-anderson: use. I mean, use these tools as much as you can while building during the course, because we're here to support and talk about them and and build with you. I do want to say I do appreciate. Everyone likely has more than full time, jobs and families, and all of these things or subsets of these. So I do understand, particularly in our line of work.\\n\\nTime is an incredibly precious\\nhugo bowne-anderson: resource.\\n\\nSo\\nhugo bowne-anderson: all that's to say is, if you don't have much time to build outside, that's totally cool. If you, if all you do is attend these workshops and nothing else. You'll get a huge amount out of the course if you keep building also, and keep in the discords, and then join the office. Hours and pods will set up, you'll get even even more so. I like to think the world's your oyster in proverbial oyster in a lot of ways.\\n\\nSo just getting started in terms of\\nhugo bowne-anderson: set up.\\n\\nhugo bowne-anderson: We use several tools, and my goal is to use as few tools as possible.\\n\\nI will rarely adopt a new tool\\nhugo bowne-anderson: if I don't have to. So in the past we used in the first.st So in the 1st cohort, we use Google drive. This is for slides supporting material. This type of stuff we use github and codespaces for code and also codespaces, feel free to clone the repository and do what you want with it, but we want to make sure that you can get set up and up and running as quickly as possible, and I'll introduce you to code spaces later. It'\\n\\ns kind of\\nhugo bowne-anderson: Google colab on steroids or Vs code superpowered in the browser. We use discord for the Async Chat announcements, and the Q.\"}]",
        "success": 1,
        "feedback_rating": null,
        "feedback_reason": null,
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information about the question asked, as it seems to be a placeholder or an error message rather than a relevant answer."
    },
    {
        "id": "e34617aa-04bb-4218-accc-515e36ec54b2",
        "timestamp": "2025-04-13T19:22:12.592276",
        "question": "breakdown into a list the sections discused in this workshop",
        "response": "1. Housekeeping and introduction to the workshop (00:12:49.260)\n- Mention of recording and sharing of workshop sessions\n- Explanation of using Discord for discussions and sharing resources\n- Invitation to provide feedback on leveraging Discord better\n\n2. Overview of the workshop topics (00:16:06.360)\n- Introduction to the foundations of LLm software and evaluation-driven development\n- Emphasis on building quickly, deploying, monitoring, evaluating, and iterating rapidly\n- Mention of prompt engineering, embeddings, fine-tuning business logic, unit tests, versioning, continuous integration, tracing, and observability\n\n3. Course Wiki and resources (00:28:30.270)\n- Introduction to the course Wiki for private use by workshop participants\n- Explanation of the course schedule and workshop pages\n- Invitation to contribute to the Transcript in Chat Gpt or suggest additions\n\n4. Setting up the coding environment (01:00:50.310)\n- Mention of using Zoom, VS Code, and Code Spaces for the workshops\n- Encouragement to watch a video on setting up the environment before the workshop\n- Note that debugging environment setup won't be done during workshop time\n\n5. Preview of next week's workshop (01:22:16.770)\n- Overview of topics to be covered, including systematic evaluation of LLm outputs, defining metrics for success, setting up feedback loops, observability basics, debugging LLm issues, and scaling observability\n- Emphasis on teaching first principles rather than specific tools\n- Invitation for Stefan to add flavor and discuss testing loops in dev and prod",
        "num_chunks": 5,
        "context_tokens": 2515,
        "completion_tokens": 326,
        "embedding_tokens": 7680,
        "total_tokens": 10521,
        "latency": 3.296436548233032,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"f173342d-43a6-45ed-a4f8-0a461afd6368\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}, {\"id\": \"17d2d848-6190-4904-b5e2-daa7f6019c1d\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}, {\"id\": \"7bb8b439-fd14-4d61-85f2-97e68d999d49\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"2ecfdfdb-8d0d-411c-a51a-556b32cb1652\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"6ac67152-c814-440b-86ee-ca92f289ca64\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}]",
        "success": 1,
        "feedback_rating": "FAIL",
        "feedback_reason": "The response was cutoff, perhaps max token limit hit",
        "feedback_notes": "Perhpas we can tune by telling the model in the prompt to keep under the token limit, so it can \"know\" before preparing the response",
        "feedback_user": "Pastor",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "64d31370-6374-4960-8071-6738281d9ee8",
        "timestamp": "2025-04-13T19:21:28.546787",
        "question": "How many speakers this workshop has?",
        "response": "This workshop has at least two speakers: Hugo Bowne-Anderson and Philip Keeley.",
        "num_chunks": 5,
        "context_tokens": 2346,
        "completion_tokens": 20,
        "embedding_tokens": 7680,
        "total_tokens": 10046,
        "latency": 1.5577495098114014,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"87db7ffd-577f-4b36-a8a1-8b74ad3b12ea\", \"position\": 62, \"relevance\": 1.0, \"tokens\": 302, \"timestamp\": \"01:59:06.670\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:59:06.670]\\nPhilip Kiely: Thank you so much for having me. Thanks everyone for your time today.\\n\\nhugo bowne-anderson: Such a pleasure. Thanks, Philip.\\n\\nhugo bowne-anderson: and everyone else. It's it's time to time to wrap up. I just want to give Philip one more round of applause.\\n\\nGreat\\nhugo bowne-anderson: It is time to wrap up. We do have 2. As as I mentioned before, we have an just an onboarding form. A lot of you have completed it, but if you're if you haven't, and able to, this will allow us, it'll let us know where you are. What you're interested in, and it will allow us to set up the office hours that that we're going to with our wonderful builders in residence as well.\\n\\nOnce again I will share with you\\nhugo bowne-anderson: the feedback form. A bunch of you have already provided a lot of valuable feedback in there, which we'll use to iterate quickly on how we, how we teach and how we approach this course. I'm going to share that in the discord chat also.\\n\\nhugo bowne-anderson: So it's there. But that's it for today, and we'll see you on discord, and we'll see you in 46\\u00a0h for the next workshop as well. So thanks everyone, and thanks for a great 1st session.\"}, {\"id\": \"17d2d848-6190-4904-b5e2-daa7f6019c1d\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}, {\"id\": \"7bb8b439-fd14-4d61-85f2-97e68d999d49\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"0fde0e63-755f-4cf7-8622-bb80e5c9829d\", \"position\": 44, \"relevance\": 1.0, \"tokens\": 474, \"timestamp\": \"01:24:11.480\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:24:11.480]\\nhugo bowne-anderson: awesome. I appreciate that. So Philip. I wonder, Philip, are you on the call yet? By any chance?\\n\\nhugo bowne-anderson: Okay, you should be here in a few minutes. But Philip Philip Keeley, who's devrel at base 10 really, really fascinating dude does a lot of technical documentation and technical writing as well as published around that. He'll be giving a talk in a few minutes on moving Llm. Apps from prototype to production with with base 10. Please do not forget to claim your $1,000 free free credit, which I'm so grateful for that I've been able to provide.\\n\\nAnd you just have a look at all the types of things they have\\nhugo bowne-anderson: on their platform that you can deploy with a couple of clicks. To be honest, I really would love, and I,\\n\\nhugo bowne-anderson: because we have a few minutes now.\\n\\nhugo bowne-anderson: I would actually really love.\\n\\nI have a feedback form\\nhugo bowne-anderson: for each workshop. And so what you'll see here.\\n\\nhugo bowne-anderson: you know you put your email in. How did you rate the pace? What did you like most? What could we improve? Was there anything unclear or confusing? If so, what any other feedback or suggestions? I'm going to put that in the discord right now, and if you wouldn't mind just taking a few minutes now to complete it, there's far more chance of you actually completing it now than there is afterwards. I just statistically. So yeah, let's just take. Don't take more than 3\\n\\nmin\\nhugo bowne-anderson: to jot down a few things there when you rate the pace of the session also. Do note, this is the 1st one. So for some people it may totally have been too slow, and I get that, but it was the 1st session. So why don't everyone can take a couple of minutes to do that? And then when Philip joins we'll jump into his talk.\\n\\nhugo bowne-anderson: Stefan, William, Nathan, while people are doing that I'm wondering.\"}, {\"id\": \"f173342d-43a6-45ed-a4f8-0a461afd6368\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "It was accurate",
        "feedback_notes": null,
        "feedback_user": "Pastor",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information relevant to the question asked, as it does not address the specific topic of the workshop."
    },
    {
        "id": "e127b1bc-93ac-4074-bd95-f6d3ec2ce092",
        "timestamp": "2025-04-13T19:19:45.479465",
        "question": "what is this workshop about?",
        "response": "This workshop is about building software powered by machine learning and LLMS (large language models). It focuses on the foundations of LLMS software and evaluation-driven development. The workshop covers topics such as prompt engineering, embeddings, fine-tuning business logic, unit tests, versioning, continuous integration, monitoring, and evaluating LLMS outputs.",
        "num_chunks": 5,
        "context_tokens": 2510,
        "completion_tokens": 67,
        "embedding_tokens": 7680,
        "total_tokens": 10257,
        "latency": 1.2587931156158447,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"7bb8b439-fd14-4d61-85f2-97e68d999d49\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"17d2d848-6190-4904-b5e2-daa7f6019c1d\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}, {\"id\": \"f173342d-43a6-45ed-a4f8-0a461afd6368\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}, {\"id\": \"6ac67152-c814-440b-86ee-ca92f289ca64\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"2ecfdfdb-8d0d-411c-a51a-556b32cb1652\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "It was basically what I asked",
        "feedback_notes": null,
        "feedback_user": "Pastor",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, as it does not specify what the question was or what the response was."
    },
    {
        "id": "0c0e82f4-ed68-495e-b251-02f4d8ceee47",
        "timestamp": "2025-04-13T17:08:00.760186",
        "question": "Summarize the main points of this workshop in two to three sentences. ",
        "response": "In this workshop, the instructor discussed the use of Zoom and Discord for the workshops and encouraged participants to join the Discord channel for access to workshop materials. He also mentioned the course wiki, which contains information about the course schedule and resources. Additionally, the instructor mentioned the importance of setting up the code space before the workshop and provided an overview of the topics that will be covered in the next workshop. The workshop ended with a thank you to the guest speaker and reminders to fill out the onboarding form and provide feedback.",
        "num_chunks": 5,
        "context_tokens": 2373,
        "completion_tokens": 104,
        "embedding_tokens": 7680,
        "total_tokens": 10157,
        "latency": 1.6799943447113037,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"214b05d8-ae67-4338-a4f2-619f995a7805\", \"position\": 62, \"relevance\": 1.0, \"tokens\": 302, \"timestamp\": \"01:59:06.670\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:59:06.670]\\nPhilip Kiely: Thank you so much for having me. Thanks everyone for your time today.\\n\\nhugo bowne-anderson: Such a pleasure. Thanks, Philip.\\n\\nhugo bowne-anderson: and everyone else. It's it's time to time to wrap up. I just want to give Philip one more round of applause.\\n\\nGreat\\nhugo bowne-anderson: It is time to wrap up. We do have 2. As as I mentioned before, we have an just an onboarding form. A lot of you have completed it, but if you're if you haven't, and able to, this will allow us, it'll let us know where you are. What you're interested in, and it will allow us to set up the office hours that that we're going to with our wonderful builders in residence as well.\\n\\nOnce again I will share with you\\nhugo bowne-anderson: the feedback form. A bunch of you have already provided a lot of valuable feedback in there, which we'll use to iterate quickly on how we, how we teach and how we approach this course. I'm going to share that in the discord chat also.\\n\\nhugo bowne-anderson: So it's there. But that's it for today, and we'll see you on discord, and we'll see you in 46\\u00a0h for the next workshop as well. So thanks everyone, and thanks for a great 1st session.\"}, {\"id\": \"6573d1c4-505e-48b2-9c94-4faa61afec43\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}, {\"id\": \"29d4a365-6ca6-4cb4-a048-767e48f49499\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"c1e8e54b-54b7-47a6-802c-f5e7a0b95632\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"454de313-22fa-432f-bda1-e7cda0633ffe\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}]",
        "success": 1,
        "feedback_rating": null,
        "feedback_reason": null,
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "bbafea55-d21d-4bfb-a781-a18c961e1262",
        "timestamp": "2025-04-13T17:04:00.832520",
        "question": "What are the credits everyone gets or can apply for based on what was mentioned in the workshop? ",
        "response": "Based on the workshop transcript sections provided, it is mentioned that participants can claim $1,000 free credit from Base10.",
        "num_chunks": 5,
        "context_tokens": 2563,
        "completion_tokens": 26,
        "embedding_tokens": 7680,
        "total_tokens": 10269,
        "latency": 0.8359231948852539,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"c1e8e54b-54b7-47a6-802c-f5e7a0b95632\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"dd93c5ca-cc3a-457d-8fc6-843372841ccb\", \"position\": 8, \"relevance\": 1.0, \"tokens\": 497, \"timestamp\": \"00:19:54.940\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:19:54.940]\\nSo\\nhugo bowne-anderson: I hinted at this. But what this course isn't, it is not a deep dive into every Llm. Tool or trend. Of course we'll be doing. We'll be doing a bunch on agents actually, in the second half of the course, and rag and embeddings and more. But the focus is on workflows, not tools, I honestly think, and I'm happy to chat about those and message about those to be honest. But you will have enough resources on that. What we're teaching is what we'\\n\\nve really noticed is a huge gap\\nhugo bowne-anderson: in education around this stuff. This is not a plug and play AI recipe book. They don't even exist. If someone tries to tell you that or sell you that I'd love to hear it. What you'll learn is how to iterate, debug and adapt not just follow step by step. Templates. Okay, once again, this is not some, you know. Hyper, scaled, load balance, multi agent, guide. This course is about getting you moving, not solving every scaling challenge,\\n\\nbut really approaching the workflow\\nhugo bowne-anderson: of how to get things in production and then keep iterating on them.\\n\\nhugo bowne-anderson: So I'm gonna put this. This is incredibly important. This is an onboarding form that actually 25 of you have completed already. And I'm so happy with with that number so far. Usually, I try to say I try to give a form of 5 to 10\\u00a0min, but I honestly think if you all take 10 to 15\\u00a0min to complete this form. It will make this workshop and community really, really special. Okay.\\n\\nhugo bowne-anderson: so and so I just saw Jeff's note. That's in discord. That's that is brilliant.\\n\\nhugo bowne-anderson: And so I do think the the more we know about you and your interests, just because there are 5 of us now as as well. Right and geographically distributed, so the more we can we can be of help.\\n\\nhugo bowne-anderson: Jeff. Nathan has shared the course Wiki page, which we'll get to in a second,\\n\\nand part of that is\\nhugo bowne-anderson: the compute credit access form. Now I'\"}, {\"id\": \"41247f88-9189-4f9f-bc96-8277f8a48764\", \"position\": 44, \"relevance\": 1.0, \"tokens\": 474, \"timestamp\": \"01:24:11.480\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:24:11.480]\\nhugo bowne-anderson: awesome. I appreciate that. So Philip. I wonder, Philip, are you on the call yet? By any chance?\\n\\nhugo bowne-anderson: Okay, you should be here in a few minutes. But Philip Philip Keeley, who's devrel at base 10 really, really fascinating dude does a lot of technical documentation and technical writing as well as published around that. He'll be giving a talk in a few minutes on moving Llm. Apps from prototype to production with with base 10. Please do not forget to claim your $1,000 free free credit, which I'm so grateful for that I've been able to provide.\\n\\nAnd you just have a look at all the types of things they have\\nhugo bowne-anderson: on their platform that you can deploy with a couple of clicks. To be honest, I really would love, and I,\\n\\nhugo bowne-anderson: because we have a few minutes now.\\n\\nhugo bowne-anderson: I would actually really love.\\n\\nI have a feedback form\\nhugo bowne-anderson: for each workshop. And so what you'll see here.\\n\\nhugo bowne-anderson: you know you put your email in. How did you rate the pace? What did you like most? What could we improve? Was there anything unclear or confusing? If so, what any other feedback or suggestions? I'm going to put that in the discord right now, and if you wouldn't mind just taking a few minutes now to complete it, there's far more chance of you actually completing it now than there is afterwards. I just statistically. So yeah, let's just take. Don't take more than 3\\n\\nmin\\nhugo bowne-anderson: to jot down a few things there when you rate the pace of the session also. Do note, this is the 1st one. So for some people it may totally have been too slow, and I get that, but it was the 1st session. So why don't everyone can take a couple of minutes to do that? And then when Philip joins we'll jump into his talk.\\n\\nhugo bowne-anderson: Stefan, William, Nathan, while people are doing that I'm wondering.\"}, {\"id\": \"b648fa70-3520-49c1-9c49-dc544406e5ea\", \"position\": 27, \"relevance\": 1.0, \"tokens\": 474, \"timestamp\": \"00:57:20.840\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:57:20.840]\\nhugo bowne-anderson: Absolutely love it. And I also just noticed in the chat Vishut went. This is probably when I spoke about proof of concept purgatory. Vishrud has faced issues when he used Mvp. Without context. In North America it's used for most valuable player totally agree,\\n\\nand it shows how much\\nhugo bowne-anderson: how most people I speak with at least professionally work in tech and know what know that it means. That right?\\n\\nhugo bowne-anderson: awesome. Well, I'm just. I can't see everything in discord at the moment,\\n\\nbut so much fantastic conversation and\\nhugo bowne-anderson: questions as as well. So if anyone.\\n\\nhugo bowne-anderson: I'm gonna open a window right now. But if anyone doesn't have access to github,\\n\\ncould you\\nhugo bowne-anderson: just put your handle in the workshop? One channel and I will add you almost in real time.\\n\\nhugo bowne-anderson: And the reason for that is with Github has changed certain things so that I actually can't assign anyone else to be admin currently as it's under my personal.\\n\\nhugo bowne-anderson: Okay, we have Vinysh. Oh, oh,\\n\\nI love this and I do hope that\\nhugo bowne-anderson: you're all okay with us. Just taking 2\\n\\nmin to\\nhugo bowne-anderson: add a few more people. Oh, this is great.\\n\\nhugo bowne-anderson: amazing.\\n\\nNathan Danielsen: Well, while people are doing that, yeah. Want to comment on the the rich conversations that's happening in discord right now. And from the 1st kind of like run of this course. This is what that the conversations are. One of the highlights as well. So just calling that out. That's a lot of good stuff. A lot of smart people sharing resources there. So check out the discord for the session.\\n\\nhugo bowne-anderson: I really appreciate that. And in fact, I know it. I mean, we we started building this right to do a court. We actually started as a workshop in Austin last year, Stefan and myself,\"}, {\"id\": \"454de313-22fa-432f-bda1-e7cda0633ffe\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "Partially correct, since the names of the platforms were mentioned more than once during the workshop, and there is a typo with the BaseTen name. ",
        "feedback_notes": null,
        "feedback_user": "Abdalmalek (Malek)",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, as it seems to be a placeholder or an error message."
    },
    {
        "id": "95972824-985b-452f-8cfb-8690ca5def4e",
        "timestamp": "2025-04-13T16:54:58.835032",
        "question": "What are the credits everyone gets or can apply for based on what was mentioned in the workshop? ",
        "response": "Based on the workshop transcript sections provided, it is mentioned that participants can claim $1,000 free credit from Base10.",
        "num_chunks": 5,
        "context_tokens": 2563,
        "completion_tokens": 26,
        "embedding_tokens": 7680,
        "total_tokens": 10269,
        "latency": 1.1076393127441406,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"9be2ec8a-8152-4250-b43f-73060f745991\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"ce8c72de-d134-4b93-80cc-e8d5bb990c6e\", \"position\": 8, \"relevance\": 1.0, \"tokens\": 497, \"timestamp\": \"00:19:54.940\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:19:54.940]\\nSo\\nhugo bowne-anderson: I hinted at this. But what this course isn't, it is not a deep dive into every Llm. Tool or trend. Of course we'll be doing. We'll be doing a bunch on agents actually, in the second half of the course, and rag and embeddings and more. But the focus is on workflows, not tools, I honestly think, and I'm happy to chat about those and message about those to be honest. But you will have enough resources on that. What we're teaching is what we'\\n\\nve really noticed is a huge gap\\nhugo bowne-anderson: in education around this stuff. This is not a plug and play AI recipe book. They don't even exist. If someone tries to tell you that or sell you that I'd love to hear it. What you'll learn is how to iterate, debug and adapt not just follow step by step. Templates. Okay, once again, this is not some, you know. Hyper, scaled, load balance, multi agent, guide. This course is about getting you moving, not solving every scaling challenge,\\n\\nbut really approaching the workflow\\nhugo bowne-anderson: of how to get things in production and then keep iterating on them.\\n\\nhugo bowne-anderson: So I'm gonna put this. This is incredibly important. This is an onboarding form that actually 25 of you have completed already. And I'm so happy with with that number so far. Usually, I try to say I try to give a form of 5 to 10\\u00a0min, but I honestly think if you all take 10 to 15\\u00a0min to complete this form. It will make this workshop and community really, really special. Okay.\\n\\nhugo bowne-anderson: so and so I just saw Jeff's note. That's in discord. That's that is brilliant.\\n\\nhugo bowne-anderson: And so I do think the the more we know about you and your interests, just because there are 5 of us now as as well. Right and geographically distributed, so the more we can we can be of help.\\n\\nhugo bowne-anderson: Jeff. Nathan has shared the course Wiki page, which we'll get to in a second,\\n\\nand part of that is\\nhugo bowne-anderson: the compute credit access form. Now I'\"}, {\"id\": \"2997eb7d-76de-42f6-84d3-fbac03f3e30b\", \"position\": 44, \"relevance\": 1.0, \"tokens\": 474, \"timestamp\": \"01:24:11.480\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:24:11.480]\\nhugo bowne-anderson: awesome. I appreciate that. So Philip. I wonder, Philip, are you on the call yet? By any chance?\\n\\nhugo bowne-anderson: Okay, you should be here in a few minutes. But Philip Philip Keeley, who's devrel at base 10 really, really fascinating dude does a lot of technical documentation and technical writing as well as published around that. He'll be giving a talk in a few minutes on moving Llm. Apps from prototype to production with with base 10. Please do not forget to claim your $1,000 free free credit, which I'm so grateful for that I've been able to provide.\\n\\nAnd you just have a look at all the types of things they have\\nhugo bowne-anderson: on their platform that you can deploy with a couple of clicks. To be honest, I really would love, and I,\\n\\nhugo bowne-anderson: because we have a few minutes now.\\n\\nhugo bowne-anderson: I would actually really love.\\n\\nI have a feedback form\\nhugo bowne-anderson: for each workshop. And so what you'll see here.\\n\\nhugo bowne-anderson: you know you put your email in. How did you rate the pace? What did you like most? What could we improve? Was there anything unclear or confusing? If so, what any other feedback or suggestions? I'm going to put that in the discord right now, and if you wouldn't mind just taking a few minutes now to complete it, there's far more chance of you actually completing it now than there is afterwards. I just statistically. So yeah, let's just take. Don't take more than 3\\n\\nmin\\nhugo bowne-anderson: to jot down a few things there when you rate the pace of the session also. Do note, this is the 1st one. So for some people it may totally have been too slow, and I get that, but it was the 1st session. So why don't everyone can take a couple of minutes to do that? And then when Philip joins we'll jump into his talk.\\n\\nhugo bowne-anderson: Stefan, William, Nathan, while people are doing that I'm wondering.\"}, {\"id\": \"0781399a-0b05-4dda-84a2-ceb1f3cc1040\", \"position\": 27, \"relevance\": 1.0, \"tokens\": 474, \"timestamp\": \"00:57:20.840\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:57:20.840]\\nhugo bowne-anderson: Absolutely love it. And I also just noticed in the chat Vishut went. This is probably when I spoke about proof of concept purgatory. Vishrud has faced issues when he used Mvp. Without context. In North America it's used for most valuable player totally agree,\\n\\nand it shows how much\\nhugo bowne-anderson: how most people I speak with at least professionally work in tech and know what know that it means. That right?\\n\\nhugo bowne-anderson: awesome. Well, I'm just. I can't see everything in discord at the moment,\\n\\nbut so much fantastic conversation and\\nhugo bowne-anderson: questions as as well. So if anyone.\\n\\nhugo bowne-anderson: I'm gonna open a window right now. But if anyone doesn't have access to github,\\n\\ncould you\\nhugo bowne-anderson: just put your handle in the workshop? One channel and I will add you almost in real time.\\n\\nhugo bowne-anderson: And the reason for that is with Github has changed certain things so that I actually can't assign anyone else to be admin currently as it's under my personal.\\n\\nhugo bowne-anderson: Okay, we have Vinysh. Oh, oh,\\n\\nI love this and I do hope that\\nhugo bowne-anderson: you're all okay with us. Just taking 2\\n\\nmin to\\nhugo bowne-anderson: add a few more people. Oh, this is great.\\n\\nhugo bowne-anderson: amazing.\\n\\nNathan Danielsen: Well, while people are doing that, yeah. Want to comment on the the rich conversations that's happening in discord right now. And from the 1st kind of like run of this course. This is what that the conversations are. One of the highlights as well. So just calling that out. That's a lot of good stuff. A lot of smart people sharing resources there. So check out the discord for the session.\\n\\nhugo bowne-anderson: I really appreciate that. And in fact, I know it. I mean, we we started building this right to do a court. We actually started as a workshop in Austin last year, Stefan and myself,\"}, {\"id\": \"4f926ec6-b5d0-444b-bcfc-6766429a1538\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}]",
        "success": 1,
        "feedback_rating": null,
        "feedback_reason": null,
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "0b371520-76ff-46c1-b400-25fc4b2ea8fb",
        "timestamp": "2025-04-13T16:51:34.508961",
        "question": "How many attended this workshop? I believe Hugo mentioned that at the beginning of the workshop. ",
        "response": "I'm sorry, but I couldn't find any information about the number of attendees in the provided sections of the workshop transcript.",
        "num_chunks": 5,
        "context_tokens": 2383,
        "completion_tokens": 26,
        "embedding_tokens": 7680,
        "total_tokens": 10089,
        "latency": 0.8055431842803955,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"74cd6888-fa5a-408a-a247-19a64c0f40e4\", \"position\": 62, \"relevance\": 1.0, \"tokens\": 302, \"timestamp\": \"01:59:06.670\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:59:06.670]\\nPhilip Kiely: Thank you so much for having me. Thanks everyone for your time today.\\n\\nhugo bowne-anderson: Such a pleasure. Thanks, Philip.\\n\\nhugo bowne-anderson: and everyone else. It's it's time to time to wrap up. I just want to give Philip one more round of applause.\\n\\nGreat\\nhugo bowne-anderson: It is time to wrap up. We do have 2. As as I mentioned before, we have an just an onboarding form. A lot of you have completed it, but if you're if you haven't, and able to, this will allow us, it'll let us know where you are. What you're interested in, and it will allow us to set up the office hours that that we're going to with our wonderful builders in residence as well.\\n\\nOnce again I will share with you\\nhugo bowne-anderson: the feedback form. A bunch of you have already provided a lot of valuable feedback in there, which we'll use to iterate quickly on how we, how we teach and how we approach this course. I'm going to share that in the discord chat also.\\n\\nhugo bowne-anderson: So it's there. But that's it for today, and we'll see you on discord, and we'll see you in 46\\u00a0h for the next workshop as well. So thanks everyone, and thanks for a great 1st session.\"}, {\"id\": \"4305b944-4351-4d48-ac5c-8fc64e475ee6\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"11f36767-2292-4f9a-8220-0c79d18ddb8d\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"bfb6a9db-5631-4184-9483-204554dd69c9\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}, {\"id\": \"28a136e6-2783-4d4b-8b7e-c353b6f4f472\", \"position\": 27, \"relevance\": 1.0, \"tokens\": 474, \"timestamp\": \"00:57:20.840\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:57:20.840]\\nhugo bowne-anderson: Absolutely love it. And I also just noticed in the chat Vishut went. This is probably when I spoke about proof of concept purgatory. Vishrud has faced issues when he used Mvp. Without context. In North America it's used for most valuable player totally agree,\\n\\nand it shows how much\\nhugo bowne-anderson: how most people I speak with at least professionally work in tech and know what know that it means. That right?\\n\\nhugo bowne-anderson: awesome. Well, I'm just. I can't see everything in discord at the moment,\\n\\nbut so much fantastic conversation and\\nhugo bowne-anderson: questions as as well. So if anyone.\\n\\nhugo bowne-anderson: I'm gonna open a window right now. But if anyone doesn't have access to github,\\n\\ncould you\\nhugo bowne-anderson: just put your handle in the workshop? One channel and I will add you almost in real time.\\n\\nhugo bowne-anderson: And the reason for that is with Github has changed certain things so that I actually can't assign anyone else to be admin currently as it's under my personal.\\n\\nhugo bowne-anderson: Okay, we have Vinysh. Oh, oh,\\n\\nI love this and I do hope that\\nhugo bowne-anderson: you're all okay with us. Just taking 2\\n\\nmin to\\nhugo bowne-anderson: add a few more people. Oh, this is great.\\n\\nhugo bowne-anderson: amazing.\\n\\nNathan Danielsen: Well, while people are doing that, yeah. Want to comment on the the rich conversations that's happening in discord right now. And from the 1st kind of like run of this course. This is what that the conversations are. One of the highlights as well. So just calling that out. That's a lot of good stuff. A lot of smart people sharing resources there. So check out the discord for the session.\\n\\nhugo bowne-anderson: I really appreciate that. And in fact, I know it. I mean, we we started building this right to do a court. We actually started as a workshop in Austin last year, Stefan and myself,\"}]",
        "success": 1,
        "feedback_rating": null,
        "feedback_reason": null,
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "ddc8251f-acf4-46e2-8c4e-7e962966c6f2",
        "timestamp": "2025-04-13T05:45:42.604366",
        "question": "Is evaluation driven development mentioned in this workshop at all? If so, how many times?",
        "response": "Evaluation driven development is mentioned multiple times in the workshop transcript sections provided. It is mentioned in the following sections:\n\n1. [TIMESTAMP: 00:16:06.360] - Hugo Bowne-Anderson mentions the importance of evaluation driven development in building software powered by machine learning and Llms.\n\n2. [TIMESTAMP: 00:36:47.170] - Hugo Bowne-Anderson introduces evaluation driven development as the way out of \"proof of concept purgatory\" and explains the iterative loop of building, monitoring, evaluating, and improving.\n\n3. [TIMESTAMP: 00:38:30.480] - Hugo Bowne-Anderson discusses the process of building a synthetic data set and evaluation harnesses for evaluation before real users exist.\n\n4. [TIMESTAMP: 00:52:20.970] - Hugo Bowne-Anderson compares evaluation driven development with traditional ML development and emphasizes the iterative nature of building and improving software.\n\n5. [TIMESTAMP: 01:22:16.770] - Hugo Bowne-Anderson mentions that the next week's workshop will focus on iteration, evaluation, and observability, further highlighting the importance of evaluation driven development.\n\nIn total, evaluation driven development is mentioned at least five times in the provided sections.",
        "num_chunks": 5,
        "context_tokens": 2443,
        "completion_tokens": 267,
        "embedding_tokens": 7680,
        "total_tokens": 10390,
        "latency": 4.445987701416016,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"e2939ea1-ac6b-41ba-a219-b1c51a395691\", \"position\": 16, \"relevance\": 1.0, \"tokens\": 402, \"timestamp\": \"00:36:47.170\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:36:47.170]\\nhugo bowne-anderson: not because the system is bad and at all right. So that's what we're here to really talk about. I do want to frame most things in terms of evaluation, driven development, although we'll we'll dovetail out of a lot of different different topics. Okay.\\n\\nhugo bowne-anderson:\\n\\nso\\nhugo bowne-anderson: our way out is Edd, evaluation, driven development. Where you have a iterative loop right where you build, you monitor, you evaluate, you improve now.\\n\\nhugo bowne-anderson: even before launching a product. And this is something we'll talk about as the course goes on. You can, you can build a synthetic data set and evaluation harnesses to help you even before real users exist. And if you don't know what an evaluation harness is, don't worry about it. It's essentially a script, something reproducible that you use to evaluate your system. So one example I like to give is.\\n\\nhugo bowne-anderson: I was working on something recently where we were using Gpt. 4.0 Mini, and then Google released Gemini 2.5. And we wanted to play around with it. And it was like, Okay, I'm going to switch this out. But how do I even know beyond vibes that it'\\n\\ns going to be\\nhugo bowne-anderson: good or not? So if you have a basic harness with a few tests, measuring latency and cost and things of business interest as well. This can get you a long way. So at the start, I actually encourage people to build what I call an Mve. So for any Mvp minimum viable product, you have an Mve a minimum viable evaluation as well. Right?\\n\\nhugo bowne-anderson: So just thinking through kind of how this happens. You have an Mvp, you have synthetic user queries.\"}, {\"id\": \"0149019d-1d94-4aa7-8135-3ec670221258\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"5f19e847-115d-4e63-b126-bd41e29af8e2\", \"position\": 24, \"relevance\": 1.0, \"tokens\": 482, \"timestamp\": \"00:52:20.970\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:52:20.970]\\nhugo bowne-anderson: and then perhaps you monitor for a while, figure out what's up, make some small changes, whatever it is. And then you start working on the next version, and there will be version releases. Then, right? So you will start working again and iterating.\\n\\nhugo bowne-anderson: based on what you how you see your software is performing. But the point is that you're iterating on the next version of it as opposed to having something continuously changing and continuously iterating.\\n\\nhugo bowne-anderson:\\n\\nSo we have software specs\\nhugo bowne-anderson: for Llm. Powered applications right? And this is an iterative process that spans development and production. You have software specs, you build, you deploy your value, you monitor and evaluate, including all of these things that I really I mentioned at the start of this workshop which we'll get into in this course.\\n\\nhugo bowne-anderson:\\n\\nSo\\nhugo bowne-anderson: the question I said at the start, how do we get out of aic a a Oc AI poc, I actually should change that because someone said someone actually said to me, they didn't know what a proof of concept was, and they thought I was using the term person of color purgatory.\\n\\nAnd I I definitely have never intended that so I probably should should change that\\nhugo bowne-anderson: So the 1st challenge non-determinism. How do we deal with that? We log inputs and outputs. We evaluate logs. We iterate on prompts and context, we use Api knobs to reduce variance.\\n\\nhugo bowne-anderson: How about the challenge of hallucinations?\\n\\nhugo bowne-anderson: Well, similarly, we log inputs and outputs in dev and prod, we use domain specific expertise to evaluate output. In both, we build systems and processes to automate assessments such as unit tests and data sets. So testing sets product feedback hooks. Similarly, for for evaluation.\\n\\nhugo bowne-anderson: for iteration, we build a software development lifecycle that enables you to quickly build, deploy, monitor and evaluate. And in terms of business value. We really need to align outputs with business metric and optimize workflows to achieve measurable return on investment.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"bbcd0c88-4e57-4215-9f05-f7a6914a9ccd\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"72ddeacb-d4fe-45d7-a92a-c5e8afcfb6ef\", \"position\": 17, \"relevance\": 1.0, \"tokens\": 460, \"timestamp\": \"00:38:30.480\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:38:30.480]\\nhugo bowne-anderson: You get the Mvp to give you responses, label them by hand, use the label data to build a basic evaluation harness, for example. And we'll get to all of this a test set and Llm. As a judge. And then we use the Mve to evaluate and improve your Mvp. I do want to. Just briefly, we'll get into this a lot later in the course, disambiguate Llm. As a judge. It's a term that people like. Oh, that must be, you know, really sophisticated.\\n\\nWhatever\\nhugo bowne-anderson: the truth is, they can be, and should be as you go on. But essentially what you're doing is you've got a bunch of traces you want to evaluate in some way. You've done a bunch hand labeling as a human that doesn't scale. So you give an Llm.\\n\\nA prompt\\nhugo bowne-anderson: and a bunch of perhaps positive and negative examples and some heuristics for evaluating, and you get it to perform the evaluation for you, and of course something we'll get to is then how to align. One of the most important things is aligning the Lm. As a judge with your own evaluation. But that's kind of just a brief detour on that. I do want to say.\\n\\nhugo bowne-anderson: Evaluation driven development isn't. New people have been building Ml. Software. Well, I've been doing it for years. If you tell me that the original Google search didn't use evaluation driven development. I'd say what? What the heck you're talking about? Because clearly they were using in like highly sophisticated monitoring and evaluation in in order to rapidly iterate on on that product.\\n\\nSo\\nhugo bowne-anderson: essentially in machine learning, we've had Mvps and collected data. Then we've labeled responses by hand. Then we use the labeled data to build a basic evaluation system. But in this case it's a test set right. And then we use this Mve to evaluate and improve your Mvp. So just to compare Eval and building with Llms versus traditional. Ml.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "Wow, this is way better than I thought it would be. I literally haven't fact checked these time stamps, but it sounds about right. It's huge here. What's more interesting is even like the third one, for example, doesn't even mention evaluation driven development as a term, but it says evaluation harnesses for evaluation before real users exist. So, looks like the system is recognizing that we're discussing Edd without explicitly using that term which I think is pretty pretty cool.",
        "feedback_notes": null,
        "feedback_user": "hugo",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information about the question asked, as it does not specify what the question was or what the response was."
    },
    {
        "id": "78d8bec5-dc92-452d-bf7f-8188d9dfe08f",
        "timestamp": "2025-04-13T05:44:26.525779",
        "question": "What are the first principles of LLM app development discussed in this workshop?",
        "response": "The first principles of LLM app development discussed in this workshop include:\n1. Building quickly, deploying, monitoring, evaluating, and iterating rapidly.\n2. Considering prompt engineering, embeddings, fine-tuning business logic, unit tests, versioning, and continuous integration during deployment.\n3. Thinking about tracing and general observability when monitoring and evaluating.\n4. Recognizing the non-deterministic nature of LLMs.\n5. Aligning outputs with business metrics and optimizing workflows to achieve measurable return on investment.\n6. Logging inputs and outputs, evaluating logs, and iterating on prompts and context to deal with non-determinism.\n7. Using domain-specific expertise to evaluate output and building systems and processes to automate assessments for dealing with hallucinations.\n8. Building a software development lifecycle that enables quick building, deploying, monitoring, and evaluating.\n9. Defining metrics for success, setting up feedback loops, and optimizing observability for production.\n10. Emphasizing first principles rather than being tool-specific to allow for adaptation to different work environments.",
        "num_chunks": 5,
        "context_tokens": 2402,
        "completion_tokens": 210,
        "embedding_tokens": 7680,
        "total_tokens": 10292,
        "latency": 2.1176435947418213,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"bbcd0c88-4e57-4215-9f05-f7a6914a9ccd\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"2771e6bb-eef3-43c5-bde5-4ce78f4e675a\", \"position\": 22, \"relevance\": 1.0, \"tokens\": 401, \"timestamp\": \"00:48:18.740\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:48:18.740]\\nAnd\\nhugo bowne-anderson: the answer, the answers come in the in the process that we're here to teach you about in this entire course. And one thing to understand is kind of the flow of the system.\\n\\nSo\\nhugo bowne-anderson: we have our upstream prompt and context being sent to an Llm. Then we have the Llm output, and this being consumed downstream in a variety of ways.\\n\\nhugo bowne-anderson: So what type of principles do we need to really think about then. And another way to frame what we're doing here is, of course, we're using tools the entire time. But we're not tool focused. We're, we're principle focused.\\n\\nAnd\\nhugo bowne-anderson: one of the reasons that'\\n\\ns the case is\\nhugo bowne-anderson: we wanna help you develop skills and adopt tools that we'\\n\\nll be around in\\nhugo bowne-anderson: several years. And I honestly can't guarantee you whether Langchain or Llama Index or crew, AI or any of these things will be around to be honest. But what Stefan and myself and a lot of our community are taking a bet on is that the principles that we learned building machine learning software for years and have started to use building Llm powered software, they will stick around.\\n\\nAnd so\\nhugo bowne-anderson: the 1st principle to recognize is upstream. You have these Api calls you have input and output. And you have knobs. You can tweak there. Right? You have system and user prompts. You have context, right? You have structured outputs, and you have a variety of knobs, such as temperature and top P, which we'll get to later this week.\\n\\nhugo bowne-anderson: Another principle and this is a foundational principle. All of these are is that Llms are non-deterministic.\"}, {\"id\": \"0149019d-1d94-4aa7-8135-3ec670221258\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"5f19e847-115d-4e63-b126-bd41e29af8e2\", \"position\": 24, \"relevance\": 1.0, \"tokens\": 482, \"timestamp\": \"00:52:20.970\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:52:20.970]\\nhugo bowne-anderson: and then perhaps you monitor for a while, figure out what's up, make some small changes, whatever it is. And then you start working on the next version, and there will be version releases. Then, right? So you will start working again and iterating.\\n\\nhugo bowne-anderson: based on what you how you see your software is performing. But the point is that you're iterating on the next version of it as opposed to having something continuously changing and continuously iterating.\\n\\nhugo bowne-anderson:\\n\\nSo we have software specs\\nhugo bowne-anderson: for Llm. Powered applications right? And this is an iterative process that spans development and production. You have software specs, you build, you deploy your value, you monitor and evaluate, including all of these things that I really I mentioned at the start of this workshop which we'll get into in this course.\\n\\nhugo bowne-anderson:\\n\\nSo\\nhugo bowne-anderson: the question I said at the start, how do we get out of aic a a Oc AI poc, I actually should change that because someone said someone actually said to me, they didn't know what a proof of concept was, and they thought I was using the term person of color purgatory.\\n\\nAnd I I definitely have never intended that so I probably should should change that\\nhugo bowne-anderson: So the 1st challenge non-determinism. How do we deal with that? We log inputs and outputs. We evaluate logs. We iterate on prompts and context, we use Api knobs to reduce variance.\\n\\nhugo bowne-anderson: How about the challenge of hallucinations?\\n\\nhugo bowne-anderson: Well, similarly, we log inputs and outputs in dev and prod, we use domain specific expertise to evaluate output. In both, we build systems and processes to automate assessments such as unit tests and data sets. So testing sets product feedback hooks. Similarly, for for evaluation.\\n\\nhugo bowne-anderson: for iteration, we build a software development lifecycle that enables you to quickly build, deploy, monitor and evaluate. And in terms of business value. We really need to align outputs with business metric and optimize workflows to achieve measurable return on investment.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"69781028-0ce8-4c2b-bf0e-9c2c6177188d\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "Yeah, this is great. I just, um, I would like to see less first principles. I mean, there are five we have explicitly. Also, so I think this is very good. It just may be too much, but I'm giving it a pass.",
        "feedback_notes": null,
        "feedback_user": "hugo",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, as it does not specify what the question was or what the response was."
    },
    {
        "id": "e873bfdd-a6fb-4014-8c1c-f182aa821a64",
        "timestamp": "2025-04-12T19:16:10.533200",
        "question": "What are some examples of applications you can build with LLMs?",
        "response": "Some examples of applications you can build with LLMs include:\n- An app that consumes LinkedIn profiles to find relevant candidates for a position and automates emails to them.\n- Audio transcription using models like Whisper.\n- Building chatbot agents using models like RAG.\n- Text embedding models for applications like Chroma or Pinecone.\n- Speech synthesis using speech synthesis models.",
        "num_chunks": 5,
        "context_tokens": 2395,
        "completion_tokens": 75,
        "embedding_tokens": 7680,
        "total_tokens": 10150,
        "latency": 2.468024730682373,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"9f56e13d-a740-4677-92ff-615aff19d685\", \"position\": 56, \"relevance\": 1.0, \"tokens\": 461, \"timestamp\": \"01:46:58.890\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:46:58.890]\\nI just click the view repository link\\nPhilip Kiely: and I got into the trust examples. So this is, you know, hundreds and hundreds of model implementations that we've made. And this lets me start to get into the tensor. Otllm build configuration. So in this case, you know, I have details around like how many Gpus, I'm using my tensor parallel count. I have different plugins that I can turn it off and on different sequence lengths. I can also,\\n\\nI should have\\nPhilip Kiely: hold this one up ahead of time.\\n\\nPhilip Kiely: yeah. I can also, for example, find one that is using speculative decoding.\\n\\nSo\\nPhilip Kiely: I can, you know. Add a speculator model to this same kind of config.\\n\\nSo I can basically\\nPhilip Kiely: add a and and all all this, by the way, is in the documentation. I can add a smaller model and try and see how much performance lift. I get on. You know, one type of input versus another type, because speculative decoding is, of course, very dependent on the actual input that you're putting in here. So yes. So with with this, you can actually do a lot more to kind of experiment with these different models.\\n\\nPhilip Kiely: and and the different levers that are available to you in dedicated deployments. The other thing I would really encourage you to do is go beyond just language models and think about what you can build from more of a multimodal sense. I know this course is maybe called. I think Llm. Is in the title of this course, but there's a lot of great models outside of Llms.\\n\\nPhilip Kiely: whisper is, of course, a great model to play with for audio transcription. If you want to build rag and agents. We just published a bunch of new text embedding models. Using a new optimized embedding runtime, which is twice as fast as Tei or Vlm or other industry standards. So you can, you know,\\n\\nuse this for something like chroma or pinecone\\nPhilip Kiely: or Mongodb and build, you know, rag and agent type stuff. We have really great speech speech synthesis models. Where is it?\"}, {\"id\": \"913e5112-3fde-48da-a2a6-aef4f9d486ac\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"7c9c7a0e-54b9-4893-a695-61994642ed08\", \"position\": 22, \"relevance\": 1.0, \"tokens\": 401, \"timestamp\": \"00:48:18.740\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:48:18.740]\\nAnd\\nhugo bowne-anderson: the answer, the answers come in the in the process that we're here to teach you about in this entire course. And one thing to understand is kind of the flow of the system.\\n\\nSo\\nhugo bowne-anderson: we have our upstream prompt and context being sent to an Llm. Then we have the Llm output, and this being consumed downstream in a variety of ways.\\n\\nhugo bowne-anderson: So what type of principles do we need to really think about then. And another way to frame what we're doing here is, of course, we're using tools the entire time. But we're not tool focused. We're, we're principle focused.\\n\\nAnd\\nhugo bowne-anderson: one of the reasons that'\\n\\ns the case is\\nhugo bowne-anderson: we wanna help you develop skills and adopt tools that we'\\n\\nll be around in\\nhugo bowne-anderson: several years. And I honestly can't guarantee you whether Langchain or Llama Index or crew, AI or any of these things will be around to be honest. But what Stefan and myself and a lot of our community are taking a bet on is that the principles that we learned building machine learning software for years and have started to use building Llm powered software, they will stick around.\\n\\nAnd so\\nhugo bowne-anderson: the 1st principle to recognize is upstream. You have these Api calls you have input and output. And you have knobs. You can tweak there. Right? You have system and user prompts. You have context, right? You have structured outputs, and you have a variety of knobs, such as temperature and top P, which we'll get to later this week.\\n\\nhugo bowne-anderson: Another principle and this is a foundational principle. All of these are is that Llms are non-deterministic.\"}, {\"id\": \"7175c405-254c-460c-95c2-520370f51147\", \"position\": 17, \"relevance\": 1.0, \"tokens\": 460, \"timestamp\": \"00:38:30.480\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:38:30.480]\\nhugo bowne-anderson: You get the Mvp to give you responses, label them by hand, use the label data to build a basic evaluation harness, for example. And we'll get to all of this a test set and Llm. As a judge. And then we use the Mve to evaluate and improve your Mvp. I do want to. Just briefly, we'll get into this a lot later in the course, disambiguate Llm. As a judge. It's a term that people like. Oh, that must be, you know, really sophisticated.\\n\\nWhatever\\nhugo bowne-anderson: the truth is, they can be, and should be as you go on. But essentially what you're doing is you've got a bunch of traces you want to evaluate in some way. You've done a bunch hand labeling as a human that doesn't scale. So you give an Llm.\\n\\nA prompt\\nhugo bowne-anderson: and a bunch of perhaps positive and negative examples and some heuristics for evaluating, and you get it to perform the evaluation for you, and of course something we'll get to is then how to align. One of the most important things is aligning the Lm. As a judge with your own evaluation. But that's kind of just a brief detour on that. I do want to say.\\n\\nhugo bowne-anderson: Evaluation driven development isn't. New people have been building Ml. Software. Well, I've been doing it for years. If you tell me that the original Google search didn't use evaluation driven development. I'd say what? What the heck you're talking about? Because clearly they were using in like highly sophisticated monitoring and evaluation in in order to rapidly iterate on on that product.\\n\\nSo\\nhugo bowne-anderson: essentially in machine learning, we've had Mvps and collected data. Then we've labeled responses by hand. Then we use the labeled data to build a basic evaluation system. But in this case it's a test set right. And then we use this Mve to evaluate and improve your Mvp. So just to compare Eval and building with Llms versus traditional. Ml.\"}, {\"id\": \"aa8cfb30-890f-42e8-8918-82c57f52b2eb\", \"position\": 21, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:46:30.010\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:46:30.010]\\nI do want to just take a quick\\nhugo bowne-anderson: detour when we're talking about.\\n\\nhugo bowne-anderson:\\n\\nYou know\\nhugo bowne-anderson: what we get use out of all of these things, for the conversational aspect of Llms is fantastic. I use it all the time. But in my humble estimation most roi will involve automation, not conversations. So, for example, an app that consumes Linkedin profiles finds relevant candidates for a position automates emails to them. That's 1 example that the demo I just showed you perhaps could could be used for.\\n\\nAnd this brings me to my point of and our point of\\nhugo bowne-anderson: really thinking about what we want to evaluate. Okay, so what's cool, you can ask, is the information extracts from Linkedin? Correct? That's a cool question to ask and important, that needs to be satisfied. But remember, we're trying to scale human behavior so, and we want it to result in the same outcomes. But better right? So the next question you might ask, do the emails generated resemble the emails domain experts sent previously.\\n\\nhugo bowne-anderson: also a good question to ask, and who would have thought trying to get a domain expert involved would be so so useful.\\n\\nBut it turns out it is now\\nhugo bowne-anderson: at a very macro level,\\n\\nthough\\nhugo bowne-anderson: you really want to know? Do the emails result in hiring good candidates? And is it more efficient and more cost effective than our previous system right? And it's actually not even clear how long these cycles are.\\n\\nSo making sure that we in the end tie these macro level\\nhugo bowne-anderson: business evaluations to the micro level Llm calls is super important.\\n\\nhugo bowne-anderson: So that brings us back to this. How do we? How do we evaluate a system like this? I don't know what the actual prompt sent to the Llm. Was. How do I give feedback on on system performance? How can I see data and traces and conversations? How can we iterate quickly on this? Mvp.\\n\\nhugo bowne-anderson:\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "Good list of examples",
        "feedback_notes": null,
        "feedback_user": "Greg Gandenberger",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, as it does not specify what the question was or what the response was."
    },
    {
        "id": "02d9d689-dd90-4bd8-92e1-9d75ce587acf",
        "timestamp": "2025-04-12T19:15:04.895751",
        "question": "What app are we building in the course?",
        "response": "Based on the provided sections of the workshop transcript, it is not explicitly mentioned what app is being built in the course.",
        "num_chunks": 5,
        "context_tokens": 2475,
        "completion_tokens": 25,
        "embedding_tokens": 7680,
        "total_tokens": 10180,
        "latency": 1.1974365711212158,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"913e5112-3fde-48da-a2a6-aef4f9d486ac\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"e7e05d7d-7faf-411b-a3ae-6f65a7697ca7\", \"position\": 11, \"relevance\": 1.0, \"tokens\": 445, \"timestamp\": \"00:26:25.726\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:26:25.726]\\nhugo bowne-anderson: Pretty, please do that.\\n\\nhugo bowne-anderson:\\n\\nand I just encourage you all to\\nhugo bowne-anderson: use. I mean, use these tools as much as you can while building during the course, because we're here to support and talk about them and and build with you. I do want to say I do appreciate. Everyone likely has more than full time, jobs and families, and all of these things or subsets of these. So I do understand, particularly in our line of work.\\n\\nTime is an incredibly precious\\nhugo bowne-anderson: resource.\\n\\nSo\\nhugo bowne-anderson: all that's to say is, if you don't have much time to build outside, that's totally cool. If you, if all you do is attend these workshops and nothing else. You'll get a huge amount out of the course if you keep building also, and keep in the discords, and then join the office. Hours and pods will set up, you'll get even even more so. I like to think the world's your oyster in proverbial oyster in a lot of ways.\\n\\nSo just getting started in terms of\\nhugo bowne-anderson: set up.\\n\\nhugo bowne-anderson: We use several tools, and my goal is to use as few tools as possible.\\n\\nI will rarely adopt a new tool\\nhugo bowne-anderson: if I don't have to. So in the past we used in the first.st So in the 1st cohort, we use Google drive. This is for slides supporting material. This type of stuff we use github and codespaces for code and also codespaces, feel free to clone the repository and do what you want with it, but we want to make sure that you can get set up and up and running as quickly as possible, and I'll introduce you to code spaces later. It'\\n\\ns kind of\\nhugo bowne-anderson: Google colab on steroids or Vs code superpowered in the browser. We use discord for the Async Chat announcements, and the Q.\"}, {\"id\": \"abb00949-53b6-45ef-b2e7-acabe2f6e901\", \"position\": 38, \"relevance\": 1.0, \"tokens\": 497, \"timestamp\": \"01:12:59.773\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:12:59.773]\\nhugo bowne-anderson: Now that we've closed this app, I don't know what happened there. I've got no visibility into it, and I can't share it with you. So after giving something something a front end, I do very much encourage everyone to add some basic logging to your system, and it once again, in doing an Mvp. This can be incredibly simple, right? And in this python 3 app log.\\n\\nWe do so by\\nhugo bowne-anderson: just creating a local sqlite database. You can even do it just to Json, if you want, I decided to go a bit more. I'm a huge fan of sqlite to be honest. But where? So that means in 82 lines of code, we've got our.\\n\\nhugo bowne-anderson: you know, rag system. We'\\n\\nve got our front end\\nhugo bowne-anderson: and we have some logging, basic logging as well. So let's now just have a look at how that works, and then I'll show you ways to think about the logging, or how how to introspect into it.\\n\\nhugo bowne-anderson: So the other thing I didn't mention before is that if you use share is equal to true in launch for gradio, you can create a public link. So when William actually created a gradio app for us to play around with. Recently, that was hosted on modal when preparing some of this course. He just shared. He put share is equal to true, and that meant I could access from Australia. The app he'd just built, which I do. I don'\\n\\nt want to like\\nhugo bowne-anderson: get too too serious. But I the fact that William in DC. Can spin this up, and I can access it. And immediately in Sydney, Australia is absolutely absolutely wild. So I'm gonna ask.\\n\\nhugo bowne-anderson: who is this person?\\n\\nAnd what do they\\nhugo bowne-anderson: do? Our pasta has a great question. What? What model am I using? And I'm actually using Openai. Gpt. 4. 0, I think it's actually once again, though, whatever the default in llama index is, I don't know. Like, maybe that changed then, right? And I don't know.\"}, {\"id\": \"e6da8e9b-62ea-4a2b-b80c-18f0fee37c1a\", \"position\": 8, \"relevance\": 1.0, \"tokens\": 497, \"timestamp\": \"00:19:54.940\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:19:54.940]\\nSo\\nhugo bowne-anderson: I hinted at this. But what this course isn't, it is not a deep dive into every Llm. Tool or trend. Of course we'll be doing. We'll be doing a bunch on agents actually, in the second half of the course, and rag and embeddings and more. But the focus is on workflows, not tools, I honestly think, and I'm happy to chat about those and message about those to be honest. But you will have enough resources on that. What we're teaching is what we'\\n\\nve really noticed is a huge gap\\nhugo bowne-anderson: in education around this stuff. This is not a plug and play AI recipe book. They don't even exist. If someone tries to tell you that or sell you that I'd love to hear it. What you'll learn is how to iterate, debug and adapt not just follow step by step. Templates. Okay, once again, this is not some, you know. Hyper, scaled, load balance, multi agent, guide. This course is about getting you moving, not solving every scaling challenge,\\n\\nbut really approaching the workflow\\nhugo bowne-anderson: of how to get things in production and then keep iterating on them.\\n\\nhugo bowne-anderson: So I'm gonna put this. This is incredibly important. This is an onboarding form that actually 25 of you have completed already. And I'm so happy with with that number so far. Usually, I try to say I try to give a form of 5 to 10\\u00a0min, but I honestly think if you all take 10 to 15\\u00a0min to complete this form. It will make this workshop and community really, really special. Okay.\\n\\nhugo bowne-anderson: so and so I just saw Jeff's note. That's in discord. That's that is brilliant.\\n\\nhugo bowne-anderson: And so I do think the the more we know about you and your interests, just because there are 5 of us now as as well. Right and geographically distributed, so the more we can we can be of help.\\n\\nhugo bowne-anderson: Jeff. Nathan has shared the course Wiki page, which we'll get to in a second,\\n\\nand part of that is\\nhugo bowne-anderson: the compute credit access form. Now I'\"}, {\"id\": \"8e9aa911-861b-4145-adc2-f1fa11e47a09\", \"position\": 18, \"relevance\": 1.0, \"tokens\": 437, \"timestamp\": \"00:40:43.000\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:40:43.000]\\nhugo bowne-anderson: in Ml, you collect real world examples, label by hand, train model on labor data, evaluate on held outset iterate based on performance. Okay, now, there are lots of challenges with Llms.\\n\\nBut\\nhugo bowne-anderson: at the start you get labeled data. It isn't real world data. But you get labeled data for free. You can build your like data flywheel really, really, quickly. So you synthesize realistic queries from personas. You can do that pre-launch label some outputs by hand.\\n\\nhugo bowne-anderson: you prompt the model tune prompts, and the system set up. Whether you're changing your embeddings or whatever it is you evaluate using your Mve, which is your test set and your automated Eval. Then you iterate, based on performance and use your evaluation to guide improvement.\\n\\nSo\\nhugo bowne-anderson: modulo differences. Both workflows are eerily similar. They're grounded in test sets, iteration and failure analysis. And those are the types of things. It's not sexy, right? But you'll get way more. You'\\n\\nll build far better apps if you get comfortable looking at spreadsheets and doing pivot tables of failure modes and building\\nhugo bowne-anderson: multi agentic systems with crew. AI, we're going to do both in this course right? But to be very clear, those are the skills that we're very interested in teaching. So before we jump into Github.\\n\\nI just want to tell you a basic story\\nhugo bowne-anderson: about how Poc purgatory starts. It starts, for example, with llama indexes what they what they call their famous 5 line, quick start, or whatever right where this is. This is incredible, that I can have some data in a document. I do my import. I set up my data directory. I do it. I created essentially a local vector store, a query engine. I then query, get out my response and print it in.\\n\\nhugo bowne-anderson: you know.\"}]",
        "success": 1,
        "feedback_rating": "FAIL",
        "feedback_reason": "I'd have to double check the transcript, but I think it should be clear enough that we are building a recruiter assistant app",
        "feedback_notes": null,
        "feedback_user": "Greg Gandenberger",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information about the question asked, as it does not specify what the question was or what the response was. Therefore, it fails to be helpful, relevant, or direct."
    },
    {
        "id": "b6a54957-5c30-4845-baad-de8c6e265edd",
        "timestamp": "2025-04-12T19:12:40.674564",
        "question": "What app are we building in the course?",
        "response": "Based on the provided sections of the workshop transcript, it is not explicitly mentioned what app is being built in the course.",
        "num_chunks": 5,
        "context_tokens": 2475,
        "completion_tokens": 25,
        "embedding_tokens": 7680,
        "total_tokens": 10180,
        "latency": 0.8957254886627197,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"7263141e-cabd-4a42-8f80-8f28aac69ac2\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"a0d4198b-0b09-40d7-bf49-79539f5d2f0f\", \"position\": 11, \"relevance\": 1.0, \"tokens\": 445, \"timestamp\": \"00:26:25.726\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:26:25.726]\\nhugo bowne-anderson: Pretty, please do that.\\n\\nhugo bowne-anderson:\\n\\nand I just encourage you all to\\nhugo bowne-anderson: use. I mean, use these tools as much as you can while building during the course, because we're here to support and talk about them and and build with you. I do want to say I do appreciate. Everyone likely has more than full time, jobs and families, and all of these things or subsets of these. So I do understand, particularly in our line of work.\\n\\nTime is an incredibly precious\\nhugo bowne-anderson: resource.\\n\\nSo\\nhugo bowne-anderson: all that's to say is, if you don't have much time to build outside, that's totally cool. If you, if all you do is attend these workshops and nothing else. You'll get a huge amount out of the course if you keep building also, and keep in the discords, and then join the office. Hours and pods will set up, you'll get even even more so. I like to think the world's your oyster in proverbial oyster in a lot of ways.\\n\\nSo just getting started in terms of\\nhugo bowne-anderson: set up.\\n\\nhugo bowne-anderson: We use several tools, and my goal is to use as few tools as possible.\\n\\nI will rarely adopt a new tool\\nhugo bowne-anderson: if I don't have to. So in the past we used in the first.st So in the 1st cohort, we use Google drive. This is for slides supporting material. This type of stuff we use github and codespaces for code and also codespaces, feel free to clone the repository and do what you want with it, but we want to make sure that you can get set up and up and running as quickly as possible, and I'll introduce you to code spaces later. It'\\n\\ns kind of\\nhugo bowne-anderson: Google colab on steroids or Vs code superpowered in the browser. We use discord for the Async Chat announcements, and the Q.\"}, {\"id\": \"7a19cbc0-ce6f-4848-9df1-29c900fb1fee\", \"position\": 38, \"relevance\": 1.0, \"tokens\": 497, \"timestamp\": \"01:12:59.773\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:12:59.773]\\nhugo bowne-anderson: Now that we've closed this app, I don't know what happened there. I've got no visibility into it, and I can't share it with you. So after giving something something a front end, I do very much encourage everyone to add some basic logging to your system, and it once again, in doing an Mvp. This can be incredibly simple, right? And in this python 3 app log.\\n\\nWe do so by\\nhugo bowne-anderson: just creating a local sqlite database. You can even do it just to Json, if you want, I decided to go a bit more. I'm a huge fan of sqlite to be honest. But where? So that means in 82 lines of code, we've got our.\\n\\nhugo bowne-anderson: you know, rag system. We'\\n\\nve got our front end\\nhugo bowne-anderson: and we have some logging, basic logging as well. So let's now just have a look at how that works, and then I'll show you ways to think about the logging, or how how to introspect into it.\\n\\nhugo bowne-anderson: So the other thing I didn't mention before is that if you use share is equal to true in launch for gradio, you can create a public link. So when William actually created a gradio app for us to play around with. Recently, that was hosted on modal when preparing some of this course. He just shared. He put share is equal to true, and that meant I could access from Australia. The app he'd just built, which I do. I don'\\n\\nt want to like\\nhugo bowne-anderson: get too too serious. But I the fact that William in DC. Can spin this up, and I can access it. And immediately in Sydney, Australia is absolutely absolutely wild. So I'm gonna ask.\\n\\nhugo bowne-anderson: who is this person?\\n\\nAnd what do they\\nhugo bowne-anderson: do? Our pasta has a great question. What? What model am I using? And I'm actually using Openai. Gpt. 4. 0, I think it's actually once again, though, whatever the default in llama index is, I don't know. Like, maybe that changed then, right? And I don't know.\"}, {\"id\": \"ea3faf8e-4d01-4a08-a167-32ed704c9de1\", \"position\": 8, \"relevance\": 1.0, \"tokens\": 497, \"timestamp\": \"00:19:54.940\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:19:54.940]\\nSo\\nhugo bowne-anderson: I hinted at this. But what this course isn't, it is not a deep dive into every Llm. Tool or trend. Of course we'll be doing. We'll be doing a bunch on agents actually, in the second half of the course, and rag and embeddings and more. But the focus is on workflows, not tools, I honestly think, and I'm happy to chat about those and message about those to be honest. But you will have enough resources on that. What we're teaching is what we'\\n\\nve really noticed is a huge gap\\nhugo bowne-anderson: in education around this stuff. This is not a plug and play AI recipe book. They don't even exist. If someone tries to tell you that or sell you that I'd love to hear it. What you'll learn is how to iterate, debug and adapt not just follow step by step. Templates. Okay, once again, this is not some, you know. Hyper, scaled, load balance, multi agent, guide. This course is about getting you moving, not solving every scaling challenge,\\n\\nbut really approaching the workflow\\nhugo bowne-anderson: of how to get things in production and then keep iterating on them.\\n\\nhugo bowne-anderson: So I'm gonna put this. This is incredibly important. This is an onboarding form that actually 25 of you have completed already. And I'm so happy with with that number so far. Usually, I try to say I try to give a form of 5 to 10\\u00a0min, but I honestly think if you all take 10 to 15\\u00a0min to complete this form. It will make this workshop and community really, really special. Okay.\\n\\nhugo bowne-anderson: so and so I just saw Jeff's note. That's in discord. That's that is brilliant.\\n\\nhugo bowne-anderson: And so I do think the the more we know about you and your interests, just because there are 5 of us now as as well. Right and geographically distributed, so the more we can we can be of help.\\n\\nhugo bowne-anderson: Jeff. Nathan has shared the course Wiki page, which we'll get to in a second,\\n\\nand part of that is\\nhugo bowne-anderson: the compute credit access form. Now I'\"}, {\"id\": \"2c6c3f23-ca7e-474f-9cdb-5b2ad8330f8c\", \"position\": 18, \"relevance\": 1.0, \"tokens\": 437, \"timestamp\": \"00:40:43.000\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:40:43.000]\\nhugo bowne-anderson: in Ml, you collect real world examples, label by hand, train model on labor data, evaluate on held outset iterate based on performance. Okay, now, there are lots of challenges with Llms.\\n\\nBut\\nhugo bowne-anderson: at the start you get labeled data. It isn't real world data. But you get labeled data for free. You can build your like data flywheel really, really, quickly. So you synthesize realistic queries from personas. You can do that pre-launch label some outputs by hand.\\n\\nhugo bowne-anderson: you prompt the model tune prompts, and the system set up. Whether you're changing your embeddings or whatever it is you evaluate using your Mve, which is your test set and your automated Eval. Then you iterate, based on performance and use your evaluation to guide improvement.\\n\\nSo\\nhugo bowne-anderson: modulo differences. Both workflows are eerily similar. They're grounded in test sets, iteration and failure analysis. And those are the types of things. It's not sexy, right? But you'll get way more. You'\\n\\nll build far better apps if you get comfortable looking at spreadsheets and doing pivot tables of failure modes and building\\nhugo bowne-anderson: multi agentic systems with crew. AI, we're going to do both in this course right? But to be very clear, those are the skills that we're very interested in teaching. So before we jump into Github.\\n\\nI just want to tell you a basic story\\nhugo bowne-anderson: about how Poc purgatory starts. It starts, for example, with llama indexes what they what they call their famous 5 line, quick start, or whatever right where this is. This is incredible, that I can have some data in a document. I do my import. I set up my data directory. I do it. I created essentially a local vector store, a query engine. I then query, get out my response and print it in.\\n\\nhugo bowne-anderson: you know.\"}]",
        "success": 1,
        "feedback_rating": null,
        "feedback_reason": null,
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information as the placeholders {QUESTION} and {RESPONSE} were not replaced with actual content, making it impossible to assess the quality of the answer."
    },
    {
        "id": "7ba3278d-98b4-4a45-a763-6e0a76aacfe5",
        "timestamp": "2025-04-12T19:11:46.582536",
        "question": "What is evaluation-driven development?",
        "response": "Evaluation-driven development is an iterative process in which software is built, monitored, evaluated, and improved based on feedback and data. It involves continuously evaluating the performance and behavior of the software, aligning it with business metrics, and iterating on the next version to achieve measurable return on investment.",
        "num_chunks": 5,
        "context_tokens": 2429,
        "completion_tokens": 58,
        "embedding_tokens": 7680,
        "total_tokens": 10167,
        "latency": 0.9704408645629884,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"8f80dea2-b456-4710-86dc-426c445ebf23\", \"position\": 16, \"relevance\": 1.0, \"tokens\": 402, \"timestamp\": \"00:36:47.170\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:36:47.170]\\nhugo bowne-anderson: not because the system is bad and at all right. So that's what we're here to really talk about. I do want to frame most things in terms of evaluation, driven development, although we'll we'll dovetail out of a lot of different different topics. Okay.\\n\\nhugo bowne-anderson:\\n\\nso\\nhugo bowne-anderson: our way out is Edd, evaluation, driven development. Where you have a iterative loop right where you build, you monitor, you evaluate, you improve now.\\n\\nhugo bowne-anderson: even before launching a product. And this is something we'll talk about as the course goes on. You can, you can build a synthetic data set and evaluation harnesses to help you even before real users exist. And if you don't know what an evaluation harness is, don't worry about it. It's essentially a script, something reproducible that you use to evaluate your system. So one example I like to give is.\\n\\nhugo bowne-anderson: I was working on something recently where we were using Gpt. 4.0 Mini, and then Google released Gemini 2.5. And we wanted to play around with it. And it was like, Okay, I'm going to switch this out. But how do I even know beyond vibes that it'\\n\\ns going to be\\nhugo bowne-anderson: good or not? So if you have a basic harness with a few tests, measuring latency and cost and things of business interest as well. This can get you a long way. So at the start, I actually encourage people to build what I call an Mve. So for any Mvp minimum viable product, you have an Mve a minimum viable evaluation as well. Right?\\n\\nhugo bowne-anderson: So just thinking through kind of how this happens. You have an Mvp, you have synthetic user queries.\"}, {\"id\": \"a35fa61d-9f2d-4470-b18f-a85e92ee6dd7\", \"position\": 17, \"relevance\": 1.0, \"tokens\": 460, \"timestamp\": \"00:38:30.480\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:38:30.480]\\nhugo bowne-anderson: You get the Mvp to give you responses, label them by hand, use the label data to build a basic evaluation harness, for example. And we'll get to all of this a test set and Llm. As a judge. And then we use the Mve to evaluate and improve your Mvp. I do want to. Just briefly, we'll get into this a lot later in the course, disambiguate Llm. As a judge. It's a term that people like. Oh, that must be, you know, really sophisticated.\\n\\nWhatever\\nhugo bowne-anderson: the truth is, they can be, and should be as you go on. But essentially what you're doing is you've got a bunch of traces you want to evaluate in some way. You've done a bunch hand labeling as a human that doesn't scale. So you give an Llm.\\n\\nA prompt\\nhugo bowne-anderson: and a bunch of perhaps positive and negative examples and some heuristics for evaluating, and you get it to perform the evaluation for you, and of course something we'll get to is then how to align. One of the most important things is aligning the Lm. As a judge with your own evaluation. But that's kind of just a brief detour on that. I do want to say.\\n\\nhugo bowne-anderson: Evaluation driven development isn't. New people have been building Ml. Software. Well, I've been doing it for years. If you tell me that the original Google search didn't use evaluation driven development. I'd say what? What the heck you're talking about? Because clearly they were using in like highly sophisticated monitoring and evaluation in in order to rapidly iterate on on that product.\\n\\nSo\\nhugo bowne-anderson: essentially in machine learning, we've had Mvps and collected data. Then we've labeled responses by hand. Then we use the labeled data to build a basic evaluation system. But in this case it's a test set right. And then we use this Mve to evaluate and improve your Mvp. So just to compare Eval and building with Llms versus traditional. Ml.\"}, {\"id\": \"9b06821d-c542-4f2f-a3e3-772499dd11df\", \"position\": 24, \"relevance\": 1.0, \"tokens\": 482, \"timestamp\": \"00:52:20.970\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:52:20.970]\\nhugo bowne-anderson: and then perhaps you monitor for a while, figure out what's up, make some small changes, whatever it is. And then you start working on the next version, and there will be version releases. Then, right? So you will start working again and iterating.\\n\\nhugo bowne-anderson: based on what you how you see your software is performing. But the point is that you're iterating on the next version of it as opposed to having something continuously changing and continuously iterating.\\n\\nhugo bowne-anderson:\\n\\nSo we have software specs\\nhugo bowne-anderson: for Llm. Powered applications right? And this is an iterative process that spans development and production. You have software specs, you build, you deploy your value, you monitor and evaluate, including all of these things that I really I mentioned at the start of this workshop which we'll get into in this course.\\n\\nhugo bowne-anderson:\\n\\nSo\\nhugo bowne-anderson: the question I said at the start, how do we get out of aic a a Oc AI poc, I actually should change that because someone said someone actually said to me, they didn't know what a proof of concept was, and they thought I was using the term person of color purgatory.\\n\\nAnd I I definitely have never intended that so I probably should should change that\\nhugo bowne-anderson: So the 1st challenge non-determinism. How do we deal with that? We log inputs and outputs. We evaluate logs. We iterate on prompts and context, we use Api knobs to reduce variance.\\n\\nhugo bowne-anderson: How about the challenge of hallucinations?\\n\\nhugo bowne-anderson: Well, similarly, we log inputs and outputs in dev and prod, we use domain specific expertise to evaluate output. In both, we build systems and processes to automate assessments such as unit tests and data sets. So testing sets product feedback hooks. Similarly, for for evaluation.\\n\\nhugo bowne-anderson: for iteration, we build a software development lifecycle that enables you to quickly build, deploy, monitor and evaluate. And in terms of business value. We really need to align outputs with business metric and optimize workflows to achieve measurable return on investment.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"7263141e-cabd-4a42-8f80-8f28aac69ac2\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"eeb976d9-5c87-45e5-b18e-e497056b3f4f\", \"position\": 40, \"relevance\": 1.0, \"tokens\": 489, \"timestamp\": \"01:15:40.650\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:15:40.650]\\nhugo bowne-anderson: my query, who is this Andrew in. Okay, now, this is really cool. The fact that we were able to just have a quick conversation with a Pdf log. Things look at them in data set.\\n\\nhugo bowne-anderson: we can export a Csv, and this is actually part of my workflow sometimes. Not as much. Now I'\\n\\nve actually\\nhugo bowne-anderson: I'll I'll tell you that the workflow where you export a Csv. Put in a spreadsheet, then do some labeling, so a column for pass or fail a column for reason for pass or fail, then failure, mode right, and what this helps is.\\n\\nhugo bowne-anderson: Once you have failure modes. For example, if you have like 5 different failure modes, you then do a pivot table rank, order them in terms of how often they occur, and that will tell you what to focus on in your app. Right. So the reason I said, I don't do that as much at the moment. I've actually been using some pretty wild vibe coding, and maybe I'll do a demo of it some sometime to spin up, you know,\\n\\nliterally in\\nhugo bowne-anderson: cursor agent mode with Gemini. 2.5. Max, at the moment is, you know, work on an app, then create some interactions with it and spin up a local Json viewer or something like like literally Vibe code, a custom viewer for the data set that I've just created, which is, which is super fun. And I encourage everyone time permitting to play around with.\\n\\nBut\\nhugo bowne-anderson:\\n\\nthe short version of the story is that we were able to\\nhugo bowne-anderson: get in demo hell in a variety of ways, but able to test out a variety of models, then put a basic front end on, then log, in order to start thinking about visibility into our app. And this is incredibly powerful. In a lot of ways. Now the next steps. This is kind of demo hell, though, because we're not sure what our app is doing, we're not sure which model to use. So using evaluation, driven development will allow us to kind of get out of the situation we've we've just gotten ourselves into.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "Concise and comprehensive summary",
        "feedback_notes": null,
        "feedback_user": "Greg Gandenberger",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, as it does not specify what the question was or what the response addressed."
    },
    {
        "id": "5a35377a-e8f0-439e-b9db-5c389c85363f",
        "timestamp": "2025-04-12T19:07:40.371231",
        "question": "What did the workshop cover?",
        "response": "The workshop covered topics such as using Discord as a communication platform, the foundations of LLN software and evaluation-driven development, building software powered by machine learning and LLNs, monitoring and evaluating LLN calls, and the use of tools like Zoom, VS Code, and Code Spaces.",
        "num_chunks": 5,
        "context_tokens": 2510,
        "completion_tokens": 57,
        "embedding_tokens": 7680,
        "total_tokens": 10247,
        "latency": 1.1857903003692627,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"095845f8-fd3f-47ad-936c-54213bc2eb1b\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"ae57fceb-959f-4ded-9cd5-444eaace2c39\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}, {\"id\": \"90dec958-bb49-48a1-83f5-e7d027c26fbb\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}, {\"id\": \"7263141e-cabd-4a42-8f80-8f28aac69ac2\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"ecbe8bbc-d334-49a9-8a20-b18f0a3c3e72\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "Fairly concise and comprehensive summary. It does say \"LLN\" instead of \"LLM\", but I am assuming that's an issue in the transcription, and https://discord.com/channels/1324240687641657484/1359250145790656796 suggests that transcription issues are out of scope.",
        "feedback_notes": null,
        "feedback_user": "Greg Gandenberger",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, as it does not specify what the question was or what the response was."
    },
    {
        "id": "df580557-352a-41c6-9aa4-7627462fe54a",
        "timestamp": "2025-04-12T17:49:04.173553",
        "question": "Was there any mention of Mario in the workshop?",
        "response": "No, there was no mention of Mario in the workshop transcript sections provided.",
        "num_chunks": 5,
        "context_tokens": 2500,
        "completion_tokens": 16,
        "embedding_tokens": 7680,
        "total_tokens": 10196,
        "latency": 0.8986544609069824,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"221de8e7-cbac-4590-8474-e77219b2cfdf\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}, {\"id\": \"435c36fe-ec02-4d09-ae9c-aad389f6283a\", \"position\": 27, \"relevance\": 1.0, \"tokens\": 474, \"timestamp\": \"00:57:20.840\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:57:20.840]\\nhugo bowne-anderson: Absolutely love it. And I also just noticed in the chat Vishut went. This is probably when I spoke about proof of concept purgatory. Vishrud has faced issues when he used Mvp. Without context. In North America it's used for most valuable player totally agree,\\n\\nand it shows how much\\nhugo bowne-anderson: how most people I speak with at least professionally work in tech and know what know that it means. That right?\\n\\nhugo bowne-anderson: awesome. Well, I'm just. I can't see everything in discord at the moment,\\n\\nbut so much fantastic conversation and\\nhugo bowne-anderson: questions as as well. So if anyone.\\n\\nhugo bowne-anderson: I'm gonna open a window right now. But if anyone doesn't have access to github,\\n\\ncould you\\nhugo bowne-anderson: just put your handle in the workshop? One channel and I will add you almost in real time.\\n\\nhugo bowne-anderson: And the reason for that is with Github has changed certain things so that I actually can't assign anyone else to be admin currently as it's under my personal.\\n\\nhugo bowne-anderson: Okay, we have Vinysh. Oh, oh,\\n\\nI love this and I do hope that\\nhugo bowne-anderson: you're all okay with us. Just taking 2\\n\\nmin to\\nhugo bowne-anderson: add a few more people. Oh, this is great.\\n\\nhugo bowne-anderson: amazing.\\n\\nNathan Danielsen: Well, while people are doing that, yeah. Want to comment on the the rich conversations that's happening in discord right now. And from the 1st kind of like run of this course. This is what that the conversations are. One of the highlights as well. So just calling that out. That's a lot of good stuff. A lot of smart people sharing resources there. So check out the discord for the session.\\n\\nhugo bowne-anderson: I really appreciate that. And in fact, I know it. I mean, we we started building this right to do a court. We actually started as a workshop in Austin last year, Stefan and myself,\"}, {\"id\": \"44ac21e9-c9e9-40be-bb8a-01407ebd9dd4\", \"position\": 45, \"relevance\": 1.0, \"tokens\": 488, \"timestamp\": \"01:25:38.330\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:25:38.330]\\nhugo bowne-anderson: Well, I was gonna talk about some things, but maybe we'll we'll wait because I don't. Wanna don't wanna distract people.\\n\\nhugo bowne-anderson: hey, Philip? Great to see you, man.\\n\\nPhilip Kiely: Hey, everyone.\\n\\nhugo bowne-anderson: We'll get started in a couple of minutes. I've just got everyone I'm taking a couple of minutes to complete a a survey about how? The 1\\n\\nst\\nhugo bowne-anderson: part of this workshop workshop when. But thank you so much for for joining. So we'll yeah just start in a minute.\\n\\nPhilip Kiely: Sounds good.\\n\\nhugo bowne-anderson: Where? Where are you, darling? Are you in the Bay Area.\\n\\nPhilip Kiely: Yeah, I'm right on embalcadero right now.\\n\\nhugo bowne-anderson: Must have been a wild, wild few days since Llama 4 dropped.\\n\\nPhilip Kiely: I I got back from jujitsu at about noon on on Saturday, you know, nice and tired and sweaty, and ready for a nice relaxing afternoon, and then I check my phone and boom, mama. 4 waits. And there went the weekend. But a lot of fun.\\n\\nhugo bowne-anderson: I'm sure. And yeah, congrats to you and the entire team for getting up, getting it up and running so quickly and getting your great Demos out. It's really, really impressive, inspiring stuff, man.\\n\\nPhilip Kiely: Thank you. It's what we do.\\n\\nhugo bowne-anderson:\\n\\nIt is\\nhugo bowne-anderson: so we'll just take 30 more seconds to give everyone a a chance to complete this. Would you mind actually giving my comment in discord a thumb up when you when you've completed it.\\n\\nhugo bowne-anderson: Nathan just wrote in discord, llama for Saturday. Exactly. That'\\n\\ns\\nhugo bowne-anderson: it. Beats deep. Seek Monday I'll tell you that.\\n\\nPhilip Kiely: I spent the day after Christmas. Implementing deep seek stuff and making deep seek content at my cousin's childhood bedroom at my aunt's house. Because that's where everyone else was having Boxing Day.\"}, {\"id\": \"e3c1a18d-2bfc-4c02-ab13-974ed28eb847\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"f5af0a01-a2e3-4ffc-836d-d0bcdae8570b\", \"position\": 25, \"relevance\": 1.0, \"tokens\": 432, \"timestamp\": \"00:54:14.400\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:54:14.400]\\nSo\\nhugo bowne-anderson: without further ado, I would love to jump into Github. I would I have spoken for a while, so I would love if there's been any, any comments in discord that could be relevant. Jeff, William, Nathan Stefan, or anything else anyone would like to add, I really I welcome it.\\n\\nStefan Krawczyk: Nothing needs to be, I guess, raised in terms of, I guess, just to reiterate what Hugo has been saying so or at least one of the themes you come to understand this course is really, you gotta look at your data right? And so and so this will be one of the key things that hopefully we'll we'll drill into you as the course goes. But.\\n\\nhugo bowne-anderson: Yeah. But Jeff.\\n\\nStefan Krawczyk: William, or Nathan, or anything.\\n\\nhugo bowne-anderson: I just did want to add, though you do want to look at your data. But something I've learned from you, Stefan, is how much once you've done that, how you can start automating pieces of that right? And so speaking to your workshop next week, but doing the scientific approach, then robustifying it, so to speak.\\n\\nhugo bowne-anderson: But yeah, Hugo.\\n\\nNathan Danielsen: So 1 1 quick question you that was raised in discord. What did you mean by fine tuning isn't really useful use these days? William gave a good initial answer. But what's your can you? And upon that, just a little bit more.\\n\\nhugo bowne-anderson: So did I say? Fine tuning isn't really useful these days, cause if I I would, that sounds like something I I would say.\\n\\nWhat I mean is that most of the time\\nhugo bowne-anderson: you need? You think you need to fine tune. You can do other things such as prompt your way out of it.\\n\\nhugo bowne-anderson: There are cases, for example.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "It was in second workshop",
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, as it does not specify what the question was or what the response was."
    },
    {
        "id": "7cd1627f-e05b-41d0-8818-d0505c452e5a",
        "timestamp": "2025-04-12T17:48:17.930075",
        "question": "What questions did the participants ask?",
        "response": "Some of the questions asked by participants in the workshop were:\n\n1. Is it common to use batch workloads and set up batch jobs with Base 10?\n2. Is streaming audio input supported by Base 10's Llm platform?\n3. How does Base 10 compare to other cloud platforms like Microsoft Azure and AWS in terms of offerings and level of abstraction?",
        "num_chunks": 5,
        "context_tokens": 2532,
        "completion_tokens": 75,
        "embedding_tokens": 7680,
        "total_tokens": 10287,
        "latency": 1.4108672142028809,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"0ed4d787-80f1-4861-b364-947c474d46e5\", \"position\": 21, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:46:30.010\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:46:30.010]\\nI do want to just take a quick\\nhugo bowne-anderson: detour when we're talking about.\\n\\nhugo bowne-anderson:\\n\\nYou know\\nhugo bowne-anderson: what we get use out of all of these things, for the conversational aspect of Llms is fantastic. I use it all the time. But in my humble estimation most roi will involve automation, not conversations. So, for example, an app that consumes Linkedin profiles finds relevant candidates for a position automates emails to them. That's 1 example that the demo I just showed you perhaps could could be used for.\\n\\nAnd this brings me to my point of and our point of\\nhugo bowne-anderson: really thinking about what we want to evaluate. Okay, so what's cool, you can ask, is the information extracts from Linkedin? Correct? That's a cool question to ask and important, that needs to be satisfied. But remember, we're trying to scale human behavior so, and we want it to result in the same outcomes. But better right? So the next question you might ask, do the emails generated resemble the emails domain experts sent previously.\\n\\nhugo bowne-anderson: also a good question to ask, and who would have thought trying to get a domain expert involved would be so so useful.\\n\\nBut it turns out it is now\\nhugo bowne-anderson: at a very macro level,\\n\\nthough\\nhugo bowne-anderson: you really want to know? Do the emails result in hiring good candidates? And is it more efficient and more cost effective than our previous system right? And it's actually not even clear how long these cycles are.\\n\\nSo making sure that we in the end tie these macro level\\nhugo bowne-anderson: business evaluations to the micro level Llm calls is super important.\\n\\nhugo bowne-anderson: So that brings us back to this. How do we? How do we evaluate a system like this? I don't know what the actual prompt sent to the Llm. Was. How do I give feedback on on system performance? How can I see data and traces and conversations? How can we iterate quickly on this? Mvp.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"5e73f14f-3d63-4a45-a62f-ee2dc8231fca\", \"position\": 44, \"relevance\": 1.0, \"tokens\": 474, \"timestamp\": \"01:24:11.480\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:24:11.480]\\nhugo bowne-anderson: awesome. I appreciate that. So Philip. I wonder, Philip, are you on the call yet? By any chance?\\n\\nhugo bowne-anderson: Okay, you should be here in a few minutes. But Philip Philip Keeley, who's devrel at base 10 really, really fascinating dude does a lot of technical documentation and technical writing as well as published around that. He'll be giving a talk in a few minutes on moving Llm. Apps from prototype to production with with base 10. Please do not forget to claim your $1,000 free free credit, which I'm so grateful for that I've been able to provide.\\n\\nAnd you just have a look at all the types of things they have\\nhugo bowne-anderson: on their platform that you can deploy with a couple of clicks. To be honest, I really would love, and I,\\n\\nhugo bowne-anderson: because we have a few minutes now.\\n\\nhugo bowne-anderson: I would actually really love.\\n\\nI have a feedback form\\nhugo bowne-anderson: for each workshop. And so what you'll see here.\\n\\nhugo bowne-anderson: you know you put your email in. How did you rate the pace? What did you like most? What could we improve? Was there anything unclear or confusing? If so, what any other feedback or suggestions? I'm going to put that in the discord right now, and if you wouldn't mind just taking a few minutes now to complete it, there's far more chance of you actually completing it now than there is afterwards. I just statistically. So yeah, let's just take. Don't take more than 3\\n\\nmin\\nhugo bowne-anderson: to jot down a few things there when you rate the pace of the session also. Do note, this is the 1st one. So for some people it may totally have been too slow, and I get that, but it was the 1st session. So why don't everyone can take a couple of minutes to do that? And then when Philip joins we'll jump into his talk.\\n\\nhugo bowne-anderson: Stefan, William, Nathan, while people are doing that I'm wondering.\"}, {\"id\": \"c8dca6d6-05b6-4cf8-9d52-4e74f0180c65\", \"position\": 58, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"01:52:08.230\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:52:08.230]\\nhugo bowne-anderson: That was. That was fantastic. We've got it. We've got several great questions in the chat which I'll get people to turn their mics on to ask themselves in a second. I also I've so I've had a wonderful experience with base 10 support. We're not offering support from base 10 in our discord. But my understanding is, if people ping support, they should be relatively quick in being able to help help with stuff.\\n\\nPhilip Kiely: Yeah, yeah. So we we try and give, you know, good support to everyone. Self service or enterprise. So yeah, absolutely stick with the stick with the support channel. Just, you know, like I said, we just we just did revamp docs. So hopefully, that's able to catch a bunch of stuff, but if not definitely, don't hesitate to hit us up. If it's something close or credit related, feel free to reach out to me directly.\\n\\nhugo bowne-anderson: Awesome. I really appreciate it, and of course we'll try to help help each other as well before before pinging you. Caleb Tutti has a great question, Caleb, would you mind just asking your question? Maybe you could just start by introducing yourself what what you do and and where you are, so we'll have a bit more context.\\n\\nCaleb Tutty: Sure. Yeah, Hi, I'm I'm Caleb. So I do. Consulting one of the projects that I work on is ASR into the legal domain.\\n\\nCaleb Tutty: and we we do. Yeah, sort of a number of different projects with sort of Llms. I I guess the question I was wondering about is, I guess, just looking at costs, and when it'\\n\\ns\\nCaleb Tutty: when it makes sense, maybe to have sort of a dedicated endpoint. Is it common with other customers to do batch workloads, maybe. Is this sort of infrastructure code kind of tools I saw you showed some gamble there to maybe sort of set up, do a batch job and then shut shut down. So the instance is that a common or good use case with base 10.\\n\\nPhilip Kiely: Yeah, that's a great question, Caleb,\"}, {\"id\": \"7e0bf3e3-6725-471b-a00c-977a57ff4fc0\", \"position\": 60, \"relevance\": 1.0, \"tokens\": 481, \"timestamp\": \"01:55:27.210\", \"speaker\": \"rafiolaverria\", \"text\": \"[TIMESTAMP: 01:55:27.210]\\nrafiolaverria: Hey? I'm Raphael, Maria. I am a senior software engineer team lead at a startup. Responsible for the Llm applications.\\n\\nrafiolaverria: And I just build some fun almost every day.\\n\\nrafiolaverria: And one of my questions, one thing I'\\n\\nve been trying to do\\nrafiolaverria: is learning Llms on transcripts.\\n\\nrafiolaverria: so doing, a lot of streaming audio.\\n\\nrafiolaverria: The is that supported? Or is that something? I had to implement myself.\\n\\nPhilip Kiely: Streaming audio input, we just actually built Websocket support. It's still in beta but is potentially, gonna actually, I think we released documentation for it. It's definitely at a place where you can play with it. But it's probably not yet ready for like a a really large scale production use case should be ready, though in a couple of weeks.\\n\\nhugo bowne-anderson: So yeah, save save some of those 1,000 credits. Only spend 500 in the next couple of weeks, Rafi.\\n\\nhugo bowne-anderson: So, Philip, we're going to wrap up in a second. Firstly, just thank you so much for your time, and also thank you and all of base 10 for this incredibly generous sponsorship and and be involved with the course, and we all appreciate it so much. We. We have a question from Vishrut which is is based in similar in offering to things like Microsoft, azure aws bedrock these types of things, and I can say from my perspective of using all of these,\\n\\nthat\\nhugo bowne-anderson: the level of abstraction for base 10 is far more appropriate for the type of work I want to do like. It's relatively high level of abstraction. It's model and app focus, whereas azure bedrock seem to me like infra focus pretty pretty low level. But I'm wondering on your take,\\n\\nand just\\nhugo bowne-anderson: if you can give any insight around how to think about the space more generally, just because there are a bazillion. And we have something called the mad landscape literally because of this space. Right? So how you think about, you know, tools in the space more generally.\"}, {\"id\": \"e3c1a18d-2bfc-4c02-ab13-974ed28eb847\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "Accurate",
        "feedback_notes": null,
        "feedback_user": "Vishrut",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "a599b2a4-b0a7-483a-a7d3-e3def17b2978",
        "timestamp": "2025-04-12T07:21:42.718194",
        "question": "Who are the lecturers",
        "response": "The lecturers mentioned in the provided sections are:\n- Hugo Bowne-Anderson\n- Stefan Krawczyk\n- Jeff Pidcock\n- Nathan Danielson\n- William Horton\n\nGuest lecturers mentioned are:\n- Hamil Hussein from parlance labs\n- Eric Ma from Moderna\n- Ravin Kumar from Google Deepmind\n- Ines Montani from Spacey",
        "num_chunks": 5,
        "context_tokens": 2465,
        "completion_tokens": 80,
        "embedding_tokens": 7680,
        "total_tokens": 10225,
        "latency": 2.720167398452759,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"c4e21689-3e56-482e-b6d0-dea4808dbc38\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}, {\"id\": \"5e36fe76-bf13-4538-8f6b-1ffbead26b06\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"2204b658-035a-4bf3-a12a-8890a5824179\", \"position\": 13, \"relevance\": 1.0, \"tokens\": 406, \"timestamp\": \"00:29:52.640\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:29:52.640]\\nI I wonder if I put\\nhugo bowne-anderson: yes, I did put the shared commitments there, so we'll go through that in a second, and we'll keep keep adding adding things here. And actually, one thing which I, some of you have asked about are the guest lectures from cohort one, and I've created a little guest lecture, Archive and there's there's actually one or 2 missing here, including William Horton, who gave a wonderful talk on, on thinking through when to launch,\\n\\nand how how to think about\\nhugo bowne-anderson: what metrics you want to measure before launch, and how sometimes that can be challenging, and how you really need to iterate on that. But these are all talks from the previous ones.\\n\\nAnd if you click on\\nhugo bowne-anderson: the page, let's click on Nathan's.\\n\\nhugo bowne-anderson: Yeah, we have an AI generated summary. We have a Youtube video. I'll put the slides in soon. Takeaways AI generated, and and so on. So in all honesty, this is the 1st time we've created something like this. So feedback, incredibly incredibly welcome. And by this I mean this type of document that links to different resources and Youtube videos and and that type of stuff. I'm really excited to have it grow with with all of you as well.\\n\\nhugo bowne-anderson:\\n\\nI\\nhugo bowne-anderson: I think that is pretty much it.\\n\\nJust before getting to\\nhugo bowne-anderson: content. Now, Williams, talk isn't like Williams.\\n\\nTalk is actually\\nhugo bowne-anderson: You remember? That was, that was a 2\\u00a0h session that turned into a 4\\u00a0h session and zoom. That also happens. By the way, and I will apologize for that. Y'all are not in like required to stick around,\"}, {\"id\": \"bfbd48a5-c455-4487-a170-4f73f9adcc87\", \"position\": 8, \"relevance\": 1.0, \"tokens\": 497, \"timestamp\": \"00:19:54.940\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:19:54.940]\\nSo\\nhugo bowne-anderson: I hinted at this. But what this course isn't, it is not a deep dive into every Llm. Tool or trend. Of course we'll be doing. We'll be doing a bunch on agents actually, in the second half of the course, and rag and embeddings and more. But the focus is on workflows, not tools, I honestly think, and I'm happy to chat about those and message about those to be honest. But you will have enough resources on that. What we're teaching is what we'\\n\\nve really noticed is a huge gap\\nhugo bowne-anderson: in education around this stuff. This is not a plug and play AI recipe book. They don't even exist. If someone tries to tell you that or sell you that I'd love to hear it. What you'll learn is how to iterate, debug and adapt not just follow step by step. Templates. Okay, once again, this is not some, you know. Hyper, scaled, load balance, multi agent, guide. This course is about getting you moving, not solving every scaling challenge,\\n\\nbut really approaching the workflow\\nhugo bowne-anderson: of how to get things in production and then keep iterating on them.\\n\\nhugo bowne-anderson: So I'm gonna put this. This is incredibly important. This is an onboarding form that actually 25 of you have completed already. And I'm so happy with with that number so far. Usually, I try to say I try to give a form of 5 to 10\\u00a0min, but I honestly think if you all take 10 to 15\\u00a0min to complete this form. It will make this workshop and community really, really special. Okay.\\n\\nhugo bowne-anderson: so and so I just saw Jeff's note. That's in discord. That's that is brilliant.\\n\\nhugo bowne-anderson: And so I do think the the more we know about you and your interests, just because there are 5 of us now as as well. Right and geographically distributed, so the more we can we can be of help.\\n\\nhugo bowne-anderson: Jeff. Nathan has shared the course Wiki page, which we'll get to in a second,\\n\\nand part of that is\\nhugo bowne-anderson: the compute credit access form. Now I'\"}, {\"id\": \"806864a3-0a8f-4aa8-9d9a-4767d3857b16\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "Correct identification",
        "feedback_notes": "Was unable to discern primary lecturers (Hugo Stefan) from volunteers given the context ",
        "feedback_user": "Geoff",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information or context related to the question asked, making it unhelpful and irrelevant."
    },
    {
        "id": "f5ecac53-0763-4be6-a341-9f560e22139a",
        "timestamp": "2025-04-12T07:19:21.861590",
        "question": "Who was the guest lecturer in workshop 1 and what platform did they talk about?",
        "response": "The guest lecturer in workshop 1 was Charles Fry, and he talked about building AI-powered apps on Modal.",
        "num_chunks": 5,
        "context_tokens": 2448,
        "completion_tokens": 23,
        "embedding_tokens": 7680,
        "total_tokens": 10151,
        "latency": 1.5278863906860352,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"a6f07844-b913-409b-a15e-0bba4eaa9df6\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}, {\"id\": \"418349ef-1917-49b2-9631-84668af08972\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}, {\"id\": \"0c4d35cd-8149-42c1-8864-dbe0ea40dc3e\", \"position\": 42, \"relevance\": 1.0, \"tokens\": 459, \"timestamp\": \"01:19:59.150\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:19:59.150]\\nhugo bowne-anderson: when we're looking at our data, I don't even know what the bloody prompt is and part of my language. But in Australia. That's barely a swear word, a cuss word, by the way, but I actually don't know what the prompt is. So how do I even know how to evaluate this this system. Right?\\n\\nSo I very much encourage you all to\\nhugo bowne-anderson: rip out llama index and rebuild the app where you don't like. You don't even need a front end. Ui, it's fun to use something in gradio. But pull it out and look at your data and see what type of responses you get and and how it compares as well.\\n\\nhugo bowne-anderson:\\n\\nSo\\nhugo bowne-anderson: in the next session, just foreshadowing slightly which is Workshop 2, we'\\n\\nll be doing a lot on prompt engineering in the Llm software development lifecycle and thinking through how we\\nhugo bowne-anderson: essentially how we start to think about evaluation when changing prompts and versioning. And and these types of things. We have a wonderful guest, speaker, Charles Fry, from from Modal about building AI powered apps on on modal. I actually also encourage you all very much to his guest. Talk last time really blew me away. So much. So I mean, I had him on a podcast to chat about it as well. This is the one page where the embed just didn't work,\\n\\nfor\\nhugo bowne-anderson: whatever reason.\\n\\nhugo bowne-anderson: And also, by the way, oh, yeah, I used sorry I used the new Gpt to create funny covers for everyone. So this is unlisted. So I would appreciate it. If you don't share these videos. These are really, for course, attendees also.\\n\\nhugo bowne-anderson: and as part of the value. But he gave a wonderful talk about what we all, as Llm. Developers need to know about gpus and hardware, so I do encourage you all time permitting to check that out, so he'll be giving a guest talk,\"}, {\"id\": \"3a8ff4a3-15a8-4268-9731-206d915e76ac\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"c038bdf5-c406-4824-a2e3-48e9b5b3903c\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}]",
        "success": 1,
        "feedback_rating": null,
        "feedback_reason": null,
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "c789dfbf-fd76-4f13-b81b-f9c97de29290",
        "timestamp": "2025-04-12T07:18:24.166359",
        "question": "Who was the guest lecturer and what platform did they talk about?",
        "response": "The guest lecturer mentioned in the transcript is Charles Fry from Modal. He gave a talk about building AI-powered apps on Modal.",
        "num_chunks": 5,
        "context_tokens": 2374,
        "completion_tokens": 26,
        "embedding_tokens": 7680,
        "total_tokens": 10080,
        "latency": 0.9481070041656494,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"418349ef-1917-49b2-9631-84668af08972\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}, {\"id\": \"0c4d35cd-8149-42c1-8864-dbe0ea40dc3e\", \"position\": 42, \"relevance\": 1.0, \"tokens\": 459, \"timestamp\": \"01:19:59.150\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:19:59.150]\\nhugo bowne-anderson: when we're looking at our data, I don't even know what the bloody prompt is and part of my language. But in Australia. That's barely a swear word, a cuss word, by the way, but I actually don't know what the prompt is. So how do I even know how to evaluate this this system. Right?\\n\\nSo I very much encourage you all to\\nhugo bowne-anderson: rip out llama index and rebuild the app where you don't like. You don't even need a front end. Ui, it's fun to use something in gradio. But pull it out and look at your data and see what type of responses you get and and how it compares as well.\\n\\nhugo bowne-anderson:\\n\\nSo\\nhugo bowne-anderson: in the next session, just foreshadowing slightly which is Workshop 2, we'\\n\\nll be doing a lot on prompt engineering in the Llm software development lifecycle and thinking through how we\\nhugo bowne-anderson: essentially how we start to think about evaluation when changing prompts and versioning. And and these types of things. We have a wonderful guest, speaker, Charles Fry, from from Modal about building AI powered apps on on modal. I actually also encourage you all very much to his guest. Talk last time really blew me away. So much. So I mean, I had him on a podcast to chat about it as well. This is the one page where the embed just didn't work,\\n\\nfor\\nhugo bowne-anderson: whatever reason.\\n\\nhugo bowne-anderson: And also, by the way, oh, yeah, I used sorry I used the new Gpt to create funny covers for everyone. So this is unlisted. So I would appreciate it. If you don't share these videos. These are really, for course, attendees also.\\n\\nhugo bowne-anderson: and as part of the value. But he gave a wonderful talk about what we all, as Llm. Developers need to know about gpus and hardware, so I do encourage you all time permitting to check that out, so he'll be giving a guest talk,\"}, {\"id\": \"288e5d72-d5e2-41c5-a6f2-69e226022109\", \"position\": 13, \"relevance\": 1.0, \"tokens\": 406, \"timestamp\": \"00:29:52.640\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:29:52.640]\\nI I wonder if I put\\nhugo bowne-anderson: yes, I did put the shared commitments there, so we'll go through that in a second, and we'll keep keep adding adding things here. And actually, one thing which I, some of you have asked about are the guest lectures from cohort one, and I've created a little guest lecture, Archive and there's there's actually one or 2 missing here, including William Horton, who gave a wonderful talk on, on thinking through when to launch,\\n\\nand how how to think about\\nhugo bowne-anderson: what metrics you want to measure before launch, and how sometimes that can be challenging, and how you really need to iterate on that. But these are all talks from the previous ones.\\n\\nAnd if you click on\\nhugo bowne-anderson: the page, let's click on Nathan's.\\n\\nhugo bowne-anderson: Yeah, we have an AI generated summary. We have a Youtube video. I'll put the slides in soon. Takeaways AI generated, and and so on. So in all honesty, this is the 1st time we've created something like this. So feedback, incredibly incredibly welcome. And by this I mean this type of document that links to different resources and Youtube videos and and that type of stuff. I'm really excited to have it grow with with all of you as well.\\n\\nhugo bowne-anderson:\\n\\nI\\nhugo bowne-anderson: I think that is pretty much it.\\n\\nJust before getting to\\nhugo bowne-anderson: content. Now, Williams, talk isn't like Williams.\\n\\nTalk is actually\\nhugo bowne-anderson: You remember? That was, that was a 2\\u00a0h session that turned into a 4\\u00a0h session and zoom. That also happens. By the way, and I will apologize for that. Y'all are not in like required to stick around,\"}, {\"id\": \"dfa64170-de86-4818-b57e-b91595aeb206\", \"position\": 61, \"relevance\": 1.0, \"tokens\": 490, \"timestamp\": \"01:56:55.830\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:56:55.830]\\nPhilip Kiely: I, I actually have a whole market map talk track which probably takes more than 15 seconds to get through. Generally, if you're looking at a influence platform from a Csp a cloud service provider. So like you were talking about bedrock, sagemaker, votex azure AI foundry. You're generally gonna run into a lot of the same like shared influence endpoint limitations with those you might be able to kick the can down the road a little bit further with some of these.\\n\\nPhilip Kiely: but generally we find that when developer teams switch from a Csp platform like that to a dedicated platform like Base 10 they end up with much better performance. Better pricing as well as just like better support. You know. I don't know if you've ever tried to go through. Aws support. It's it's not legendarily amazing.\\n\\nAnd\\nPhilip Kiely: so yeah, it's it's definitely a a pretty direct competitor in that same space of going from that kind of offering within the Csp to a offering that sits on top of multiple Csps and is able to kind of leverage the best of everyone.\\n\\nhugo bowne-anderson: Awesome. Well, thank you so much. It'\\n\\ns\\nhugo bowne-anderson: we're we're at time. It's it's time to wrap up, but really appreciate your time and hope you travel safe, and don't have to give away too many, too many credits at the at the airport or not. The amount of credits, just the amount of time. Hope you get the chill as well.\\n\\nPhilip Kiely: It'll be great. Yeah, definitely hit me. Send me an email. Hit me up for credits. And if you have any remaining questions for my talk.\\n\\nI do have\\nPhilip Kiely: a link to the discord. Drop them in the discord, and I'\\n\\nll swing by tomorrow and answer them\\nPhilip Kiely: fantastic. And are you at liberty to share your slides in the discord as well cause people love.\\n\\nPhilip Kiely: Yeah, I'll drop by and and put those out as well.\\n\\nhugo bowne-anderson: Fantastic. Well, safe travels, my man, and be in touch soon.\\n\\nPhilip Kiely: All right. Sounds good.\\n\\nhugo bowne-anderson: Thank you. And everyone.\"}, {\"id\": \"1ce92ca2-436c-4c2c-bf9c-bfc2cbb11bc9\", \"position\": 48, \"relevance\": 1.0, \"tokens\": 442, \"timestamp\": \"01:28:11.060\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:28:11.060]\\nPhilip Kiely: We're gonna talk about what it takes to run influence in production. We're gonna talk about the journey of going from some of the things that you may be learning about and prototyping in this course to how you can maybe apply this stuff either in your day job,\\n\\nor if you start a startup as you scale or if you start a side project\\nPhilip Kiely: and it goes super viral. Actually, one of our biggest customers kind of started that way. Then, yeah, this also becomes, very, very relevant.\\n\\nPhilip Kiely: I had a little sneak peek at the at the lesson plan for today that that Hugo put together,\\n\\nand it sounds like a lot of the last hour hour and a half was about how to build AI products going from objective to data to model development model evaluation\\nPhilip Kiely: and talking about how that sort of workflow has changed. Going from an Ml.\\n\\nWorld to an AI world\\nPhilip Kiely: so base. 10 kind of comes in at the end of that. At the end of that cycle to take the thing that you've built and scale it to the entire world.\\n\\nPhilip Kiely: Sorry I should not have eaten very dry popcorn right before giving a a public talk.\\n\\nPhilip Kiely: So as we think about, you know how AI tools are being consumed in these applications today they're kind of 2 extremes. One extreme is you just outsource everything you go with a closed source shared endpoint like Openai or anthropic. You don't think about the model. You don't think about the infrastructure. You don't think about anything other than how many tokens you'\\n\\nre consuming and how much every single one of those tokens costs\\nPhilip Kiely: on the complete other end of the spectrum. You can do everything yourself. You can get your own Gpus, set up your own model influence servers load your own model weights and wire up your own infrastructure. Do everything yourself. What we're gonna talk about today is kind of a middle path where you get most of the control of the Diy with most of the ease of the, you know, low overhead, close source stuff.\"}]",
        "success": 1,
        "feedback_rating": "FAIL",
        "feedback_reason": "This is workshop 2, not workshop 1",
        "feedback_notes": null,
        "feedback_user": "Geoff Pidcock",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response accurately summarizes the key differences mentioned in the likely context regarding evaluation-driven development and non-determinism."
    },
    {
        "id": "d1c24388-764f-4125-81b0-0ddcee8b3299",
        "timestamp": "2025-04-12T07:14:22.046859",
        "question": "What was the content of workshop 1 vs workshop 2, summarised as tweets?",
        "response": "The content of workshop 1 focused on setting up the course wiki, accessing resources, and exploring the course schedule. It also mentioned the use of Zoom for workshops and the importance of setting up the code space before the next session. Workshop 2, on the other hand, will cover topics such as iteration, evaluation, observability, testing, and debugging. It will emphasize first principles rather than specific tools.",
        "num_chunks": 5,
        "context_tokens": 2479,
        "completion_tokens": 83,
        "embedding_tokens": 7680,
        "total_tokens": 10242,
        "latency": 3.13578462600708,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"074ad912-f6fa-498a-b0ce-3a004fe25f95\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"f48fdf4b-7adc-4114-b294-2b56dc4cd3ef\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"d7084bd4-8acb-458a-a496-32d121efee45\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}, {\"id\": \"99043096-59c5-4a9a-80d9-b6c8ce802008\", \"position\": 13, \"relevance\": 1.0, \"tokens\": 406, \"timestamp\": \"00:29:52.640\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:29:52.640]\\nI I wonder if I put\\nhugo bowne-anderson: yes, I did put the shared commitments there, so we'll go through that in a second, and we'll keep keep adding adding things here. And actually, one thing which I, some of you have asked about are the guest lectures from cohort one, and I've created a little guest lecture, Archive and there's there's actually one or 2 missing here, including William Horton, who gave a wonderful talk on, on thinking through when to launch,\\n\\nand how how to think about\\nhugo bowne-anderson: what metrics you want to measure before launch, and how sometimes that can be challenging, and how you really need to iterate on that. But these are all talks from the previous ones.\\n\\nAnd if you click on\\nhugo bowne-anderson: the page, let's click on Nathan's.\\n\\nhugo bowne-anderson: Yeah, we have an AI generated summary. We have a Youtube video. I'll put the slides in soon. Takeaways AI generated, and and so on. So in all honesty, this is the 1st time we've created something like this. So feedback, incredibly incredibly welcome. And by this I mean this type of document that links to different resources and Youtube videos and and that type of stuff. I'm really excited to have it grow with with all of you as well.\\n\\nhugo bowne-anderson:\\n\\nI\\nhugo bowne-anderson: I think that is pretty much it.\\n\\nJust before getting to\\nhugo bowne-anderson: content. Now, Williams, talk isn't like Williams.\\n\\nTalk is actually\\nhugo bowne-anderson: You remember? That was, that was a 2\\u00a0h session that turned into a 4\\u00a0h session and zoom. That also happens. By the way, and I will apologize for that. Y'all are not in like required to stick around,\"}, {\"id\": \"81524ba2-ad8b-47f2-a063-7ff602097fb1\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}]",
        "success": 1,
        "feedback_rating": "FAIL",
        "feedback_reason": "Workshop 2 out of context yet still hallucinated",
        "feedback_notes": null,
        "feedback_user": "Geoff ",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, as it does not specify what the question was or what the response was."
    },
    {
        "id": "5e26728b-5705-4e83-a68f-5ecad0d4c005",
        "timestamp": "2025-04-12T06:56:49.723280",
        "question": "Is this is of course about LLMs. Is it tool focused or first principles focused?",
        "response": "This course is first principles focused. The instructor mentions that they are not tool focused and that they want to help participants develop skills and adopt tools that will be around for several years. They emphasize the importance of principles in building machine learning software and LLM-powered software.",
        "num_chunks": 5,
        "context_tokens": 2393,
        "completion_tokens": 54,
        "embedding_tokens": 7680,
        "total_tokens": 10127,
        "latency": 1.1853768825531006,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"40527365-135c-49f4-815d-598beac04224\", \"position\": 22, \"relevance\": 1.0, \"tokens\": 401, \"timestamp\": \"00:48:18.740\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:48:18.740]\\nAnd\\nhugo bowne-anderson: the answer, the answers come in the in the process that we're here to teach you about in this entire course. And one thing to understand is kind of the flow of the system.\\n\\nSo\\nhugo bowne-anderson: we have our upstream prompt and context being sent to an Llm. Then we have the Llm output, and this being consumed downstream in a variety of ways.\\n\\nhugo bowne-anderson: So what type of principles do we need to really think about then. And another way to frame what we're doing here is, of course, we're using tools the entire time. But we're not tool focused. We're, we're principle focused.\\n\\nAnd\\nhugo bowne-anderson: one of the reasons that'\\n\\ns the case is\\nhugo bowne-anderson: we wanna help you develop skills and adopt tools that we'\\n\\nll be around in\\nhugo bowne-anderson: several years. And I honestly can't guarantee you whether Langchain or Llama Index or crew, AI or any of these things will be around to be honest. But what Stefan and myself and a lot of our community are taking a bet on is that the principles that we learned building machine learning software for years and have started to use building Llm powered software, they will stick around.\\n\\nAnd so\\nhugo bowne-anderson: the 1st principle to recognize is upstream. You have these Api calls you have input and output. And you have knobs. You can tweak there. Right? You have system and user prompts. You have context, right? You have structured outputs, and you have a variety of knobs, such as temperature and top P, which we'll get to later this week.\\n\\nhugo bowne-anderson: Another principle and this is a foundational principle. All of these are is that Llms are non-deterministic.\"}, {\"id\": \"8fcc6975-57cc-4ba0-831b-d0540c81ba66\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"4f4b92d3-0b64-4b93-ae02-c610361c10c9\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"c0cd4e26-875c-4288-83b2-dadea624684b\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}, {\"id\": \"2cd625f5-2450-4b52-b99b-66b94b30a370\", \"position\": 21, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:46:30.010\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:46:30.010]\\nI do want to just take a quick\\nhugo bowne-anderson: detour when we're talking about.\\n\\nhugo bowne-anderson:\\n\\nYou know\\nhugo bowne-anderson: what we get use out of all of these things, for the conversational aspect of Llms is fantastic. I use it all the time. But in my humble estimation most roi will involve automation, not conversations. So, for example, an app that consumes Linkedin profiles finds relevant candidates for a position automates emails to them. That's 1 example that the demo I just showed you perhaps could could be used for.\\n\\nAnd this brings me to my point of and our point of\\nhugo bowne-anderson: really thinking about what we want to evaluate. Okay, so what's cool, you can ask, is the information extracts from Linkedin? Correct? That's a cool question to ask and important, that needs to be satisfied. But remember, we're trying to scale human behavior so, and we want it to result in the same outcomes. But better right? So the next question you might ask, do the emails generated resemble the emails domain experts sent previously.\\n\\nhugo bowne-anderson: also a good question to ask, and who would have thought trying to get a domain expert involved would be so so useful.\\n\\nBut it turns out it is now\\nhugo bowne-anderson: at a very macro level,\\n\\nthough\\nhugo bowne-anderson: you really want to know? Do the emails result in hiring good candidates? And is it more efficient and more cost effective than our previous system right? And it's actually not even clear how long these cycles are.\\n\\nSo making sure that we in the end tie these macro level\\nhugo bowne-anderson: business evaluations to the micro level Llm calls is super important.\\n\\nhugo bowne-anderson: So that brings us back to this. How do we? How do we evaluate a system like this? I don't know what the actual prompt sent to the Llm. Was. How do I give feedback on on system performance? How can I see data and traces and conversations? How can we iterate quickly on this? Mvp.\\n\\nhugo bowne-anderson:\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "This is really nice. It's kind of concise and comprehensive.",
        "feedback_notes": null,
        "feedback_user": "hugo",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "b87d7c3b-e209-46ec-ae63-17bffb45d47e",
        "timestamp": "2025-04-12T06:55:29.031805",
        "question": "What month and year did the workshop take place in?",
        "response": "The workshop transcript sections provided do not mention the month and year in which the workshop took place.",
        "num_chunks": 5,
        "context_tokens": 2375,
        "completion_tokens": 20,
        "embedding_tokens": 7680,
        "total_tokens": 10075,
        "latency": 0.9251601696014404,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"4f4b92d3-0b64-4b93-ae02-c610361c10c9\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"e18abf0d-be1f-4502-b672-494ed5de1dbb\", \"position\": 62, \"relevance\": 1.0, \"tokens\": 302, \"timestamp\": \"01:59:06.670\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:59:06.670]\\nPhilip Kiely: Thank you so much for having me. Thanks everyone for your time today.\\n\\nhugo bowne-anderson: Such a pleasure. Thanks, Philip.\\n\\nhugo bowne-anderson: and everyone else. It's it's time to time to wrap up. I just want to give Philip one more round of applause.\\n\\nGreat\\nhugo bowne-anderson: It is time to wrap up. We do have 2. As as I mentioned before, we have an just an onboarding form. A lot of you have completed it, but if you're if you haven't, and able to, this will allow us, it'll let us know where you are. What you're interested in, and it will allow us to set up the office hours that that we're going to with our wonderful builders in residence as well.\\n\\nOnce again I will share with you\\nhugo bowne-anderson: the feedback form. A bunch of you have already provided a lot of valuable feedback in there, which we'll use to iterate quickly on how we, how we teach and how we approach this course. I'm going to share that in the discord chat also.\\n\\nhugo bowne-anderson: So it's there. But that's it for today, and we'll see you on discord, and we'll see you in 46\\u00a0h for the next workshop as well. So thanks everyone, and thanks for a great 1st session.\"}, {\"id\": \"d7e95b47-950c-4c08-b656-0cf0ef2dda8b\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}, {\"id\": \"1e9fafeb-7265-484f-9616-e23f52f63e85\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}, {\"id\": \"b805408e-4fa8-4b71-82c3-447046211885\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "I'll give it a pass, but perhaps we should include metadata in the transcript for this.",
        "feedback_notes": null,
        "feedback_user": "hugo",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not address the specific question asked as it does not provide any information about the workshop content or context."
    },
    {
        "id": "cf746c51-2a8c-4ac0-83e1-40b12d155dfc",
        "timestamp": "2025-04-12T06:42:56.903273",
        "question": "What month and year did the workshop take place in?",
        "response": "The workshop transcript sections provided do not mention the month and year in which the workshop took place.",
        "num_chunks": 5,
        "context_tokens": 2375,
        "completion_tokens": 20,
        "embedding_tokens": 7680,
        "total_tokens": 10075,
        "latency": 0.8530733585357666,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"74b77363-7853-4b4a-9304-ea8f4eea9d1e\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"e05641dc-6dcf-488b-b2c2-c4e0abd244b6\", \"position\": 62, \"relevance\": 1.0, \"tokens\": 302, \"timestamp\": \"01:59:06.670\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:59:06.670]\\nPhilip Kiely: Thank you so much for having me. Thanks everyone for your time today.\\n\\nhugo bowne-anderson: Such a pleasure. Thanks, Philip.\\n\\nhugo bowne-anderson: and everyone else. It's it's time to time to wrap up. I just want to give Philip one more round of applause.\\n\\nGreat\\nhugo bowne-anderson: It is time to wrap up. We do have 2. As as I mentioned before, we have an just an onboarding form. A lot of you have completed it, but if you're if you haven't, and able to, this will allow us, it'll let us know where you are. What you're interested in, and it will allow us to set up the office hours that that we're going to with our wonderful builders in residence as well.\\n\\nOnce again I will share with you\\nhugo bowne-anderson: the feedback form. A bunch of you have already provided a lot of valuable feedback in there, which we'll use to iterate quickly on how we, how we teach and how we approach this course. I'm going to share that in the discord chat also.\\n\\nhugo bowne-anderson: So it's there. But that's it for today, and we'll see you on discord, and we'll see you in 46\\u00a0h for the next workshop as well. So thanks everyone, and thanks for a great 1st session.\"}, {\"id\": \"83d1c318-95e3-44c3-a42c-a66be0d7e598\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}, {\"id\": \"2bb9495b-a750-46c9-9b3c-695ec53aab19\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}, {\"id\": \"e915d03d-410a-427d-ba2d-3264981c75fa\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}]",
        "success": 1,
        "feedback_rating": null,
        "feedback_reason": null,
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "59fba2e8-c4b8-4abb-b360-a5e3d15e354d",
        "timestamp": "2025-04-12T06:42:02.621978",
        "question": "Did anyone talk about builders in residence?",
        "response": "Yes, Hugo Bowne-Anderson mentioned Jeff Pidcock, Nathan Danielson, and William Horton as the builders in residence who joined for cohort one as participants in the course. They were invited back to work with the participants on building projects and providing assistance.",
        "num_chunks": 5,
        "context_tokens": 2320,
        "completion_tokens": 54,
        "embedding_tokens": 7680,
        "total_tokens": 10054,
        "latency": 1.5947670936584473,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"e915d03d-410a-427d-ba2d-3264981c75fa\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"e05641dc-6dcf-488b-b2c2-c4e0abd244b6\", \"position\": 62, \"relevance\": 1.0, \"tokens\": 302, \"timestamp\": \"01:59:06.670\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:59:06.670]\\nPhilip Kiely: Thank you so much for having me. Thanks everyone for your time today.\\n\\nhugo bowne-anderson: Such a pleasure. Thanks, Philip.\\n\\nhugo bowne-anderson: and everyone else. It's it's time to time to wrap up. I just want to give Philip one more round of applause.\\n\\nGreat\\nhugo bowne-anderson: It is time to wrap up. We do have 2. As as I mentioned before, we have an just an onboarding form. A lot of you have completed it, but if you're if you haven't, and able to, this will allow us, it'll let us know where you are. What you're interested in, and it will allow us to set up the office hours that that we're going to with our wonderful builders in residence as well.\\n\\nOnce again I will share with you\\nhugo bowne-anderson: the feedback form. A bunch of you have already provided a lot of valuable feedback in there, which we'll use to iterate quickly on how we, how we teach and how we approach this course. I'm going to share that in the discord chat also.\\n\\nhugo bowne-anderson: So it's there. But that's it for today, and we'll see you on discord, and we'll see you in 46\\u00a0h for the next workshop as well. So thanks everyone, and thanks for a great 1st session.\"}, {\"id\": \"639049ea-89bd-45c5-a055-322500b4ad0c\", \"position\": 11, \"relevance\": 1.0, \"tokens\": 445, \"timestamp\": \"00:26:25.726\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:26:25.726]\\nhugo bowne-anderson: Pretty, please do that.\\n\\nhugo bowne-anderson:\\n\\nand I just encourage you all to\\nhugo bowne-anderson: use. I mean, use these tools as much as you can while building during the course, because we're here to support and talk about them and and build with you. I do want to say I do appreciate. Everyone likely has more than full time, jobs and families, and all of these things or subsets of these. So I do understand, particularly in our line of work.\\n\\nTime is an incredibly precious\\nhugo bowne-anderson: resource.\\n\\nSo\\nhugo bowne-anderson: all that's to say is, if you don't have much time to build outside, that's totally cool. If you, if all you do is attend these workshops and nothing else. You'll get a huge amount out of the course if you keep building also, and keep in the discords, and then join the office. Hours and pods will set up, you'll get even even more so. I like to think the world's your oyster in proverbial oyster in a lot of ways.\\n\\nSo just getting started in terms of\\nhugo bowne-anderson: set up.\\n\\nhugo bowne-anderson: We use several tools, and my goal is to use as few tools as possible.\\n\\nI will rarely adopt a new tool\\nhugo bowne-anderson: if I don't have to. So in the past we used in the first.st So in the 1st cohort, we use Google drive. This is for slides supporting material. This type of stuff we use github and codespaces for code and also codespaces, feel free to clone the repository and do what you want with it, but we want to make sure that you can get set up and up and running as quickly as possible, and I'll introduce you to code spaces later. It'\\n\\ns kind of\\nhugo bowne-anderson: Google colab on steroids or Vs code superpowered in the browser. We use discord for the Async Chat announcements, and the Q.\"}, {\"id\": \"03208153-ee98-4042-a567-d04d0e764996\", \"position\": 27, \"relevance\": 1.0, \"tokens\": 474, \"timestamp\": \"00:57:20.840\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:57:20.840]\\nhugo bowne-anderson: Absolutely love it. And I also just noticed in the chat Vishut went. This is probably when I spoke about proof of concept purgatory. Vishrud has faced issues when he used Mvp. Without context. In North America it's used for most valuable player totally agree,\\n\\nand it shows how much\\nhugo bowne-anderson: how most people I speak with at least professionally work in tech and know what know that it means. That right?\\n\\nhugo bowne-anderson: awesome. Well, I'm just. I can't see everything in discord at the moment,\\n\\nbut so much fantastic conversation and\\nhugo bowne-anderson: questions as as well. So if anyone.\\n\\nhugo bowne-anderson: I'm gonna open a window right now. But if anyone doesn't have access to github,\\n\\ncould you\\nhugo bowne-anderson: just put your handle in the workshop? One channel and I will add you almost in real time.\\n\\nhugo bowne-anderson: And the reason for that is with Github has changed certain things so that I actually can't assign anyone else to be admin currently as it's under my personal.\\n\\nhugo bowne-anderson: Okay, we have Vinysh. Oh, oh,\\n\\nI love this and I do hope that\\nhugo bowne-anderson: you're all okay with us. Just taking 2\\n\\nmin to\\nhugo bowne-anderson: add a few more people. Oh, this is great.\\n\\nhugo bowne-anderson: amazing.\\n\\nNathan Danielsen: Well, while people are doing that, yeah. Want to comment on the the rich conversations that's happening in discord right now. And from the 1st kind of like run of this course. This is what that the conversations are. One of the highlights as well. So just calling that out. That's a lot of good stuff. A lot of smart people sharing resources there. So check out the discord for the session.\\n\\nhugo bowne-anderson: I really appreciate that. And in fact, I know it. I mean, we we started building this right to do a court. We actually started as a workshop in Austin last year, Stefan and myself,\"}, {\"id\": \"9f3ca935-772c-4892-9fbb-f61516363e46\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "I'm giving this a pass because it's comprehensive and correct except for typos in people's names, but I presume that is due to the transcript and not the information retrieval system, although we should consider the transcript as part of the AI system, so maybe we want to work on that. So keep this in mind.",
        "feedback_notes": null,
        "feedback_user": "hugo",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, making it unhelpful and irrelevant."
    },
    {
        "id": "d3bc3f3a-b1e1-4717-a5a9-b8a20f1a5a12",
        "timestamp": "2025-04-12T06:40:37.752760",
        "question": "Who are the instructors in this workshop?",
        "response": "The instructors in this workshop are Hugo Bowne-Anderson and Stefan Krawczyk.",
        "num_chunks": 5,
        "context_tokens": 2352,
        "completion_tokens": 20,
        "embedding_tokens": 7680,
        "total_tokens": 10052,
        "latency": 1.7558724880218506,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"e915d03d-410a-427d-ba2d-3264981c75fa\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"ef250e6a-fc69-47b1-8cd0-e3d906a4fb97\", \"position\": 0, \"relevance\": 1.0, \"tokens\": 487, \"timestamp\": \"00:00:14.050\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:00:14.050]\\nhugo bowne-anderson: All right. Welcome everyone. Hugo Bowen Anderson, here so excited to be kicking off workshop. One of building Llm. Powered applications for data, scientists, software engineers, and whoever else wants to get on this rocket ship together, love that. I can see a bunch of friendly faces already. We'll get to this.\\n\\nBut\\nhugo bowne-anderson: if you're able to turn your camera on, I, personally would really appreciate it, and I can tell you it makes me a better teacher as well to see a bunch of faces, and to see all the, all the engagement as well, and only if you're able to, of course, and generally microphones off when not speaking as well.\\n\\nhugo bowne-anderson: I'm I'm so excited to have you all here already, seeing what you all are up to in the discord in the forms you filled in really appreciate you filling in the onboarding form as well. We'\\n\\nve got a bunch of really serious builders who seem a lot of fun also so really excited to get to know you all\\nhugo bowne-anderson: as well. So my name is Hugo Band Anderson. I've worked in data, science and machine learning, and what now we call AI for far out 15 years now. So I feel a bit old to to be honest. I've worked in building, in education, in consulting and and devrel. Also a lot of work in devrel for open, open source stuff.\\n\\nhugo bowne-anderson: so like my, I think my, my.\\n\\nhugo bowne-anderson: my background really has been in doing scientific research using the Pi data stack that then turned into software stuff. So that's really where I come from. In the past couple of years I've been building a lot with generative AI and helping a lot of other people to build also.\\n\\nhugo bowne-anderson: But that really brings up my my background is in scientific research, in doing stuff, in notebooks, in doing my best to productionize stuff without throwing it over the wall to software engineers, which is one of the reasons I teamed up with with Stefan, who is my co-instructor and colleague and friend here, so I'll just hand it over to Stefan to say a few words.\"}, {\"id\": \"688abe96-168a-48d1-bc3e-2969d72673f6\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}, {\"id\": \"e05641dc-6dcf-488b-b2c2-c4e0abd244b6\", \"position\": 62, \"relevance\": 1.0, \"tokens\": 302, \"timestamp\": \"01:59:06.670\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:59:06.670]\\nPhilip Kiely: Thank you so much for having me. Thanks everyone for your time today.\\n\\nhugo bowne-anderson: Such a pleasure. Thanks, Philip.\\n\\nhugo bowne-anderson: and everyone else. It's it's time to time to wrap up. I just want to give Philip one more round of applause.\\n\\nGreat\\nhugo bowne-anderson: It is time to wrap up. We do have 2. As as I mentioned before, we have an just an onboarding form. A lot of you have completed it, but if you're if you haven't, and able to, this will allow us, it'll let us know where you are. What you're interested in, and it will allow us to set up the office hours that that we're going to with our wonderful builders in residence as well.\\n\\nOnce again I will share with you\\nhugo bowne-anderson: the feedback form. A bunch of you have already provided a lot of valuable feedback in there, which we'll use to iterate quickly on how we, how we teach and how we approach this course. I'm going to share that in the discord chat also.\\n\\nhugo bowne-anderson: So it's there. But that's it for today, and we'll see you on discord, and we'll see you in 46\\u00a0h for the next workshop as well. So thanks everyone, and thanks for a great 1st session.\"}, {\"id\": \"74b77363-7853-4b4a-9304-ea8f4eea9d1e\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "accurate and no extraneous  info",
        "feedback_notes": null,
        "feedback_user": "hugo",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "4e9f0a5a-0b02-42b9-aa39-245925891ffb",
        "timestamp": "2025-04-12T01:59:37.398606",
        "question": "What are the top five topics covered in this workshop?",
        "response": "The top five topics covered in this workshop are:\n\n1. Housekeeping and logistics related to the workshop, such as recording and sharing materials.\n2. The foundations of LL(M) software and evaluation-driven development.\n3. Building software powered by machine learning and LL(M), including prompt engineering, embeddings, fine-tuning business logic, unit tests, versioning, and continuous integration.\n4. Monitoring and evaluating LL(M) software, including monitoring individual LL(M) calls and their impact on business metrics.\n5. The use of tools like Zoom, Discord, and Code Spaces for the workshop.",
        "num_chunks": 5,
        "context_tokens": 2515,
        "completion_tokens": 119,
        "embedding_tokens": 7680,
        "total_tokens": 10314,
        "latency": 1.7099244594573977,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"c4b8b1af-eb1a-4a2b-bfde-a0c69917ee5a\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"e3038b2f-bea0-4da0-9256-36e3ff99fa29\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}, {\"id\": \"aacbef40-33a6-41a0-aca9-8b21b1fa3db5\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"d01ac2fa-9386-4581-ac2b-a0bbb92ac1e4\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"4f1185c0-6269-42cb-9f6f-154b7530da4f\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "prettu good! missed building apps that get into purgatory tho?",
        "feedback_notes": null,
        "feedback_user": "hugo",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "2d1e3753-3862-481b-940b-0c9312f3063f",
        "timestamp": "2025-04-12T01:36:19.703915",
        "question": "What is the main worldview of this workshop?",
        "response": "The main worldview of this workshop is focused on iterative development and evaluation of AI-powered applications. The workshop emphasizes the importance of logging inputs and outputs, using domain-specific expertise to evaluate output, building systems and processes for automation and assessment, aligning outputs with business metrics, and optimizing workflows for measurable return on investment.",
        "num_chunks": 5,
        "context_tokens": 2546,
        "completion_tokens": 63,
        "embedding_tokens": 7680,
        "total_tokens": 10289,
        "latency": 1.15753436088562,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"6c121ce2-7a98-4a96-b350-65b0bafd6998\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}, {\"id\": \"b05952a8-e551-4871-bca1-e27431187e71\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"9235fae1-7ef7-4090-ab54-5a1ec19f25b1\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}, {\"id\": \"d3823c2f-5a9d-4361-a5ea-1f3f447f150b\", \"position\": 24, \"relevance\": 1.0, \"tokens\": 482, \"timestamp\": \"00:52:20.970\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:52:20.970]\\nhugo bowne-anderson: and then perhaps you monitor for a while, figure out what's up, make some small changes, whatever it is. And then you start working on the next version, and there will be version releases. Then, right? So you will start working again and iterating.\\n\\nhugo bowne-anderson: based on what you how you see your software is performing. But the point is that you're iterating on the next version of it as opposed to having something continuously changing and continuously iterating.\\n\\nhugo bowne-anderson:\\n\\nSo we have software specs\\nhugo bowne-anderson: for Llm. Powered applications right? And this is an iterative process that spans development and production. You have software specs, you build, you deploy your value, you monitor and evaluate, including all of these things that I really I mentioned at the start of this workshop which we'll get into in this course.\\n\\nhugo bowne-anderson:\\n\\nSo\\nhugo bowne-anderson: the question I said at the start, how do we get out of aic a a Oc AI poc, I actually should change that because someone said someone actually said to me, they didn't know what a proof of concept was, and they thought I was using the term person of color purgatory.\\n\\nAnd I I definitely have never intended that so I probably should should change that\\nhugo bowne-anderson: So the 1st challenge non-determinism. How do we deal with that? We log inputs and outputs. We evaluate logs. We iterate on prompts and context, we use Api knobs to reduce variance.\\n\\nhugo bowne-anderson: How about the challenge of hallucinations?\\n\\nhugo bowne-anderson: Well, similarly, we log inputs and outputs in dev and prod, we use domain specific expertise to evaluate output. In both, we build systems and processes to automate assessments such as unit tests and data sets. So testing sets product feedback hooks. Similarly, for for evaluation.\\n\\nhugo bowne-anderson: for iteration, we build a software development lifecycle that enables you to quickly build, deploy, monitor and evaluate. And in terms of business value. We really need to align outputs with business metric and optimize workflows to achieve measurable return on investment.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"9e901a3e-b650-4215-be06-6a9fcfa3149f\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "pretty pretty good!",
        "feedback_notes": "took 15 seconds",
        "feedback_user": "hugo",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response is not provided in the example, so there is no content to evaluate. The evaluation criteria of helpfulness, relevance, and directness cannot be applied without a specific response."
    },
    {
        "id": "b58025f5-c92c-417b-8098-24b189ad6bb6",
        "timestamp": "2025-04-12T01:31:04.860596",
        "question": "Does anybody mention the Builders in Residence Program?",
        "response": "Yes, Hugo Bowne-Anderson mentions the Builders in Residence Program in the workshop transcript. He introduces Jeff Pidcock, Nathan Danielson, and William Horton as participants in the program who will be working with the students on building projects.",
        "num_chunks": 5,
        "context_tokens": 2321,
        "completion_tokens": 50,
        "embedding_tokens": 7680,
        "total_tokens": 10051,
        "latency": 3.372382402420044,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"7469514f-c606-4ac3-8b30-0179c5fb9ad3\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"96ca4f76-187c-4bd9-b1ce-f72b80893210\", \"position\": 11, \"relevance\": 1.0, \"tokens\": 445, \"timestamp\": \"00:26:25.726\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:26:25.726]\\nhugo bowne-anderson: Pretty, please do that.\\n\\nhugo bowne-anderson:\\n\\nand I just encourage you all to\\nhugo bowne-anderson: use. I mean, use these tools as much as you can while building during the course, because we're here to support and talk about them and and build with you. I do want to say I do appreciate. Everyone likely has more than full time, jobs and families, and all of these things or subsets of these. So I do understand, particularly in our line of work.\\n\\nTime is an incredibly precious\\nhugo bowne-anderson: resource.\\n\\nSo\\nhugo bowne-anderson: all that's to say is, if you don't have much time to build outside, that's totally cool. If you, if all you do is attend these workshops and nothing else. You'll get a huge amount out of the course if you keep building also, and keep in the discords, and then join the office. Hours and pods will set up, you'll get even even more so. I like to think the world's your oyster in proverbial oyster in a lot of ways.\\n\\nSo just getting started in terms of\\nhugo bowne-anderson: set up.\\n\\nhugo bowne-anderson: We use several tools, and my goal is to use as few tools as possible.\\n\\nI will rarely adopt a new tool\\nhugo bowne-anderson: if I don't have to. So in the past we used in the first.st So in the 1st cohort, we use Google drive. This is for slides supporting material. This type of stuff we use github and codespaces for code and also codespaces, feel free to clone the repository and do what you want with it, but we want to make sure that you can get set up and up and running as quickly as possible, and I'll introduce you to code spaces later. It'\\n\\ns kind of\\nhugo bowne-anderson: Google colab on steroids or Vs code superpowered in the browser. We use discord for the Async Chat announcements, and the Q.\"}, {\"id\": \"25fb53f8-f4d0-4df9-a08b-d2d8560d6484\", \"position\": 62, \"relevance\": 1.0, \"tokens\": 302, \"timestamp\": \"01:59:06.670\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:59:06.670]\\nPhilip Kiely: Thank you so much for having me. Thanks everyone for your time today.\\n\\nhugo bowne-anderson: Such a pleasure. Thanks, Philip.\\n\\nhugo bowne-anderson: and everyone else. It's it's time to time to wrap up. I just want to give Philip one more round of applause.\\n\\nGreat\\nhugo bowne-anderson: It is time to wrap up. We do have 2. As as I mentioned before, we have an just an onboarding form. A lot of you have completed it, but if you're if you haven't, and able to, this will allow us, it'll let us know where you are. What you're interested in, and it will allow us to set up the office hours that that we're going to with our wonderful builders in residence as well.\\n\\nOnce again I will share with you\\nhugo bowne-anderson: the feedback form. A bunch of you have already provided a lot of valuable feedback in there, which we'll use to iterate quickly on how we, how we teach and how we approach this course. I'm going to share that in the discord chat also.\\n\\nhugo bowne-anderson: So it's there. But that's it for today, and we'll see you on discord, and we'll see you in 46\\u00a0h for the next workshop as well. So thanks everyone, and thanks for a great 1st session.\"}, {\"id\": \"c9c26123-b50a-413d-ac0f-dc32e504ba06\", \"position\": 27, \"relevance\": 1.0, \"tokens\": 474, \"timestamp\": \"00:57:20.840\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:57:20.840]\\nhugo bowne-anderson: Absolutely love it. And I also just noticed in the chat Vishut went. This is probably when I spoke about proof of concept purgatory. Vishrud has faced issues when he used Mvp. Without context. In North America it's used for most valuable player totally agree,\\n\\nand it shows how much\\nhugo bowne-anderson: how most people I speak with at least professionally work in tech and know what know that it means. That right?\\n\\nhugo bowne-anderson: awesome. Well, I'm just. I can't see everything in discord at the moment,\\n\\nbut so much fantastic conversation and\\nhugo bowne-anderson: questions as as well. So if anyone.\\n\\nhugo bowne-anderson: I'm gonna open a window right now. But if anyone doesn't have access to github,\\n\\ncould you\\nhugo bowne-anderson: just put your handle in the workshop? One channel and I will add you almost in real time.\\n\\nhugo bowne-anderson: And the reason for that is with Github has changed certain things so that I actually can't assign anyone else to be admin currently as it's under my personal.\\n\\nhugo bowne-anderson: Okay, we have Vinysh. Oh, oh,\\n\\nI love this and I do hope that\\nhugo bowne-anderson: you're all okay with us. Just taking 2\\n\\nmin to\\nhugo bowne-anderson: add a few more people. Oh, this is great.\\n\\nhugo bowne-anderson: amazing.\\n\\nNathan Danielsen: Well, while people are doing that, yeah. Want to comment on the the rich conversations that's happening in discord right now. And from the 1st kind of like run of this course. This is what that the conversations are. One of the highlights as well. So just calling that out. That's a lot of good stuff. A lot of smart people sharing resources there. So check out the discord for the session.\\n\\nhugo bowne-anderson: I really appreciate that. And in fact, I know it. I mean, we we started building this right to do a court. We actually started as a workshop in Austin last year, Stefan and myself,\"}, {\"id\": \"d177e05a-73a8-410a-b57a-ac72f9cb7b06\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "Yeah, this is correct. There are typos in the builders in residence names, but that's probably from the transcripts. So something we'd want to fix there and not necessarily in the AI system, although of course transcripts are part of AI system.",
        "feedback_notes": null,
        "feedback_user": "hugo",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response is not provided in the example, so there is no content to evaluate. The evaluation criteria cannot be applied without an actual response."
    },
    {
        "id": "f337413f-5ad4-4126-bcea-0976fff4cf12",
        "timestamp": "2025-04-12T01:29:58.176225",
        "question": "Who are the instructors?",
        "response": "The instructors mentioned in the provided sections are Hugo Bowne-Anderson and Stefan Krawczyk.",
        "num_chunks": 5,
        "context_tokens": 2553,
        "completion_tokens": 22,
        "embedding_tokens": 7680,
        "total_tokens": 10255,
        "latency": 1.5657482147216797,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"176918a3-f9a2-4efe-a666-98311df33a1e\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}, {\"id\": \"7469514f-c606-4ac3-8b30-0179c5fb9ad3\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"1b2bfb26-63ac-4b4d-b854-5ad648455001\", \"position\": 0, \"relevance\": 1.0, \"tokens\": 487, \"timestamp\": \"00:00:14.050\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:00:14.050]\\nhugo bowne-anderson: All right. Welcome everyone. Hugo Bowen Anderson, here so excited to be kicking off workshop. One of building Llm. Powered applications for data, scientists, software engineers, and whoever else wants to get on this rocket ship together, love that. I can see a bunch of friendly faces already. We'll get to this.\\n\\nBut\\nhugo bowne-anderson: if you're able to turn your camera on, I, personally would really appreciate it, and I can tell you it makes me a better teacher as well to see a bunch of faces, and to see all the, all the engagement as well, and only if you're able to, of course, and generally microphones off when not speaking as well.\\n\\nhugo bowne-anderson: I'm I'm so excited to have you all here already, seeing what you all are up to in the discord in the forms you filled in really appreciate you filling in the onboarding form as well. We'\\n\\nve got a bunch of really serious builders who seem a lot of fun also so really excited to get to know you all\\nhugo bowne-anderson: as well. So my name is Hugo Band Anderson. I've worked in data, science and machine learning, and what now we call AI for far out 15 years now. So I feel a bit old to to be honest. I've worked in building, in education, in consulting and and devrel. Also a lot of work in devrel for open, open source stuff.\\n\\nhugo bowne-anderson: so like my, I think my, my.\\n\\nhugo bowne-anderson: my background really has been in doing scientific research using the Pi data stack that then turned into software stuff. So that's really where I come from. In the past couple of years I've been building a lot with generative AI and helping a lot of other people to build also.\\n\\nhugo bowne-anderson: But that really brings up my my background is in scientific research, in doing stuff, in notebooks, in doing my best to productionize stuff without throwing it over the wall to software engineers, which is one of the reasons I teamed up with with Stefan, who is my co-instructor and colleague and friend here, so I'll just hand it over to Stefan to say a few words.\"}, {\"id\": \"17f3301b-d6c4-4cda-9ff3-f165e3012300\", \"position\": 14, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:31:23.130\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:31:23.130]\\nbut sometimes we\\nhugo bowne-anderson: really get and get into it. But zoom cut. Cut up that video so so many times that I'm needing to stitch certain things back together. So a little bit about what I call shared commitments. I don't want to get to like consultancy or whatever, but I do. I do just want to make clear you all. Do you? Right? For sure. We we want you here to bring everything that you are. But I do want to say this course does work best when everyone's engaged and present, so, if possible.\\n\\nhugo bowne-anderson: keep your camera on. Helps us teach better when we can see who we're working with. Keep your mic off unless you're speaking.\\n\\nhugo bowne-anderson: Ask questions early and often. We love participation. On top of that.\\n\\nhugo bowne-anderson: It's very rare that questions in a course like this are uncorrelated. What I mean by that is, if you have a question almost guaranteed. Several other people have the same, if not a related question. So you're doing everyone a favor and help each other out on discord as well. You're building with awesome peers.\\n\\nI just do want to give a shout out to\\nhugo bowne-anderson: to Greg Gandenberger, did I pronounce that correctly, Greg, close enough.\\n\\ngreg: You got it? Yep.\\n\\nhugo bowne-anderson: Awesome who's already been helping out and getting people fixed up with with bugs in my end example, which are invisible bugs. In fact, among other things, Greg has already issued 2 pull requests to the repository we'll get to, and that is so cool, so please do as much as time permits, but engage with each other and and help each other out.\\n\\nSo\\nhugo bowne-anderson: really, really fantastic to have you all here.\\n\\nAnd\\nhugo bowne-anderson: wow! This slide still scares me, but it's it's real, it's it's real pain.\\n\\nAnd for some reason my\\nhugo bowne-anderson: screen isn't quite rendering everything it's slightly bigger than it it should be.\\n\\nBut what I want to say is that\\nhugo bowne-anderson: if you think about as you see here.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"1391744c-0420-4950-a0c9-07973be164f1\", \"position\": 8, \"relevance\": 1.0, \"tokens\": 497, \"timestamp\": \"00:19:54.940\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:19:54.940]\\nSo\\nhugo bowne-anderson: I hinted at this. But what this course isn't, it is not a deep dive into every Llm. Tool or trend. Of course we'll be doing. We'll be doing a bunch on agents actually, in the second half of the course, and rag and embeddings and more. But the focus is on workflows, not tools, I honestly think, and I'm happy to chat about those and message about those to be honest. But you will have enough resources on that. What we're teaching is what we'\\n\\nve really noticed is a huge gap\\nhugo bowne-anderson: in education around this stuff. This is not a plug and play AI recipe book. They don't even exist. If someone tries to tell you that or sell you that I'd love to hear it. What you'll learn is how to iterate, debug and adapt not just follow step by step. Templates. Okay, once again, this is not some, you know. Hyper, scaled, load balance, multi agent, guide. This course is about getting you moving, not solving every scaling challenge,\\n\\nbut really approaching the workflow\\nhugo bowne-anderson: of how to get things in production and then keep iterating on them.\\n\\nhugo bowne-anderson: So I'm gonna put this. This is incredibly important. This is an onboarding form that actually 25 of you have completed already. And I'm so happy with with that number so far. Usually, I try to say I try to give a form of 5 to 10\\u00a0min, but I honestly think if you all take 10 to 15\\u00a0min to complete this form. It will make this workshop and community really, really special. Okay.\\n\\nhugo bowne-anderson: so and so I just saw Jeff's note. That's in discord. That's that is brilliant.\\n\\nhugo bowne-anderson: And so I do think the the more we know about you and your interests, just because there are 5 of us now as as well. Right and geographically distributed, so the more we can we can be of help.\\n\\nhugo bowne-anderson: Jeff. Nathan has shared the course Wiki page, which we'll get to in a second,\\n\\nand part of that is\\nhugo bowne-anderson: the compute credit access form. Now I'\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "correct and no extraneous info",
        "feedback_notes": "none",
        "feedback_user": "hugo",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, making it unhelpful and irrelevant."
    },
    {
        "id": "b906307c-bb30-4d60-a7df-70783b1c2f8d",
        "timestamp": "2025-04-12T01:28:10.523217",
        "question": "Does anyone talk about a builders in residence program here?",
        "response": "Yes, Hugo Bowne-Anderson mentions the builders in residence program in the workshop transcript. He introduces Jeff Pidcock, Nathan Danielson, and William Horton as participants in the course who have joined the builders in residence program. They will be working with the participants to help them build and answer questions.",
        "num_chunks": 5,
        "context_tokens": 2323,
        "completion_tokens": 63,
        "embedding_tokens": 7680,
        "total_tokens": 10066,
        "latency": 2.4230003356933594,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"7469514f-c606-4ac3-8b30-0179c5fb9ad3\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"96ca4f76-187c-4bd9-b1ce-f72b80893210\", \"position\": 11, \"relevance\": 1.0, \"tokens\": 445, \"timestamp\": \"00:26:25.726\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:26:25.726]\\nhugo bowne-anderson: Pretty, please do that.\\n\\nhugo bowne-anderson:\\n\\nand I just encourage you all to\\nhugo bowne-anderson: use. I mean, use these tools as much as you can while building during the course, because we're here to support and talk about them and and build with you. I do want to say I do appreciate. Everyone likely has more than full time, jobs and families, and all of these things or subsets of these. So I do understand, particularly in our line of work.\\n\\nTime is an incredibly precious\\nhugo bowne-anderson: resource.\\n\\nSo\\nhugo bowne-anderson: all that's to say is, if you don't have much time to build outside, that's totally cool. If you, if all you do is attend these workshops and nothing else. You'll get a huge amount out of the course if you keep building also, and keep in the discords, and then join the office. Hours and pods will set up, you'll get even even more so. I like to think the world's your oyster in proverbial oyster in a lot of ways.\\n\\nSo just getting started in terms of\\nhugo bowne-anderson: set up.\\n\\nhugo bowne-anderson: We use several tools, and my goal is to use as few tools as possible.\\n\\nI will rarely adopt a new tool\\nhugo bowne-anderson: if I don't have to. So in the past we used in the first.st So in the 1st cohort, we use Google drive. This is for slides supporting material. This type of stuff we use github and codespaces for code and also codespaces, feel free to clone the repository and do what you want with it, but we want to make sure that you can get set up and up and running as quickly as possible, and I'll introduce you to code spaces later. It'\\n\\ns kind of\\nhugo bowne-anderson: Google colab on steroids or Vs code superpowered in the browser. We use discord for the Async Chat announcements, and the Q.\"}, {\"id\": \"c9c26123-b50a-413d-ac0f-dc32e504ba06\", \"position\": 27, \"relevance\": 1.0, \"tokens\": 474, \"timestamp\": \"00:57:20.840\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:57:20.840]\\nhugo bowne-anderson: Absolutely love it. And I also just noticed in the chat Vishut went. This is probably when I spoke about proof of concept purgatory. Vishrud has faced issues when he used Mvp. Without context. In North America it's used for most valuable player totally agree,\\n\\nand it shows how much\\nhugo bowne-anderson: how most people I speak with at least professionally work in tech and know what know that it means. That right?\\n\\nhugo bowne-anderson: awesome. Well, I'm just. I can't see everything in discord at the moment,\\n\\nbut so much fantastic conversation and\\nhugo bowne-anderson: questions as as well. So if anyone.\\n\\nhugo bowne-anderson: I'm gonna open a window right now. But if anyone doesn't have access to github,\\n\\ncould you\\nhugo bowne-anderson: just put your handle in the workshop? One channel and I will add you almost in real time.\\n\\nhugo bowne-anderson: And the reason for that is with Github has changed certain things so that I actually can't assign anyone else to be admin currently as it's under my personal.\\n\\nhugo bowne-anderson: Okay, we have Vinysh. Oh, oh,\\n\\nI love this and I do hope that\\nhugo bowne-anderson: you're all okay with us. Just taking 2\\n\\nmin to\\nhugo bowne-anderson: add a few more people. Oh, this is great.\\n\\nhugo bowne-anderson: amazing.\\n\\nNathan Danielsen: Well, while people are doing that, yeah. Want to comment on the the rich conversations that's happening in discord right now. And from the 1st kind of like run of this course. This is what that the conversations are. One of the highlights as well. So just calling that out. That's a lot of good stuff. A lot of smart people sharing resources there. So check out the discord for the session.\\n\\nhugo bowne-anderson: I really appreciate that. And in fact, I know it. I mean, we we started building this right to do a court. We actually started as a workshop in Austin last year, Stefan and myself,\"}, {\"id\": \"25fb53f8-f4d0-4df9-a08b-d2d8560d6484\", \"position\": 62, \"relevance\": 1.0, \"tokens\": 302, \"timestamp\": \"01:59:06.670\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:59:06.670]\\nPhilip Kiely: Thank you so much for having me. Thanks everyone for your time today.\\n\\nhugo bowne-anderson: Such a pleasure. Thanks, Philip.\\n\\nhugo bowne-anderson: and everyone else. It's it's time to time to wrap up. I just want to give Philip one more round of applause.\\n\\nGreat\\nhugo bowne-anderson: It is time to wrap up. We do have 2. As as I mentioned before, we have an just an onboarding form. A lot of you have completed it, but if you're if you haven't, and able to, this will allow us, it'll let us know where you are. What you're interested in, and it will allow us to set up the office hours that that we're going to with our wonderful builders in residence as well.\\n\\nOnce again I will share with you\\nhugo bowne-anderson: the feedback form. A bunch of you have already provided a lot of valuable feedback in there, which we'll use to iterate quickly on how we, how we teach and how we approach this course. I'm going to share that in the discord chat also.\\n\\nhugo bowne-anderson: So it's there. But that's it for today, and we'll see you on discord, and we'll see you in 46\\u00a0h for the next workshop as well. So thanks everyone, and thanks for a great 1st session.\"}, {\"id\": \"d177e05a-73a8-410a-b57a-ac72f9cb7b06\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "nice!",
        "feedback_notes": null,
        "feedback_user": "hugo",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information relevant to the question asked, as it does not specify what the question was or what the response was."
    },
    {
        "id": "8cac24b1-f113-494c-b358-b851a9a29e8b",
        "timestamp": "2025-04-12T01:13:54.842789",
        "question": "Who are the guest lecturers in this course?",
        "response": "The guest lecturers in this course include Hamil Hussein from parlance labs, Eric Ma from Moderna, Ravin Kumar from Google Deepmind, and Ines Montani from Spacey.",
        "num_chunks": 5,
        "context_tokens": 2448,
        "completion_tokens": 40,
        "embedding_tokens": 7680,
        "total_tokens": 10168,
        "latency": 1.6807711124420166,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"534edc6c-fdb0-47df-9fd5-ccaefda7cd37\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}, {\"id\": \"4ef68589-d878-49ec-9e98-13b1e68e69a3\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"fd366711-a6c0-4bec-9a96-e7e4961b1832\", \"position\": 1, \"relevance\": 1.0, \"tokens\": 471, \"timestamp\": \"00:02:47.710\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 00:02:47.710]\\nStefan Krawczyk: Cool. Hi, everyone welcome so name Stefan Craftyk. I'm based in San Francisco. But by my judging by my accent, if you can tell, I'm from New Zealand, not Australia.\\n\\nSo\\nStefan Krawczyk: in terms of yeah, like my background effectively for the last 10 years has been around Mlops. So if you heard the term machine learning operations. That's kind of where I kind of cut a lot of my teeth in terms of helping data scientists and machine learning. Engineers in particular go from prototype to productionization. More recently, in the last few years I've been the CEO of a company called Dagworks, where we've been driving to open source projects called Hamilton and Burr,\\n\\nand the thesis around there is that the same\\nStefan Krawczyk: problems that you had with Mlops are the same ones you have with Gen. AI, specifically, you need to understand and observe a lot around your data. And once you know more about your data, you can actually improve your whatever apps you'\\n\\nre kind of building\\nStefan Krawczyk: news news for you guys. So like, I didn't introduce myself to the CEO, because, actually, the company's actually been absorbed by a large public company,\\n\\nso\\nStefan Krawczyk: can't talk about it. But all I can say is, I'm helping them with their kind of agent efforts. And so in particular, yeah, how to get to production. So I will have I'll be on discord mostly, but otherwise I'll have a few sessions throughout this course that will talk a little bit more about some of the production stuff. And so just to let you know this is, you know, this firsthand stuff.\\n\\nStefan Krawczyk: anything relevant I left out of my intro Hugo, or.\\n\\nhugo bowne-anderson: No, I'll just say on under friend Da. Stefan has told me where he's where he's he's working, and I hope we get to announce it throughout the course. Because he's a really incredible place as far as I'm I'm concerned, supporting cutting edge at agentic work. So it's really very, very exciting.\"}, {\"id\": \"69b2eb7a-2152-4f06-945b-59d77c1355cc\", \"position\": 8, \"relevance\": 1.0, \"tokens\": 497, \"timestamp\": \"00:19:54.940\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:19:54.940]\\nSo\\nhugo bowne-anderson: I hinted at this. But what this course isn't, it is not a deep dive into every Llm. Tool or trend. Of course we'll be doing. We'll be doing a bunch on agents actually, in the second half of the course, and rag and embeddings and more. But the focus is on workflows, not tools, I honestly think, and I'm happy to chat about those and message about those to be honest. But you will have enough resources on that. What we're teaching is what we'\\n\\nve really noticed is a huge gap\\nhugo bowne-anderson: in education around this stuff. This is not a plug and play AI recipe book. They don't even exist. If someone tries to tell you that or sell you that I'd love to hear it. What you'll learn is how to iterate, debug and adapt not just follow step by step. Templates. Okay, once again, this is not some, you know. Hyper, scaled, load balance, multi agent, guide. This course is about getting you moving, not solving every scaling challenge,\\n\\nbut really approaching the workflow\\nhugo bowne-anderson: of how to get things in production and then keep iterating on them.\\n\\nhugo bowne-anderson: So I'm gonna put this. This is incredibly important. This is an onboarding form that actually 25 of you have completed already. And I'm so happy with with that number so far. Usually, I try to say I try to give a form of 5 to 10\\u00a0min, but I honestly think if you all take 10 to 15\\u00a0min to complete this form. It will make this workshop and community really, really special. Okay.\\n\\nhugo bowne-anderson: so and so I just saw Jeff's note. That's in discord. That's that is brilliant.\\n\\nhugo bowne-anderson: And so I do think the the more we know about you and your interests, just because there are 5 of us now as as well. Right and geographically distributed, so the more we can we can be of help.\\n\\nhugo bowne-anderson: Jeff. Nathan has shared the course Wiki page, which we'll get to in a second,\\n\\nand part of that is\\nhugo bowne-anderson: the compute credit access form. Now I'\"}, {\"id\": \"b37a95c0-cac3-4c2a-a4d5-36ca41c015a7\", \"position\": 13, \"relevance\": 1.0, \"tokens\": 406, \"timestamp\": \"00:29:52.640\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:29:52.640]\\nI I wonder if I put\\nhugo bowne-anderson: yes, I did put the shared commitments there, so we'll go through that in a second, and we'll keep keep adding adding things here. And actually, one thing which I, some of you have asked about are the guest lectures from cohort one, and I've created a little guest lecture, Archive and there's there's actually one or 2 missing here, including William Horton, who gave a wonderful talk on, on thinking through when to launch,\\n\\nand how how to think about\\nhugo bowne-anderson: what metrics you want to measure before launch, and how sometimes that can be challenging, and how you really need to iterate on that. But these are all talks from the previous ones.\\n\\nAnd if you click on\\nhugo bowne-anderson: the page, let's click on Nathan's.\\n\\nhugo bowne-anderson: Yeah, we have an AI generated summary. We have a Youtube video. I'll put the slides in soon. Takeaways AI generated, and and so on. So in all honesty, this is the 1st time we've created something like this. So feedback, incredibly incredibly welcome. And by this I mean this type of document that links to different resources and Youtube videos and and that type of stuff. I'm really excited to have it grow with with all of you as well.\\n\\nhugo bowne-anderson:\\n\\nI\\nhugo bowne-anderson: I think that is pretty much it.\\n\\nJust before getting to\\nhugo bowne-anderson: content. Now, Williams, talk isn't like Williams.\\n\\nTalk is actually\\nhugo bowne-anderson: You remember? That was, that was a 2\\u00a0h session that turned into a 4\\u00a0h session and zoom. That also happens. By the way, and I will apologize for that. Y'all are not in like required to stick around,\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "giving a pass as they're correct but not comprehensive I think? also spelling errors but that's likely from transcript!",
        "feedback_notes": null,
        "feedback_user": "hugo",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "20e12abf-ef63-4f0a-b30c-68e827a21d2b",
        "timestamp": "2025-04-12T01:01:53.848504",
        "question": "Who are the instructors of this course, workshop, whatever it is? Is it a workshop or a course or both as well?",
        "response": "The instructors of this course/workshop are Hugo Bowne-Anderson and Stefan Krawczyk.",
        "num_chunks": 5,
        "context_tokens": 2571,
        "completion_tokens": 22,
        "embedding_tokens": 7680,
        "total_tokens": 10273,
        "latency": 0.9917094707489014,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"48be5d96-5aff-499a-8571-f1535453e9b5\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"8cddfbd6-2be7-4ea2-8588-df745ff09fa3\", \"position\": 8, \"relevance\": 1.0, \"tokens\": 497, \"timestamp\": \"00:19:54.940\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:19:54.940]\\nSo\\nhugo bowne-anderson: I hinted at this. But what this course isn't, it is not a deep dive into every Llm. Tool or trend. Of course we'll be doing. We'll be doing a bunch on agents actually, in the second half of the course, and rag and embeddings and more. But the focus is on workflows, not tools, I honestly think, and I'm happy to chat about those and message about those to be honest. But you will have enough resources on that. What we're teaching is what we'\\n\\nve really noticed is a huge gap\\nhugo bowne-anderson: in education around this stuff. This is not a plug and play AI recipe book. They don't even exist. If someone tries to tell you that or sell you that I'd love to hear it. What you'll learn is how to iterate, debug and adapt not just follow step by step. Templates. Okay, once again, this is not some, you know. Hyper, scaled, load balance, multi agent, guide. This course is about getting you moving, not solving every scaling challenge,\\n\\nbut really approaching the workflow\\nhugo bowne-anderson: of how to get things in production and then keep iterating on them.\\n\\nhugo bowne-anderson: So I'm gonna put this. This is incredibly important. This is an onboarding form that actually 25 of you have completed already. And I'm so happy with with that number so far. Usually, I try to say I try to give a form of 5 to 10\\u00a0min, but I honestly think if you all take 10 to 15\\u00a0min to complete this form. It will make this workshop and community really, really special. Okay.\\n\\nhugo bowne-anderson: so and so I just saw Jeff's note. That's in discord. That's that is brilliant.\\n\\nhugo bowne-anderson: And so I do think the the more we know about you and your interests, just because there are 5 of us now as as well. Right and geographically distributed, so the more we can we can be of help.\\n\\nhugo bowne-anderson: Jeff. Nathan has shared the course Wiki page, which we'll get to in a second,\\n\\nand part of that is\\nhugo bowne-anderson: the compute credit access form. Now I'\"}, {\"id\": \"064412f9-b21f-4eb0-998c-fa8eb190e739\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"c3cae2c7-aaf8-447c-bed5-dcb968793e1b\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}, {\"id\": \"dbd47e26-6868-4d9c-a0a1-abb0877e7bd9\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "good!",
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, as it does not specify what the question was or what the response was."
    },
    {
        "id": "8f48da26-885a-466d-a64a-737e15bc0a33",
        "timestamp": "2025-04-12T00:57:14.973643",
        "question": "Who are the instructors?",
        "response": "The instructors mentioned in the provided sections are Hugo Bowne-Anderson and Stefan Krawczyk.",
        "num_chunks": 5,
        "context_tokens": 2553,
        "completion_tokens": 22,
        "embedding_tokens": 7680,
        "total_tokens": 10255,
        "latency": 1.172684907913208,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"7a134e7d-76c7-4c11-92f6-a33a36172b17\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}, {\"id\": \"10c8dd71-67d8-4ee0-b7e8-580360567bcd\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"7e422023-ed5d-4512-8204-80f2508542a3\", \"position\": 0, \"relevance\": 1.0, \"tokens\": 487, \"timestamp\": \"00:00:14.050\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:00:14.050]\\nhugo bowne-anderson: All right. Welcome everyone. Hugo Bowen Anderson, here so excited to be kicking off workshop. One of building Llm. Powered applications for data, scientists, software engineers, and whoever else wants to get on this rocket ship together, love that. I can see a bunch of friendly faces already. We'll get to this.\\n\\nBut\\nhugo bowne-anderson: if you're able to turn your camera on, I, personally would really appreciate it, and I can tell you it makes me a better teacher as well to see a bunch of faces, and to see all the, all the engagement as well, and only if you're able to, of course, and generally microphones off when not speaking as well.\\n\\nhugo bowne-anderson: I'm I'm so excited to have you all here already, seeing what you all are up to in the discord in the forms you filled in really appreciate you filling in the onboarding form as well. We'\\n\\nve got a bunch of really serious builders who seem a lot of fun also so really excited to get to know you all\\nhugo bowne-anderson: as well. So my name is Hugo Band Anderson. I've worked in data, science and machine learning, and what now we call AI for far out 15 years now. So I feel a bit old to to be honest. I've worked in building, in education, in consulting and and devrel. Also a lot of work in devrel for open, open source stuff.\\n\\nhugo bowne-anderson: so like my, I think my, my.\\n\\nhugo bowne-anderson: my background really has been in doing scientific research using the Pi data stack that then turned into software stuff. So that's really where I come from. In the past couple of years I've been building a lot with generative AI and helping a lot of other people to build also.\\n\\nhugo bowne-anderson: But that really brings up my my background is in scientific research, in doing stuff, in notebooks, in doing my best to productionize stuff without throwing it over the wall to software engineers, which is one of the reasons I teamed up with with Stefan, who is my co-instructor and colleague and friend here, so I'll just hand it over to Stefan to say a few words.\"}, {\"id\": \"bb0bb774-79cc-4a01-8519-fa395ef455f5\", \"position\": 14, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:31:23.130\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:31:23.130]\\nbut sometimes we\\nhugo bowne-anderson: really get and get into it. But zoom cut. Cut up that video so so many times that I'm needing to stitch certain things back together. So a little bit about what I call shared commitments. I don't want to get to like consultancy or whatever, but I do. I do just want to make clear you all. Do you? Right? For sure. We we want you here to bring everything that you are. But I do want to say this course does work best when everyone's engaged and present, so, if possible.\\n\\nhugo bowne-anderson: keep your camera on. Helps us teach better when we can see who we're working with. Keep your mic off unless you're speaking.\\n\\nhugo bowne-anderson: Ask questions early and often. We love participation. On top of that.\\n\\nhugo bowne-anderson: It's very rare that questions in a course like this are uncorrelated. What I mean by that is, if you have a question almost guaranteed. Several other people have the same, if not a related question. So you're doing everyone a favor and help each other out on discord as well. You're building with awesome peers.\\n\\nI just do want to give a shout out to\\nhugo bowne-anderson: to Greg Gandenberger, did I pronounce that correctly, Greg, close enough.\\n\\ngreg: You got it? Yep.\\n\\nhugo bowne-anderson: Awesome who's already been helping out and getting people fixed up with with bugs in my end example, which are invisible bugs. In fact, among other things, Greg has already issued 2 pull requests to the repository we'll get to, and that is so cool, so please do as much as time permits, but engage with each other and and help each other out.\\n\\nSo\\nhugo bowne-anderson: really, really fantastic to have you all here.\\n\\nAnd\\nhugo bowne-anderson: wow! This slide still scares me, but it's it's real, it's it's real pain.\\n\\nAnd for some reason my\\nhugo bowne-anderson: screen isn't quite rendering everything it's slightly bigger than it it should be.\\n\\nBut what I want to say is that\\nhugo bowne-anderson: if you think about as you see here.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"8588e326-89a7-4a5c-bc51-834189dec40f\", \"position\": 8, \"relevance\": 1.0, \"tokens\": 497, \"timestamp\": \"00:19:54.940\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:19:54.940]\\nSo\\nhugo bowne-anderson: I hinted at this. But what this course isn't, it is not a deep dive into every Llm. Tool or trend. Of course we'll be doing. We'll be doing a bunch on agents actually, in the second half of the course, and rag and embeddings and more. But the focus is on workflows, not tools, I honestly think, and I'm happy to chat about those and message about those to be honest. But you will have enough resources on that. What we're teaching is what we'\\n\\nve really noticed is a huge gap\\nhugo bowne-anderson: in education around this stuff. This is not a plug and play AI recipe book. They don't even exist. If someone tries to tell you that or sell you that I'd love to hear it. What you'll learn is how to iterate, debug and adapt not just follow step by step. Templates. Okay, once again, this is not some, you know. Hyper, scaled, load balance, multi agent, guide. This course is about getting you moving, not solving every scaling challenge,\\n\\nbut really approaching the workflow\\nhugo bowne-anderson: of how to get things in production and then keep iterating on them.\\n\\nhugo bowne-anderson: So I'm gonna put this. This is incredibly important. This is an onboarding form that actually 25 of you have completed already. And I'm so happy with with that number so far. Usually, I try to say I try to give a form of 5 to 10\\u00a0min, but I honestly think if you all take 10 to 15\\u00a0min to complete this form. It will make this workshop and community really, really special. Okay.\\n\\nhugo bowne-anderson: so and so I just saw Jeff's note. That's in discord. That's that is brilliant.\\n\\nhugo bowne-anderson: And so I do think the the more we know about you and your interests, just because there are 5 of us now as as well. Right and geographically distributed, so the more we can we can be of help.\\n\\nhugo bowne-anderson: Jeff. Nathan has shared the course Wiki page, which we'll get to in a second,\\n\\nand part of that is\\nhugo bowne-anderson: the compute credit access form. Now I'\"}]",
        "success": 1,
        "feedback_rating": null,
        "feedback_reason": null,
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information relevant to the question asked, as it does not address the specific topic of the workshop."
    },
    {
        "id": "f205146c-60f1-42da-8e21-e45a6781c5d8",
        "timestamp": "2025-04-12T00:49:46.297353",
        "question": "What are the top three topics covered in this workshop rank ordered?",
        "response": "Based on the provided sections of the workshop transcript, the top three topics covered in this workshop, ranked in order, are:\n\n1. Building software powered by machine learning and Llms, including the non-deterministic nature and the need for rapid iteration and evaluation.\n2. Tools and resources used in the course, such as Zoom, a course Wiki, and compute credits.\n3. The importance of data analysis and automation in the context of machine learning, as well as the concept of fine-tuning and its limitations.",
        "num_chunks": 5,
        "context_tokens": 2481,
        "completion_tokens": 106,
        "embedding_tokens": 7680,
        "total_tokens": 10267,
        "latency": 3.2846779823303223,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"edbf6a23-6c90-4c18-9555-6a66d3c394f6\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"31c00d54-b385-445d-b36f-7b94ab2998a4\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}, {\"id\": \"ddd72ab8-d019-485a-870c-d863a3c24631\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 449, \"timestamp\": \"00:16:06.360\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:16:06.360]\\nre here for just some housekeeping and then we will jump in and\\nhugo bowne-anderson: start building some apps together immediately. Today we're actually going to get into a proof of concept purgatory together and then try to get out of it later later in the week.\\n\\nSo\\nhugo bowne-anderson: Can you see my screen, Jeff? Someone just give me a thumb up. Yep, great.\\n\\nhugo bowne-anderson: So I'\\n\\nm super excited to be talking to you and working\\nhugo bowne-anderson: how we oh, yeah, I'm sorry. Microphones off, please. The foundations of Llm software and evaluation driven development. And what's changed now from traditional software software development. And how we really need to think about building software that's powered by machine learning and Llms which share a lot of similarities, as Stefan pointed out. But instead of you know, writing some specs.\\n\\nhugo bowne-anderson: building, then deploying, and then maybe working on v. 1.2 in a month, or something like that. What we really need to do, due to the non-deterministic nature, the flip-floppy nature and the nature of Llm. Powered software that it brings in a lot of data from the real world. And we don't know how it will behave.\\n\\nhugo bowne-anderson: We need to build quickly and then deploy and then monitor and evaluate and iterate rapidly on this cycle. So that's what this course is all about, and we'll see on the building side. Prompt engineering will be important. Embeddings will be important. Fine tuning business logic. When deploying. We want to think through unit tests and versioning and continuous integration. And those things are some of the very exciting things that Stefan will be talking about in his workshop next week.\\n\\nhugo bowne-anderson: Want to think about tracing and general observability when monitoring and when evaluating. We want to think about not only monitoring how good individual Llm. Calls are, but how they relate to the business metrics that you're you're trying to meet as well.\"}, {\"id\": \"5dee389c-2b34-4eda-8f59-99433f1966a0\", \"position\": 12, \"relevance\": 1.0, \"tokens\": 493, \"timestamp\": \"00:28:30.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:28:30.270]\\nAnd a\\nhugo bowne-anderson: we use zoom for these workshops, and that's what we did in cohort one. Those were the 4 tools we used now. I didn't even quite need to put notion here to. To be honest, because you don't get to. You don't need to see the notion at all.\\n\\nhugo bowne-anderson: But what I decided to build this time was a course, Wiki, which I would very much love you all to keep private. That's really for this course, as with everything in this course I do think.\\n\\nhugo bowne-anderson: You all are paying like a handsome sum of money to to learn and get access to all of this. So please respect that everyone else in the room is is doing the same as well, and and so don't share share too much with with friends, and we'll put out a lot of free content as as well. Having said that this is the course wiki which we'll keep updated.\\n\\nSo I will actually spend a couple of minutes\\nhugo bowne-anderson: going through this. So we have. Yep stuff about us when the sessions are little welcome here. This was the setup before week one and anything you haven't done there feel free to do afterwards. There'\\n\\ns the course schedule\\nhugo bowne-anderson: and so you click on that, and it goes to another page, and you'll see. Week one workshop one. We're in that right now. Okay, and you'll see there's something called a workshop. One page coming soon. And so that's empty. But what I'm going to do is put the slides there, put the recording there. Maybe put some transcripts there or some takeaways, and I'\\n\\nd actually\\nhugo bowne-anderson: welcome all of you. If you want to do something with the Transcript in Chat Gpt, or whatever it is, please do feel free to contribute, and I'm I'm not linking to the notion page for people to contribute, just because collaborative editing on notion is not my favorite thing to do. But if you have suggestions or want to send stuff to me just just ping me and I'd love to to add things or figure it out.\\n\\nhugo bowne-anderson: We've got our compute credits.\\n\\nhugo bowne-anderson:\"}, {\"id\": \"05857f47-6321-4762-9920-f28066bf36ec\", \"position\": 25, \"relevance\": 1.0, \"tokens\": 432, \"timestamp\": \"00:54:14.400\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:54:14.400]\\nSo\\nhugo bowne-anderson: without further ado, I would love to jump into Github. I would I have spoken for a while, so I would love if there's been any, any comments in discord that could be relevant. Jeff, William, Nathan Stefan, or anything else anyone would like to add, I really I welcome it.\\n\\nStefan Krawczyk: Nothing needs to be, I guess, raised in terms of, I guess, just to reiterate what Hugo has been saying so or at least one of the themes you come to understand this course is really, you gotta look at your data right? And so and so this will be one of the key things that hopefully we'll we'll drill into you as the course goes. But.\\n\\nhugo bowne-anderson: Yeah. But Jeff.\\n\\nStefan Krawczyk: William, or Nathan, or anything.\\n\\nhugo bowne-anderson: I just did want to add, though you do want to look at your data. But something I've learned from you, Stefan, is how much once you've done that, how you can start automating pieces of that right? And so speaking to your workshop next week, but doing the scientific approach, then robustifying it, so to speak.\\n\\nhugo bowne-anderson: But yeah, Hugo.\\n\\nNathan Danielsen: So 1 1 quick question you that was raised in discord. What did you mean by fine tuning isn't really useful use these days? William gave a good initial answer. But what's your can you? And upon that, just a little bit more.\\n\\nhugo bowne-anderson: So did I say? Fine tuning isn't really useful these days, cause if I I would, that sounds like something I I would say.\\n\\nWhat I mean is that most of the time\\nhugo bowne-anderson: you need? You think you need to fine tune. You can do other things such as prompt your way out of it.\\n\\nhugo bowne-anderson: There are cases, for example.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "great lol",
        "feedback_notes": null,
        "feedback_user": "hugo",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not address the specific question asked as it does not provide any information about the workshop content or context."
    },
    {
        "id": "4e6b6050-d8b7-482c-aab8-40c3e79cc9dd",
        "timestamp": "2025-04-12T00:42:37.124275",
        "question": "Who are the guest lecturers that they speak about here?",
        "response": "The guest lecturers mentioned in the workshop transcript sections are:\n\n1. Hamil Hussein from parlance labs\n2. Eric Ma from Moderna\n3. Ravin Kumar from Google Deepmind\n4. Ines Montani from Spacey\n5. Charles Fry from Modal",
        "num_chunks": 5,
        "context_tokens": 2439,
        "completion_tokens": 57,
        "embedding_tokens": 7680,
        "total_tokens": 10176,
        "latency": 1.1878728866577148,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"e18893ca-aae1-4b78-a05c-7791e1aa7e94\", \"position\": 7, \"relevance\": 1.0, \"tokens\": 423, \"timestamp\": \"00:17:53.960\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:17:53.960]\\nhugo bowne-anderson: So what this course is. It's a practical 1st principles. Approach to building Llm. Powered apps focusing on workflows, iteration and hands-on development. Okay, it's also a space to build production grade systems that scale beyond proof of concepts and demos. It's a deep dive into the non-deterministic nature of these systems, observability, testing, and evaluation, which are the backbones of AI systems.\\n\\nThere is a world out there\\nhugo bowne-anderson: called Linkedin, among other things which wants you to believe that the backbone of robust AI systems is the latest and hottest models, multi-agentic frameworks, infinite rag systems conversations about is rag dead because of 10 trillion token, context windows.\\n\\nAnd this type of stuff\\nhugo bowne-anderson: all of that stuff aside. I mean, there are places for that. That is not what this course is about. Of course we're going to introduce you to a lot of those tools. But this is about the workflow and the non-determinism, the observability, testing and evaluation. It's also an opportunity to learn from practitioners not only the ones who are here and will be here the entire time, but we have a lot of guest guest lectures from people.\\n\\nhugo bowne-anderson: from people I admire deeply. I mean, we invited them because we think they're they're at the top top of the game. People like Hamil Hussein from parlance labs, Eric, Ma. From Moderna, Ravin Kumar from Google Deepmind, who I ravin's talk last time on because he he was on the team that built notebook. Lm. And mariner at Google and Deepmind. Just getting insight into that Ines Montani from from Spacey, who's an old friend,\\n\\nand\\nhugo bowne-anderson: her work's just just so so wonderful. And that's kind of a short list of of a lot of the wonderful guest lectures and talks that we have.\"}, {\"id\": \"10d76a77-7a21-41b3-b3c0-2a830619743b\", \"position\": 13, \"relevance\": 1.0, \"tokens\": 406, \"timestamp\": \"00:29:52.640\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:29:52.640]\\nI I wonder if I put\\nhugo bowne-anderson: yes, I did put the shared commitments there, so we'll go through that in a second, and we'll keep keep adding adding things here. And actually, one thing which I, some of you have asked about are the guest lectures from cohort one, and I've created a little guest lecture, Archive and there's there's actually one or 2 missing here, including William Horton, who gave a wonderful talk on, on thinking through when to launch,\\n\\nand how how to think about\\nhugo bowne-anderson: what metrics you want to measure before launch, and how sometimes that can be challenging, and how you really need to iterate on that. But these are all talks from the previous ones.\\n\\nAnd if you click on\\nhugo bowne-anderson: the page, let's click on Nathan's.\\n\\nhugo bowne-anderson: Yeah, we have an AI generated summary. We have a Youtube video. I'll put the slides in soon. Takeaways AI generated, and and so on. So in all honesty, this is the 1st time we've created something like this. So feedback, incredibly incredibly welcome. And by this I mean this type of document that links to different resources and Youtube videos and and that type of stuff. I'm really excited to have it grow with with all of you as well.\\n\\nhugo bowne-anderson:\\n\\nI\\nhugo bowne-anderson: I think that is pretty much it.\\n\\nJust before getting to\\nhugo bowne-anderson: content. Now, Williams, talk isn't like Williams.\\n\\nTalk is actually\\nhugo bowne-anderson: You remember? That was, that was a 2\\u00a0h session that turned into a 4\\u00a0h session and zoom. That also happens. By the way, and I will apologize for that. Y'all are not in like required to stick around,\"}, {\"id\": \"ac913c9a-bd35-441c-adaf-99720dd9b961\", \"position\": 42, \"relevance\": 1.0, \"tokens\": 459, \"timestamp\": \"01:19:59.150\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:19:59.150]\\nhugo bowne-anderson: when we're looking at our data, I don't even know what the bloody prompt is and part of my language. But in Australia. That's barely a swear word, a cuss word, by the way, but I actually don't know what the prompt is. So how do I even know how to evaluate this this system. Right?\\n\\nSo I very much encourage you all to\\nhugo bowne-anderson: rip out llama index and rebuild the app where you don't like. You don't even need a front end. Ui, it's fun to use something in gradio. But pull it out and look at your data and see what type of responses you get and and how it compares as well.\\n\\nhugo bowne-anderson:\\n\\nSo\\nhugo bowne-anderson: in the next session, just foreshadowing slightly which is Workshop 2, we'\\n\\nll be doing a lot on prompt engineering in the Llm software development lifecycle and thinking through how we\\nhugo bowne-anderson: essentially how we start to think about evaluation when changing prompts and versioning. And and these types of things. We have a wonderful guest, speaker, Charles Fry, from from Modal about building AI powered apps on on modal. I actually also encourage you all very much to his guest. Talk last time really blew me away. So much. So I mean, I had him on a podcast to chat about it as well. This is the one page where the embed just didn't work,\\n\\nfor\\nhugo bowne-anderson: whatever reason.\\n\\nhugo bowne-anderson: And also, by the way, oh, yeah, I used sorry I used the new Gpt to create funny covers for everyone. So this is unlisted. So I would appreciate it. If you don't share these videos. These are really, for course, attendees also.\\n\\nhugo bowne-anderson: and as part of the value. But he gave a wonderful talk about what we all, as Llm. Developers need to know about gpus and hardware, so I do encourage you all time permitting to check that out, so he'll be giving a guest talk,\"}, {\"id\": \"d32d676a-eaa8-409c-a2c4-227ef5cbe218\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"a1ed891a-2ae2-4db9-bbb9-90118be47358\", \"position\": 9, \"relevance\": 1.0, \"tokens\": 498, \"timestamp\": \"00:22:16.270\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:22:16.270]\\nm\\nhugo bowne-anderson: I'\\n\\nm incredibly humbled to have had such wonderful sponsors and partners\\nhugo bowne-anderson: for this and I approach people whose so, just to be clear, none of these places have ever paid me or anyone working on this course. As far as as far as I know. The only way they've I suppose they've paid me is by sponsoring like giving credits to students in workshops and courses I've taught. And there's a reason I've chosen all of these, and you'll see why, throughout the the course, I don't think.\\n\\nhugo bowne-anderson: Okay. Modal. For, for example,\\n\\njust the ability to let me just show you and Charles fry devrel at Modal\\nhugo bowne-anderson:\\n\\nis coming to give a talk about how to leverage it the best\\nhugo bowne-anderson: on in in our second workshop this week. But just look at the type of things you can do pretty much out of the box,\\n\\nwith with modals from voice chat with\\nhugo bowne-anderson: Llms to protein folding to deploy an Oai compatible Llm. Server, serve diffusion models. All of this type of stuff. So that's 1. And it's and it's relatively straight, straightforward. And they're a wonderful community. Base 10 who's giving a talk later that all the stuff they provide for inference is absolutely incredible. You may have seen all the stuff they're doing with Llama 4 since Saturday.\\n\\nThey hustle hard to get all of all of that stuff working\\nhugo bowne-anderson: Gemini, we'll get to this.\\n\\nBut I I honestly think\\nhugo bowne-anderson: I think Gemini and Google's models out of the box are my favorite once again. I've never taken any money from Google.\\n\\nI happily would\\nhugo bowne-anderson: take a lot of money from Google, but I wouldn't do it to work for them. But they've got wonderful products. They've got a wonderful open source ecosystem, and they have some of the best people working on it as well, Mistral Super. Cool stuff. They're smaller. Models are incredibly performant. Mistral Ocr is really exciting, and they've been great to sponsor replicate. I don't know if you all know.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "nice",
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, as it does not specify what the question was or what the response addressed."
    },
    {
        "id": "da75741d-e767-4bd2-9de3-8c03b1c3cb67",
        "timestamp": "2025-04-12T00:42:14.443917",
        "question": "What month is this workshop occurring in?",
        "response": "The workshop is occurring in an unspecified month.",
        "num_chunks": 5,
        "context_tokens": 2372,
        "completion_tokens": 10,
        "embedding_tokens": 7680,
        "total_tokens": 10062,
        "latency": 1.6693060398101809,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"3f63d89f-ea70-4e37-bb7c-ebe944991565\", \"position\": 62, \"relevance\": 1.0, \"tokens\": 302, \"timestamp\": \"01:59:06.670\", \"speaker\": \"Philip Kiely\", \"text\": \"[TIMESTAMP: 01:59:06.670]\\nPhilip Kiely: Thank you so much for having me. Thanks everyone for your time today.\\n\\nhugo bowne-anderson: Such a pleasure. Thanks, Philip.\\n\\nhugo bowne-anderson: and everyone else. It's it's time to time to wrap up. I just want to give Philip one more round of applause.\\n\\nGreat\\nhugo bowne-anderson: It is time to wrap up. We do have 2. As as I mentioned before, we have an just an onboarding form. A lot of you have completed it, but if you're if you haven't, and able to, this will allow us, it'll let us know where you are. What you're interested in, and it will allow us to set up the office hours that that we're going to with our wonderful builders in residence as well.\\n\\nOnce again I will share with you\\nhugo bowne-anderson: the feedback form. A bunch of you have already provided a lot of valuable feedback in there, which we'll use to iterate quickly on how we, how we teach and how we approach this course. I'm going to share that in the discord chat also.\\n\\nhugo bowne-anderson: So it's there. But that's it for today, and we'll see you on discord, and we'll see you in 46\\u00a0h for the next workshop as well. So thanks everyone, and thanks for a great 1st session.\"}, {\"id\": \"48e469f8-33cc-40ac-8f1a-f287c6c992da\", \"position\": 43, \"relevance\": 1.0, \"tokens\": 491, \"timestamp\": \"01:22:16.770\", \"speaker\": \"Stefan Krawczyk\", \"text\": \"[TIMESTAMP: 01:22:16.770]\\nand then\\nhugo bowne-anderson: in next week it'll all be about iteration, evaluation, and observability. So we'll be jumping right into systematic evaluation of Llm outputs qualitative and quantitative outputs how to define metrics for success such as relevance, coherence, user satisfaction setting up feedback loops, observability basics, debugging common Llm issues and then scaling observability and tools for production.\\n\\nMonitoring\\nhugo bowne-anderson: Stefan. I don't know if you want to add any flavor with respect to what you will talk about next week. Something I really did appreciate, do appreciate about your work is really thinking about the testing loops in Devon prod. So maybe you want to say a word about that.\\n\\nStefan Krawczyk: I mean, yeah, I mean the so testing and evaluation. So one of the things I guess we'll dig into over the I guess the the coming workshop is to you know what's the difference?\\n\\nStefan Krawczyk: in terms of mechanics. There really isn't any just kind of what what you do and what you want to do with it.\\n\\nAnd so\\nStefan Krawczyk: in terms of the 1st principles, right? We're really trying to gonna be teaching you, you know, not trying to teach you a particular tool so, and how to do it with that tool, but really the principle behind it.\\n\\nSo you can kind of\\nStefan Krawczyk: take it, and project it to where, however, your place of work kind of does things right? So so that's probably I want to say at a high level, the things to kind of think about is that, yeah, we we're not necessarily going to be very tool specific. We're going to be 1st principle based. And that way it should hopefully be easier for you to then project and like, bring in to wherever you're working, since everybody does software development, something differently. And so which case the emphasis, I think on 1st principles also. Helps here.\\n\\nBut\\nStefan Krawczyk: yeah, any any more. There was that.\\n\\nStefan Krawczyk: That's I mean, Hugo, cool.\\n\\nhugo bowne-anderson: I love that workshop last time so much. I'm just excited excited for it.\"}, {\"id\": \"02a14c80-037b-488f-ae78-495f484ef936\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 468, \"timestamp\": \"00:12:49.260\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:12:49.260]\\nll figure that out\\nhugo bowne-anderson: as we as we move along. Now, one bit of housekeeping, as I said, cameras on. Great to see you all got 40 people in in the room, which is, which is really incredible. All of these are recorded, and we'll share them as soon as they're available from Zoom afterwards. But something we're trying this time.\\n\\nLast time in the course\\nhugo bowne-anderson: there was lots of exciting conversations during the workshops, and that all happened on zoom, and it wasn't very clear how to port them over to discord and have have them accessible after the fact. So what we've done is we've turned off the chat. Here. You can. DM me. Please don't do that right now, because I can't reply to Dms while I'm talking, but you can. DM. Stefan, you can. DM. Jeff, Nathan, and William. In order to get into discord. They'\\n\\nll share the link and then add you to the\\nhugo bowne-anderson: channels for this cohort, and there's a channel called Workshop one where I've just dropped the slides that we're about to jump in and get started with. Now, the way we're using discord is a bit of an experiment. We did it all in cohort one. But now what we're doing is we'\\n\\nre locking off\\nhugo bowne-anderson: a series of channels solely for this cohort, but giving you access to everything else in in the discord so feel free to explore. If you have any ideas for how we can leverage discord better as a growing community. Please do let us let us know this isn'\\n\\nt\\nhugo bowne-anderson: this isn't static, as we know, software is nowhere near static anymore. And we want this to be a very dynamic place that you bring all of what you are to as well. So we'd love that.\\n\\nhugo bowne-anderson: I think now, without further ado, I'm gonna jump. I'\\n\\nm gonna share some slides and\\nhugo bowne-anderson: talk through 1st what we're up to at at the moment. What we'\"}, {\"id\": \"d32d676a-eaa8-409c-a2c4-227ef5cbe218\", \"position\": 2, \"relevance\": 1.0, \"tokens\": 500, \"timestamp\": \"00:04:57.490\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:04:57.490]\\nI will add that\\nhugo bowne-anderson: Stephan will be. He'll be giving a full workshop next week, and it's 1 of my favorite workshops in in this course, actually,\\n\\nbecause I get to learn so much from it about\\nhugo bowne-anderson: testing and running tests, both in Dev and and production for Llm. Powered apps and all the things he's just mentioned, but plus plus essentially.\\n\\nStefan Krawczyk: Cool.\\n\\nStefan Krawczyk: Yeah, so hopefully, I'll be able to reveal more in the course. But I have a few things with kind of, you know, legal, social and a few other things that need to clear before I officially change my Linkedin status. So I appreciate you guys keeping that under apps until I can do that myself. Thanks.\\n\\nhugo bowne-anderson: And, as we all know, Linkedin is the only reality. So we'll wait for that to happen. Thanks so much, Stefan. I also am super excited to introduce you to Jeff Pidcock, Nathan Danielson, and William Horton,\\n\\nwho\\nhugo bowne-anderson: joined for cohort, one as participants students in the course, and they're very serious builders in industry, and I was so blown away I was blown away by the caliber of participants generally, but we invited them back to to kick off our builders in residence program one of the requests from people in cohort. One was just more time building more office hours more,\\n\\nbeing able to\\nhugo bowne-anderson: answer questions and help people build. So I chatted with Jeff, William and and Nathan about this, and they were so excited to to come back and work with you all on everything you're you're trying to build. So I'd love for them each to say a thing or 2, and we've got them geographically distributed. So for context, this course is really timed for the Us. And Apac. Selfishly, because I'm in Sydney.\\n\\nhugo bowne-anderson: and so Jeff is in Sydney, or just south of Sydney, plus Williams on the East coast in DC. And and Nathan's in Los Angeles. So we've got them geographically distributed so they can organize pods to to work with you all on on things. So, Jeff, maybe you could say a few words about yourself.\"}, {\"id\": \"e7939e01-d7d3-4463-ac9e-8b327c042835\", \"position\": 29, \"relevance\": 1.0, \"tokens\": 462, \"timestamp\": \"01:00:50.310\", \"speaker\": \"greg\", \"text\": \"[TIMESTAMP: 01:00:50.310]\\nhugo bowne-anderson: another way to view it is. It's Vs code. But in your browser, with everything provided, and I find it fantastic, because what it allows me to do is it abstracts over all the environment issues? Well, most of the environment issues. We have, of course not, you know invisible carriage returns, and that type of stuff, but it allows me to set things up so you can run them as easily as possible. Now, before. Whoa! I didn't even how did I get a co-pilot in there?\\n\\nhugo bowne-anderson: What I am gonna say is due to the nature of these workshops. We're not gonna use workshop time to debug all of you. Like getting environment set up. And that type of stuff I put a video out beforehand, which I encourage you to to watch. And I'll put one out again before Thursdays, because that's the 1st time we'll be using notebooks.\\n\\nhugo bowne-anderson: but I think getting the code space set up. If you're able to do it before the workshop. That's great, if not feel free to, after just in terms of time management. It's especially because most of the issues have to do with environment variables and stuff like that. It just doesn't make sense for us to spend half an hour to 45\\u00a0min of a 2\\u00a0h session doing that here. Okay, so all that having been said,\\n\\nI want to just check\\nhugo bowne-anderson: what I have in my environment here.\\n\\nhugo bowne-anderson: Okay, so I wanna so I don't have all the cool packages I want.\\n\\nSo I want to activate\\nhugo bowne-anderson: and let me make this a bit bigger, super cool. And then, okay, that's great.\\n\\nhugo bowne-anderson: Got all the things I want.\\n\\nhugo bowne-anderson: Okay.\\n\\nhugo bowne-anderson: So now, what I'm going to do is go into, actually, where am I?\\n\\nhugo bowne-anderson: Yep, going to workshop one and the apps directory?\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "ok",
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response accurately and directly addresses the user's question by providing a clear and relevant summary of the key differences as mentioned in the workshop transcript."
    },
    {
        "id": "5ad50723-e20b-4643-bf6a-d0b707eaef8d",
        "timestamp": "2025-04-12T00:21:29.926672",
        "question": "Who are the instructors in this workshop?",
        "response": "The instructors in this workshop are Hugo Bowne-Anderson and Stefan Krawczyk.",
        "num_chunks": 5,
        "context_tokens": 2499,
        "completion_tokens": 20,
        "embedding_tokens": 7680,
        "total_tokens": 10199,
        "latency": 2.1896963119506836,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"c7c0ee99-a3b4-46fe-82cf-a6fc996c4a0e\", \"position\": 1, \"relevance\": 1.0, \"tokens\": 454, \"timestamp\": \"00:02:17.182\", \"speaker\": \"Unknown\", \"text\": \"[TIMESTAMP: 00:02:17.182]\\nhugo bowne-anderson: Looking at data and figuring out how you evaluate your systems. Incredibly important. So that's a brief introduction to me touching on what's in in the course as well, Stefan, maybe you can introduce yourself also.\\nStefan Krawczyk CEO DAGWorks Inc.: Yeah. Hi, Stefan Kafchuk.\\nStefan Krawczyk CEO DAGWorks Inc.: so super excited to to be here in terms of my background. I grew up in New Zealand, being out here in the bay since 2,007. So I live in San Francisco\\nStefan Krawczyk CEO DAGWorks Inc.: throughout my career. The only thing I haven't done is mobile development front end stuff, but effectively in the last kind of 10 years has been building on the data platform mlop side of things. And most recently, Gen. AI on the Lmops side of things.\\nStefan Krawczyk CEO DAGWorks Inc.: Specifically, I have been driving 2 open source projects, Hamilton and Burr. I'll put links in the chat if you're curious, but effectively have been trying to think about, how do you enable software engineers and have them transition to AI engineers? And then, conversely, how do you help\\nStefan Krawczyk CEO DAGWorks Inc.: the people on the data. Ml, side, take their skills and then apply them, build more software and product. Right? So very much interested in what is the new software development lifecycle shaping up to be since the agile sprint model doesn't really work when you're building something with Gen. AI as as it would as it did with traditional software, but otherwise, yeah, super excited for the amount of experience that's on here. I'm hopeful I can learn stuff from you guys as well\\nStefan Krawczyk CEO DAGWorks Inc.: but otherwise yeah, I will be, you know. Q will be driving most of this this course. I'll be kind of helping where I can with things, but otherwise\\nStefan Krawczyk CEO DAGWorks Inc.: Do you guys anything else to transition to? Otherwise?\"}, {\"id\": \"18cafb50-748a-4f88-bf52-d2a5e6fb8629\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:13:17.160\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:13:17.160]\\nand when we go through the syllabus\\nhugo bowne-anderson: we'll see this play out. But we're going to have guest lectures from people really on the cutting edge. So I suppose I talked about the cutting edge of tech companies. There are also a handful of people I know who are on the cutting edge,\\n\\nand\\nhugo bowne-anderson: in some ways further ahead the curve of adoption and technology than myself and Stefan not necessarily settled technology. So this isn't stuff I'd take out and tell everyone to adopt immediately. But people such as Sean Swicks working with agents. Hamel Hussein's work on Llms in production is exceptional.\\n\\nI think him and Philip\\nhugo bowne-anderson: at Honeycomb they actually outside the vendor Apis. They were the 1st to put an Llm. In production. Essentially, it was text to, not SQL. But text to honeycomb query, language. Sander Schulhoff, who published,\\n\\nwhich is now like\\nhugo bowne-anderson: it's called the prompt report. But essentially it's a report written by 40 people about prompt engineering people from Openai Sand, a bunch of others coming and talking about prompt engineering Charles from Modal, where we've got a thousand dollars of credits for each of you to talk about hardware and Ravan, Kumar, Ravin,\\n\\nKumar from\\nhugo bowne-anderson: the AI labs at Google, where he worked on notebook. Lm, and now, mariner, and he's going to come and give a talk which I'm working on with him currently about end-to-end products. So how to design user experiences from machine learning models. And his work at AI labs.\\n\\nhugo bowne-anderson: Google, AI is going to inform a lot of lot of that. So I just want to make sure that you don't only get kind of the base foundational stuff. But you see what people are doing on the cutting edge as well.\\n\\nThe other thing is\\nhugo bowne-anderson: these types of courses. Of course Stefan and I are here to teach and offer as much value as as we can and and beyond. But sometimes these courses have a magic of their own,\"}, {\"id\": \"52ed0af7-3832-45fd-a742-a2ae8e99f47d\", \"position\": 60, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"01:50:39.550\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:50:39.550]\\nh\\nhugo bowne-anderson: a work outside a week, you'll get significantly more. If you do. 4\\u00a0h outside per week you'll probably get like way way more. So of course it's January. We've all got a bunch of stuff on, but definitely leverage myself, Stefan, and the community we're building as well.\\n\\nWhat I\\nhugo bowne-anderson: also want to say we didn't get round to this, and we'll do it next time you can deploy this app on Gradio. And I've actually got a video here of me doing.\\nStefan Krawczyk CEO DAGWorks Inc.: Tomorrow.\\n\\nhugo bowne-anderson: Yes, sorry on Modal. Exactly. And you need to have we need to have given you credentials, and so we'll get those, and so we'll get that sorted.\\n\\nhugo bowne-anderson: Everything we need in the modal form.\\n\\nhugo bowne-anderson: And I'll do that next time.\\n\\nAnd then\\nhugo bowne-anderson: the final thing I would very much appreciate. If you all took 3\\u00a0min now, I don't know why it has this big gap here. We'd love feedback on this session, so I'd like to know? How do you rate the pace? What did you like most? What could we improve anything unclear or confusing? If so, what this will help us create the best course going forward for all of you, and and both of us as well. To be honest. The other thing I'm not sure I mentioned. But this is the 1\\n\\nst time\\nhugo bowne-anderson:\\n\\nStefan and I are teaching this long version of\\nhugo bowne-anderson: of this material. We actually taught a 3\\u00a0h version of it recently in Austin, at the generative AI summit to 100 people, which was just so wonderful to do that in person, and Stefan and I have been teaching and working on these things for a long time, but this course, as it exists, it is the 1st cohort of it, so there may be rough edges. I'd be very surprised I'd be concerned if there weren'\"}, {\"id\": \"137d5f41-6697-43f3-a6f8-943f4c30052e\", \"position\": 18, \"relevance\": 1.0, \"tokens\": 488, \"timestamp\": \"00:43:32.890\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:43:32.890]\\nhugo bowne-anderson: Also. Additionally, this kind of mirrors, real world development environments where teams work across multiple platforms. And I'm sure we've all been. I don't know how many of you have like worked in. I've worked in several startups that go like from 4 people to 150, and seeing the amount of tools introduced in that type of growth is mind boggling. I actually think that may be why startups fail because they don't adopt tools mindfully, but that's for another day.\\n\\nhugo bowne-anderson: I'll say a bit about the high level structure, and then I'll get you to complete a survey, and then we'll jump into executing some code together. So this is week one. Clearly, it's foundations of Llm software development. So we'\\n\\nre going to introduce you to Genai and Llm development\\nhugo bowne-anderson: give an overview of the software development lifecycle. Use some key tools and frameworks for Llm.\\n\\nBased applications and set up the foundational app which is querying Pdfs and generating responses\\nhugo bowne-anderson: today will be introductory and building this app. Then, on Wednesday or Thursday, depending what time zone you're in, I'm in Australia. So it's actually Tuesday morning here, soon to be Tuesday afternoon. But I was in America recently, which is why I'm saying Tuesday and not Tuesday.\\n\\nhugo bowne-anderson: We have several guest lectures, as you're aware.\\n\\nhugo bowne-anderson: the final part of our second session this week will be Charles Fry, from modal talking about hardware for Llm. Developers. And I recently did a podcast with him. And he's he'\\n\\ns just\\nhugo bowne-anderson: super wonderful and bright on this. Next week we'll be doing iteration, evaluation and observability. And the 1st lesson will be evaluation and feedback loops the second one on observability and debugging next week next. So we'll be doing a lot of prompt engineering in the second session this week in the 1st session next week, Sander Schulhoff, from learnprompting.org,\\n\\nand the prompt report will give a guest lecture on prompt engineering in the Llm software development lifecycle\\nhugo bowne-anderson: Week 3, we'\"}, {\"id\": \"5194a354-11fd-4118-a650-193dfee1f2d0\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:15:16.300\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:15:16.300]\\nand people\\nhugo bowne-anderson: communicate and learn from each other, and I've already seen hints of this on discord before our 1st session. I've seen people chatting who are both in DC. And may meet up. I've corresponded with a couple of people in Sydney about meeting up. I've been seeing people ask each other about each other's work. Just go to the introductions Channel. If you haven't, and see what everyone's working on, and the variance of what everyone's working on. And it's incredibly exciting to me.\\n\\nhugo bowne-anderson: So I think that's something we can get out of this course as well.\\n\\nSo\\nhugo bowne-anderson: what this course isn't. It is not a deep dive into every Llm. Tool or trend. Of course we'll be talking about rag and agents and embeddings. But the focus is on workflows, not an exhaustive tool coverage. And actually, on top of that, in today's session, we use Lama Index gradio sqlite, a tool by Salem and Willison, called dataset. We may even get to modal for deployment. We'll use one or 2 vendor Apis. So this isn't to say we won't be using tools all the time.\\n\\nBut the focus will not\\nhugo bowne-anderson: not be on tool thinking. And I actually, this is maybe a provocation, and I'\\n\\nd be happy to discuss this\\nhugo bowne-anderson: with all of you. But almost an assumption we're going in with is that tools should not be the focus and tools themselves will come and go. Ways of working with tools will come and go. We're in the early days. This is the infancy of the Llm. Powered app space right?\\n\\nSo\\nhugo bowne-anderson: even processes. Well, no, I'm certain some big processes will change right. But what our bet is, what won't change is a bunch of 1st principles and 1st principle, thinking for how to build software with generative AI Apps and Llms. So we'll go through those 1st principles. But that really is what this, what this course is about.\"}]",
        "success": 1,
        "feedback_rating": "FAIL",
        "feedback_reason": "correct ",
        "feedback_notes": "fast enough for now",
        "feedback_user": "hugo",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, as it does not specify what the question was or what the response was."
    },
    {
        "id": "68658f1a-8223-4016-b36f-35956a551233",
        "timestamp": "2025-04-11T23:03:25.296977",
        "question": "Are there any guest lectures?",
        "response": "Yes, there are guest lectures mentioned in the workshop transcript sections. Some of the guest lecturers mentioned include Sean Swicks, Hamel Hussein, Sander Schulhoff, Charles Fry, and Ravin Kumar.",
        "num_chunks": 5,
        "context_tokens": 2463,
        "completion_tokens": 43,
        "embedding_tokens": 7680,
        "total_tokens": 10186,
        "latency": 1.6975727081298828,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"60dc82bb-b13f-4a2d-ab73-76f9311661a7\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:13:17.160\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:13:17.160]\\nand when we go through the syllabus\\nhugo bowne-anderson: we'll see this play out. But we're going to have guest lectures from people really on the cutting edge. So I suppose I talked about the cutting edge of tech companies. There are also a handful of people I know who are on the cutting edge,\\n\\nand\\nhugo bowne-anderson: in some ways further ahead the curve of adoption and technology than myself and Stefan not necessarily settled technology. So this isn't stuff I'd take out and tell everyone to adopt immediately. But people such as Sean Swicks working with agents. Hamel Hussein's work on Llms in production is exceptional.\\n\\nI think him and Philip\\nhugo bowne-anderson: at Honeycomb they actually outside the vendor Apis. They were the 1st to put an Llm. In production. Essentially, it was text to, not SQL. But text to honeycomb query, language. Sander Schulhoff, who published,\\n\\nwhich is now like\\nhugo bowne-anderson: it's called the prompt report. But essentially it's a report written by 40 people about prompt engineering people from Openai Sand, a bunch of others coming and talking about prompt engineering Charles from Modal, where we've got a thousand dollars of credits for each of you to talk about hardware and Ravan, Kumar, Ravin,\\n\\nKumar from\\nhugo bowne-anderson: the AI labs at Google, where he worked on notebook. Lm, and now, mariner, and he's going to come and give a talk which I'm working on with him currently about end-to-end products. So how to design user experiences from machine learning models. And his work at AI labs.\\n\\nhugo bowne-anderson: Google, AI is going to inform a lot of lot of that. So I just want to make sure that you don't only get kind of the base foundational stuff. But you see what people are doing on the cutting edge as well.\\n\\nThe other thing is\\nhugo bowne-anderson: these types of courses. Of course Stefan and I are here to teach and offer as much value as as we can and and beyond. But sometimes these courses have a magic of their own,\"}, {\"id\": \"fc9c54e0-36e5-4634-b27a-f1d1357664ce\", \"position\": 20, \"relevance\": 1.0, \"tokens\": 480, \"timestamp\": \"00:47:10.640\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:47:10.640]\\nhugo bowne-anderson: then in week 4, we're gonna jump into from customization to deployment. So there are a lot of different paths. We can go down. And this is what we'll figure out with you what you want to learn the most from advanced prompt optimization to fine tuning, to preparing data sets synthetically generating data, sets multi agent workflows talking through future trends. So over the next couple of weeks we'll get a sense of what you what would help you the most to learn out of these things.\\n\\nhugo bowne-anderson: and we'll be building more and more guest lectures that week will be Hamel Hussein, who's a good friend of ours, and he's going to give a talk on basic data literacy for debugging and evaluating Llms. He's been running office hours for the past year where people come with Llm. Application problems. And they'll say I've got these like multi agent multi-turn conversations and these complex rag pipelines.\\n\\nAnd\\nhugo bowne-anderson: I need to evaluate them. And he'll say, just look at your data. And he actually says people still don't understand what he means by that.\\n\\nhugo bowne-anderson: And people may not have the data literacy skills to. As I was saying before, jump into, look at the traces internally within an agentic pipeline, and you'll see the failure modes emerge. And we'll see examples of this today. And actually, so I'm really excited for this session. It will be outside class time. It'll be on. Oh, this is hilarious. It'\\n\\ns actually going to be on\\nhugo bowne-anderson: Tuesday, Tuesday. At this time I wrote Wednesday because it is Wednesday for me again.\\n\\nBut a recording will be\\nhugo bowne-anderson: available, and we may even release it as a podcast so you'll have access to that session whether you can make it or not. And Sean swicks from the latent space podcast and small AI, AI engineer will be talking about engineering, AI agents in 2025.\\n\\nhugo bowne-anderson: Eric has a great question. I heard that AI. Agents is the future. Is this a reasonable statement? I will answer that. And this is something we'll go through.\"}, {\"id\": \"fefab037-b794-4e42-b7fd-7a99945057c2\", \"position\": 18, \"relevance\": 1.0, \"tokens\": 488, \"timestamp\": \"00:43:32.890\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:43:32.890]\\nhugo bowne-anderson: Also. Additionally, this kind of mirrors, real world development environments where teams work across multiple platforms. And I'm sure we've all been. I don't know how many of you have like worked in. I've worked in several startups that go like from 4 people to 150, and seeing the amount of tools introduced in that type of growth is mind boggling. I actually think that may be why startups fail because they don't adopt tools mindfully, but that's for another day.\\n\\nhugo bowne-anderson: I'll say a bit about the high level structure, and then I'll get you to complete a survey, and then we'll jump into executing some code together. So this is week one. Clearly, it's foundations of Llm software development. So we'\\n\\nre going to introduce you to Genai and Llm development\\nhugo bowne-anderson: give an overview of the software development lifecycle. Use some key tools and frameworks for Llm.\\n\\nBased applications and set up the foundational app which is querying Pdfs and generating responses\\nhugo bowne-anderson: today will be introductory and building this app. Then, on Wednesday or Thursday, depending what time zone you're in, I'm in Australia. So it's actually Tuesday morning here, soon to be Tuesday afternoon. But I was in America recently, which is why I'm saying Tuesday and not Tuesday.\\n\\nhugo bowne-anderson: We have several guest lectures, as you're aware.\\n\\nhugo bowne-anderson: the final part of our second session this week will be Charles Fry, from modal talking about hardware for Llm. Developers. And I recently did a podcast with him. And he's he'\\n\\ns just\\nhugo bowne-anderson: super wonderful and bright on this. Next week we'll be doing iteration, evaluation and observability. And the 1st lesson will be evaluation and feedback loops the second one on observability and debugging next week next. So we'll be doing a lot of prompt engineering in the second session this week in the 1st session next week, Sander Schulhoff, from learnprompting.org,\\n\\nand the prompt report will give a guest lecture on prompt engineering in the Llm software development lifecycle\\nhugo bowne-anderson: Week 3, we'\"}, {\"id\": \"069f9263-ef08-4687-bc04-5caaab923c38\", \"position\": 1, \"relevance\": 1.0, \"tokens\": 454, \"timestamp\": \"00:02:17.182\", \"speaker\": \"Unknown\", \"text\": \"[TIMESTAMP: 00:02:17.182]\\nhugo bowne-anderson: Looking at data and figuring out how you evaluate your systems. Incredibly important. So that's a brief introduction to me touching on what's in in the course as well, Stefan, maybe you can introduce yourself also.\\nStefan Krawczyk CEO DAGWorks Inc.: Yeah. Hi, Stefan Kafchuk.\\nStefan Krawczyk CEO DAGWorks Inc.: so super excited to to be here in terms of my background. I grew up in New Zealand, being out here in the bay since 2,007. So I live in San Francisco\\nStefan Krawczyk CEO DAGWorks Inc.: throughout my career. The only thing I haven't done is mobile development front end stuff, but effectively in the last kind of 10 years has been building on the data platform mlop side of things. And most recently, Gen. AI on the Lmops side of things.\\nStefan Krawczyk CEO DAGWorks Inc.: Specifically, I have been driving 2 open source projects, Hamilton and Burr. I'll put links in the chat if you're curious, but effectively have been trying to think about, how do you enable software engineers and have them transition to AI engineers? And then, conversely, how do you help\\nStefan Krawczyk CEO DAGWorks Inc.: the people on the data. Ml, side, take their skills and then apply them, build more software and product. Right? So very much interested in what is the new software development lifecycle shaping up to be since the agile sprint model doesn't really work when you're building something with Gen. AI as as it would as it did with traditional software, but otherwise, yeah, super excited for the amount of experience that's on here. I'm hopeful I can learn stuff from you guys as well\\nStefan Krawczyk CEO DAGWorks Inc.: but otherwise yeah, I will be, you know. Q will be driving most of this this course. I'll be kind of helping where I can with things, but otherwise\\nStefan Krawczyk CEO DAGWorks Inc.: Do you guys anything else to transition to? Otherwise?\"}, {\"id\": \"1b60c477-c2e2-4fd3-8fa2-2ba75f9c7e53\", \"position\": 52, \"relevance\": 1.0, \"tokens\": 425, \"timestamp\": \"01:37:19.430\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:37:19.430]\\nhugo bowne-anderson: Great! So we'll let you all take a few more minutes to query. Anyone's linkedin profile as a Pdf.\\n\\nhugo bowne-anderson:\\n\\nand\\nhugo bowne-anderson: in next class we'll actually have a whole bunch that we we can give them some Pdfs as well. Right, Stefan.\\nStefan Krawczyk CEO DAGWorks Inc.: Yep.\\n\\nhugo bowne-anderson: Yeah, that's so interesting that Ios needed to get pulled.\\nStefan Krawczyk CEO DAGWorks Inc.: There you go, Wendy, so let's do it, man.\\n\\nhugo bowne-anderson: Come to the camera.\\nStefan Krawczyk CEO DAGWorks Inc.: Rooms.\\n\\nhugo bowne-anderson: Breakout, so we'll break out for 10\\u00a0min, and then we'll come back and add some logging observability,\\n\\nand\\nhugo bowne-anderson: then rock and roll.\\nStefan Krawczyk CEO DAGWorks Inc.: All right, I'm gonna automatically assign everyone. So I guess there's.\\n\\nhugo bowne-anderson: And how many rooms are you gonna create.\\nStefan Krawczyk CEO DAGWorks Inc.: I guess almost 40 of us. I was thinking.\\n\\nhugo bowne-anderson: 10 rooms.\\nStefan Krawczyk CEO DAGWorks Inc.: Yeah, 9 or so.\\n\\nhugo bowne-anderson: Right.\\nStefan Krawczyk CEO DAGWorks Inc.: Customer.\\n\\nhugo bowne-anderson: And are you and I able to jump around rooms or you are? Cause I'm gonna I'm not.\\nStefan Krawczyk CEO DAGWorks Inc.: I believe you should be able to, but.\\n\\nhugo bowne-anderson: Let's do.\\nStefan Krawczyk CEO DAGWorks Inc.: Alright!\\n\\nPratiksha: Okay.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "cool!",
        "feedback_notes": "ok",
        "feedback_user": "hiugo",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "28ffa314-ac8f-44c5-be6c-6c6a0a6e468d",
        "timestamp": "2025-04-11T23:03:03.362530",
        "question": "Who are the instructors here?",
        "response": "The instructors in this workshop are Hugo Bowne-Anderson and Stefan Krawczyk.",
        "num_chunks": 5,
        "context_tokens": 2220,
        "completion_tokens": 20,
        "embedding_tokens": 7680,
        "total_tokens": 9920,
        "latency": 1.3658859729766846,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"069f9263-ef08-4687-bc04-5caaab923c38\", \"position\": 1, \"relevance\": 1.0, \"tokens\": 454, \"timestamp\": \"00:02:17.182\", \"speaker\": \"Unknown\", \"text\": \"[TIMESTAMP: 00:02:17.182]\\nhugo bowne-anderson: Looking at data and figuring out how you evaluate your systems. Incredibly important. So that's a brief introduction to me touching on what's in in the course as well, Stefan, maybe you can introduce yourself also.\\nStefan Krawczyk CEO DAGWorks Inc.: Yeah. Hi, Stefan Kafchuk.\\nStefan Krawczyk CEO DAGWorks Inc.: so super excited to to be here in terms of my background. I grew up in New Zealand, being out here in the bay since 2,007. So I live in San Francisco\\nStefan Krawczyk CEO DAGWorks Inc.: throughout my career. The only thing I haven't done is mobile development front end stuff, but effectively in the last kind of 10 years has been building on the data platform mlop side of things. And most recently, Gen. AI on the Lmops side of things.\\nStefan Krawczyk CEO DAGWorks Inc.: Specifically, I have been driving 2 open source projects, Hamilton and Burr. I'll put links in the chat if you're curious, but effectively have been trying to think about, how do you enable software engineers and have them transition to AI engineers? And then, conversely, how do you help\\nStefan Krawczyk CEO DAGWorks Inc.: the people on the data. Ml, side, take their skills and then apply them, build more software and product. Right? So very much interested in what is the new software development lifecycle shaping up to be since the agile sprint model doesn't really work when you're building something with Gen. AI as as it would as it did with traditional software, but otherwise, yeah, super excited for the amount of experience that's on here. I'm hopeful I can learn stuff from you guys as well\\nStefan Krawczyk CEO DAGWorks Inc.: but otherwise yeah, I will be, you know. Q will be driving most of this this course. I'll be kind of helping where I can with things, but otherwise\\nStefan Krawczyk CEO DAGWorks Inc.: Do you guys anything else to transition to? Otherwise?\"}, {\"id\": \"60dc82bb-b13f-4a2d-ab73-76f9311661a7\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:13:17.160\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:13:17.160]\\nand when we go through the syllabus\\nhugo bowne-anderson: we'll see this play out. But we're going to have guest lectures from people really on the cutting edge. So I suppose I talked about the cutting edge of tech companies. There are also a handful of people I know who are on the cutting edge,\\n\\nand\\nhugo bowne-anderson: in some ways further ahead the curve of adoption and technology than myself and Stefan not necessarily settled technology. So this isn't stuff I'd take out and tell everyone to adopt immediately. But people such as Sean Swicks working with agents. Hamel Hussein's work on Llms in production is exceptional.\\n\\nI think him and Philip\\nhugo bowne-anderson: at Honeycomb they actually outside the vendor Apis. They were the 1st to put an Llm. In production. Essentially, it was text to, not SQL. But text to honeycomb query, language. Sander Schulhoff, who published,\\n\\nwhich is now like\\nhugo bowne-anderson: it's called the prompt report. But essentially it's a report written by 40 people about prompt engineering people from Openai Sand, a bunch of others coming and talking about prompt engineering Charles from Modal, where we've got a thousand dollars of credits for each of you to talk about hardware and Ravan, Kumar, Ravin,\\n\\nKumar from\\nhugo bowne-anderson: the AI labs at Google, where he worked on notebook. Lm, and now, mariner, and he's going to come and give a talk which I'm working on with him currently about end-to-end products. So how to design user experiences from machine learning models. And his work at AI labs.\\n\\nhugo bowne-anderson: Google, AI is going to inform a lot of lot of that. So I just want to make sure that you don't only get kind of the base foundational stuff. But you see what people are doing on the cutting edge as well.\\n\\nThe other thing is\\nhugo bowne-anderson: these types of courses. Of course Stefan and I are here to teach and offer as much value as as we can and and beyond. But sometimes these courses have a magic of their own,\"}, {\"id\": \"f50abcb7-9a7e-457b-aff8-5536880e53c7\", \"position\": 60, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"01:50:39.550\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:50:39.550]\\nh\\nhugo bowne-anderson: a work outside a week, you'll get significantly more. If you do. 4\\u00a0h outside per week you'll probably get like way way more. So of course it's January. We've all got a bunch of stuff on, but definitely leverage myself, Stefan, and the community we're building as well.\\n\\nWhat I\\nhugo bowne-anderson: also want to say we didn't get round to this, and we'll do it next time you can deploy this app on Gradio. And I've actually got a video here of me doing.\\nStefan Krawczyk CEO DAGWorks Inc.: Tomorrow.\\n\\nhugo bowne-anderson: Yes, sorry on Modal. Exactly. And you need to have we need to have given you credentials, and so we'll get those, and so we'll get that sorted.\\n\\nhugo bowne-anderson: Everything we need in the modal form.\\n\\nhugo bowne-anderson: And I'll do that next time.\\n\\nAnd then\\nhugo bowne-anderson: the final thing I would very much appreciate. If you all took 3\\u00a0min now, I don't know why it has this big gap here. We'd love feedback on this session, so I'd like to know? How do you rate the pace? What did you like most? What could we improve anything unclear or confusing? If so, what this will help us create the best course going forward for all of you, and and both of us as well. To be honest. The other thing I'm not sure I mentioned. But this is the 1\\n\\nst time\\nhugo bowne-anderson:\\n\\nStefan and I are teaching this long version of\\nhugo bowne-anderson: of this material. We actually taught a 3\\u00a0h version of it recently in Austin, at the generative AI summit to 100 people, which was just so wonderful to do that in person, and Stefan and I have been teaching and working on these things for a long time, but this course, as it exists, it is the 1st cohort of it, so there may be rough edges. I'd be very surprised I'd be concerned if there weren'\"}, {\"id\": \"6b383d6c-81eb-4145-a43d-f0487642e00f\", \"position\": 4, \"relevance\": 1.0, \"tokens\": 451, \"timestamp\": \"00:09:56.800\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:09:56.800]\\nt\\nhugo bowne-anderson: been added yet. If you cannot access this, please message me your github handle on zoom, and this is the way we're going to do things. All course, all correspondence during sessions will be on zoom otherwise on discord. Okay.\\n\\nhugo bowne-anderson: so please do. Message me your github handle and we'\\n\\nll get started on that in\\nhugo bowne-anderson: I'll add all of those once we have a look at this 1st notebook.\\n\\nhugo bowne-anderson:\\n\\nSo\\nhugo bowne-anderson: I wanted to start just by saying once again welcome to the course. Stefan and I are deeply excited about building Llm applications, leveraging modern technology to build robust software and helping other people build Llm applications. I've been educating data scientists and machine learning engineers and Ml people.\\n\\nMachine learners quote unquote\\nhugo bowne-anderson: for over a decade now, and I haven't had a strong opening to be able to educate software engineers to to be honest about the data stuff. And I think with Llms, it's an incredible opportunity for a lot of people from the software side and product side in all honesty to come in and start learning a lot more about data, science and machine learning. And AI. So that's why we frame this as being very valuable for software engineers as well.\\n\\nhugo bowne-anderson: I do want to say what this course is about and what it isn't. I think we all have a sense of what it's about. But I just want to make clear to manage expectations. So we're going to be providing a practical 1st principles. Approach to building Llm. Powered apps. So focusing on all the 1st principles which I'll get to in a second, but workflows iteration and hands-on development. This is a space to talk about and to build production grade systems that scale beyond Pocs, proof of concepts and purgatories.\\n\\nhugo bowne-anderson: And it's also an opportunity not only to learn from practitioners such as myself and Stefan, but you may have seen,\"}, {\"id\": \"693c06f4-8f6a-40b5-8170-0dbef693d239\", \"position\": 61, \"relevance\": 1.0, \"tokens\": 229, \"timestamp\": \"01:52:42.720\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:52:42.720]\\nt\\nhugo bowne-anderson: but so all that is to say is, we welcome and encourage as much critical as feedback as possible. We want to make this course as wonderful as possible for you all. We want to make sure that we make it as wonderful as possible in future as well, so don'\\n\\nt hold back with\\nhugo bowne-anderson: with critiques and critical feedback also. So I will paste this.\\n\\nhugo bowne-anderson: Oh, wait! Yep! Oh, I've pasted it in the chat here. Please just take a couple of minutes to do that now, and we'll see you on discord, and we'\\n\\nll see you\\nhugo bowne-anderson: in 46\\u00a0h in the next session as well.\\n\\nhugo bowne-anderson: So thank you. Everyone.\\nStefan Krawczyk CEO DAGWorks Inc.: Thanks. Everyone.\\n\\nMika Castellani: Thank you.\\n\\nTravis Leleu: Thanks. Everyone.\\n\\nIgnacio Alonso: So.\\n\\nIlona Brinkmeier: Bye.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "good",
        "feedback_notes": "nonw",
        "feedback_user": "hgo",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, making it unhelpful and irrelevant."
    },
    {
        "id": "10eb6769-d4da-47a9-b6eb-dd02a389f549",
        "timestamp": "2025-04-11T22:58:49.342487",
        "question": "Who are the instructors here?",
        "response": "The instructors in this workshop are Hugo Bowne-Anderson and Stefan Krawczyk.",
        "num_chunks": 5,
        "context_tokens": 2220,
        "completion_tokens": 20,
        "embedding_tokens": 7680,
        "total_tokens": 9920,
        "latency": 1.1227474212646484,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"2be657af-2236-45eb-9f73-de597284cc70\", \"position\": 1, \"relevance\": 1.0, \"tokens\": 454, \"timestamp\": \"00:02:17.182\", \"speaker\": \"Unknown\", \"text\": \"[TIMESTAMP: 00:02:17.182]\\nhugo bowne-anderson: Looking at data and figuring out how you evaluate your systems. Incredibly important. So that's a brief introduction to me touching on what's in in the course as well, Stefan, maybe you can introduce yourself also.\\nStefan Krawczyk CEO DAGWorks Inc.: Yeah. Hi, Stefan Kafchuk.\\nStefan Krawczyk CEO DAGWorks Inc.: so super excited to to be here in terms of my background. I grew up in New Zealand, being out here in the bay since 2,007. So I live in San Francisco\\nStefan Krawczyk CEO DAGWorks Inc.: throughout my career. The only thing I haven't done is mobile development front end stuff, but effectively in the last kind of 10 years has been building on the data platform mlop side of things. And most recently, Gen. AI on the Lmops side of things.\\nStefan Krawczyk CEO DAGWorks Inc.: Specifically, I have been driving 2 open source projects, Hamilton and Burr. I'll put links in the chat if you're curious, but effectively have been trying to think about, how do you enable software engineers and have them transition to AI engineers? And then, conversely, how do you help\\nStefan Krawczyk CEO DAGWorks Inc.: the people on the data. Ml, side, take their skills and then apply them, build more software and product. Right? So very much interested in what is the new software development lifecycle shaping up to be since the agile sprint model doesn't really work when you're building something with Gen. AI as as it would as it did with traditional software, but otherwise, yeah, super excited for the amount of experience that's on here. I'm hopeful I can learn stuff from you guys as well\\nStefan Krawczyk CEO DAGWorks Inc.: but otherwise yeah, I will be, you know. Q will be driving most of this this course. I'll be kind of helping where I can with things, but otherwise\\nStefan Krawczyk CEO DAGWorks Inc.: Do you guys anything else to transition to? Otherwise?\"}, {\"id\": \"3b3b6a96-8665-4d88-b90f-07f2cdae898a\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:13:17.160\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:13:17.160]\\nand when we go through the syllabus\\nhugo bowne-anderson: we'll see this play out. But we're going to have guest lectures from people really on the cutting edge. So I suppose I talked about the cutting edge of tech companies. There are also a handful of people I know who are on the cutting edge,\\n\\nand\\nhugo bowne-anderson: in some ways further ahead the curve of adoption and technology than myself and Stefan not necessarily settled technology. So this isn't stuff I'd take out and tell everyone to adopt immediately. But people such as Sean Swicks working with agents. Hamel Hussein's work on Llms in production is exceptional.\\n\\nI think him and Philip\\nhugo bowne-anderson: at Honeycomb they actually outside the vendor Apis. They were the 1st to put an Llm. In production. Essentially, it was text to, not SQL. But text to honeycomb query, language. Sander Schulhoff, who published,\\n\\nwhich is now like\\nhugo bowne-anderson: it's called the prompt report. But essentially it's a report written by 40 people about prompt engineering people from Openai Sand, a bunch of others coming and talking about prompt engineering Charles from Modal, where we've got a thousand dollars of credits for each of you to talk about hardware and Ravan, Kumar, Ravin,\\n\\nKumar from\\nhugo bowne-anderson: the AI labs at Google, where he worked on notebook. Lm, and now, mariner, and he's going to come and give a talk which I'm working on with him currently about end-to-end products. So how to design user experiences from machine learning models. And his work at AI labs.\\n\\nhugo bowne-anderson: Google, AI is going to inform a lot of lot of that. So I just want to make sure that you don't only get kind of the base foundational stuff. But you see what people are doing on the cutting edge as well.\\n\\nThe other thing is\\nhugo bowne-anderson: these types of courses. Of course Stefan and I are here to teach and offer as much value as as we can and and beyond. But sometimes these courses have a magic of their own,\"}, {\"id\": \"7ba7c771-72f0-45c8-a781-d2c82b37f1c5\", \"position\": 60, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"01:50:39.550\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:50:39.550]\\nh\\nhugo bowne-anderson: a work outside a week, you'll get significantly more. If you do. 4\\u00a0h outside per week you'll probably get like way way more. So of course it's January. We've all got a bunch of stuff on, but definitely leverage myself, Stefan, and the community we're building as well.\\n\\nWhat I\\nhugo bowne-anderson: also want to say we didn't get round to this, and we'll do it next time you can deploy this app on Gradio. And I've actually got a video here of me doing.\\nStefan Krawczyk CEO DAGWorks Inc.: Tomorrow.\\n\\nhugo bowne-anderson: Yes, sorry on Modal. Exactly. And you need to have we need to have given you credentials, and so we'll get those, and so we'll get that sorted.\\n\\nhugo bowne-anderson: Everything we need in the modal form.\\n\\nhugo bowne-anderson: And I'll do that next time.\\n\\nAnd then\\nhugo bowne-anderson: the final thing I would very much appreciate. If you all took 3\\u00a0min now, I don't know why it has this big gap here. We'd love feedback on this session, so I'd like to know? How do you rate the pace? What did you like most? What could we improve anything unclear or confusing? If so, what this will help us create the best course going forward for all of you, and and both of us as well. To be honest. The other thing I'm not sure I mentioned. But this is the 1\\n\\nst time\\nhugo bowne-anderson:\\n\\nStefan and I are teaching this long version of\\nhugo bowne-anderson: of this material. We actually taught a 3\\u00a0h version of it recently in Austin, at the generative AI summit to 100 people, which was just so wonderful to do that in person, and Stefan and I have been teaching and working on these things for a long time, but this course, as it exists, it is the 1st cohort of it, so there may be rough edges. I'd be very surprised I'd be concerned if there weren'\"}, {\"id\": \"2b85709c-a814-437d-b24e-ba32e0b73b14\", \"position\": 4, \"relevance\": 1.0, \"tokens\": 451, \"timestamp\": \"00:09:56.800\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:09:56.800]\\nt\\nhugo bowne-anderson: been added yet. If you cannot access this, please message me your github handle on zoom, and this is the way we're going to do things. All course, all correspondence during sessions will be on zoom otherwise on discord. Okay.\\n\\nhugo bowne-anderson: so please do. Message me your github handle and we'\\n\\nll get started on that in\\nhugo bowne-anderson: I'll add all of those once we have a look at this 1st notebook.\\n\\nhugo bowne-anderson:\\n\\nSo\\nhugo bowne-anderson: I wanted to start just by saying once again welcome to the course. Stefan and I are deeply excited about building Llm applications, leveraging modern technology to build robust software and helping other people build Llm applications. I've been educating data scientists and machine learning engineers and Ml people.\\n\\nMachine learners quote unquote\\nhugo bowne-anderson: for over a decade now, and I haven't had a strong opening to be able to educate software engineers to to be honest about the data stuff. And I think with Llms, it's an incredible opportunity for a lot of people from the software side and product side in all honesty to come in and start learning a lot more about data, science and machine learning. And AI. So that's why we frame this as being very valuable for software engineers as well.\\n\\nhugo bowne-anderson: I do want to say what this course is about and what it isn't. I think we all have a sense of what it's about. But I just want to make clear to manage expectations. So we're going to be providing a practical 1st principles. Approach to building Llm. Powered apps. So focusing on all the 1st principles which I'll get to in a second, but workflows iteration and hands-on development. This is a space to talk about and to build production grade systems that scale beyond Pocs, proof of concepts and purgatories.\\n\\nhugo bowne-anderson: And it's also an opportunity not only to learn from practitioners such as myself and Stefan, but you may have seen,\"}, {\"id\": \"5903d92a-3cb2-44be-a069-ba97b7e9b5b8\", \"position\": 61, \"relevance\": 1.0, \"tokens\": 229, \"timestamp\": \"01:52:42.720\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:52:42.720]\\nt\\nhugo bowne-anderson: but so all that is to say is, we welcome and encourage as much critical as feedback as possible. We want to make this course as wonderful as possible for you all. We want to make sure that we make it as wonderful as possible in future as well, so don'\\n\\nt hold back with\\nhugo bowne-anderson: with critiques and critical feedback also. So I will paste this.\\n\\nhugo bowne-anderson: Oh, wait! Yep! Oh, I've pasted it in the chat here. Please just take a couple of minutes to do that now, and we'll see you on discord, and we'\\n\\nll see you\\nhugo bowne-anderson: in 46\\u00a0h in the next session as well.\\n\\nhugo bowne-anderson: So thank you. Everyone.\\nStefan Krawczyk CEO DAGWorks Inc.: Thanks. Everyone.\\n\\nMika Castellani: Thank you.\\n\\nTravis Leleu: Thanks. Everyone.\\n\\nIgnacio Alonso: So.\\n\\nIlona Brinkmeier: Bye.\"}]",
        "success": 1,
        "feedback_rating": null,
        "feedback_reason": null,
        "feedback_notes": null,
        "feedback_user": null,
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, as it does not specify what the question was or what the response was."
    },
    {
        "id": "3b258c46-5f67-4cf7-9ea5-7c130258f599",
        "timestamp": "2025-04-11T22:55:43.228804",
        "question": "What can you tell me about the Builders in Residence program?",
        "response": "Based on the provided sections of the workshop transcript, there is no information about the Builders in Residence program.",
        "num_chunks": 5,
        "context_tokens": 2547,
        "completion_tokens": 22,
        "embedding_tokens": 7680,
        "total_tokens": 10249,
        "latency": 1.1461453437805176,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"ab026274-628c-41d2-875f-5ccbf1abed1e\", \"position\": 18, \"relevance\": 1.0, \"tokens\": 488, \"timestamp\": \"00:43:32.890\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:43:32.890]\\nhugo bowne-anderson: Also. Additionally, this kind of mirrors, real world development environments where teams work across multiple platforms. And I'm sure we've all been. I don't know how many of you have like worked in. I've worked in several startups that go like from 4 people to 150, and seeing the amount of tools introduced in that type of growth is mind boggling. I actually think that may be why startups fail because they don't adopt tools mindfully, but that's for another day.\\n\\nhugo bowne-anderson: I'll say a bit about the high level structure, and then I'll get you to complete a survey, and then we'll jump into executing some code together. So this is week one. Clearly, it's foundations of Llm software development. So we'\\n\\nre going to introduce you to Genai and Llm development\\nhugo bowne-anderson: give an overview of the software development lifecycle. Use some key tools and frameworks for Llm.\\n\\nBased applications and set up the foundational app which is querying Pdfs and generating responses\\nhugo bowne-anderson: today will be introductory and building this app. Then, on Wednesday or Thursday, depending what time zone you're in, I'm in Australia. So it's actually Tuesday morning here, soon to be Tuesday afternoon. But I was in America recently, which is why I'm saying Tuesday and not Tuesday.\\n\\nhugo bowne-anderson: We have several guest lectures, as you're aware.\\n\\nhugo bowne-anderson: the final part of our second session this week will be Charles Fry, from modal talking about hardware for Llm. Developers. And I recently did a podcast with him. And he's he'\\n\\ns just\\nhugo bowne-anderson: super wonderful and bright on this. Next week we'll be doing iteration, evaluation and observability. And the 1st lesson will be evaluation and feedback loops the second one on observability and debugging next week next. So we'll be doing a lot of prompt engineering in the second session this week in the 1st session next week, Sander Schulhoff, from learnprompting.org,\\n\\nand the prompt report will give a guest lecture on prompt engineering in the Llm software development lifecycle\\nhugo bowne-anderson: Week 3, we'\"}, {\"id\": \"e712fdca-89a7-4b2d-98c1-c23b7abcb01d\", \"position\": 1, \"relevance\": 1.0, \"tokens\": 454, \"timestamp\": \"00:02:17.182\", \"speaker\": \"Unknown\", \"text\": \"[TIMESTAMP: 00:02:17.182]\\nhugo bowne-anderson: Looking at data and figuring out how you evaluate your systems. Incredibly important. So that's a brief introduction to me touching on what's in in the course as well, Stefan, maybe you can introduce yourself also.\\nStefan Krawczyk CEO DAGWorks Inc.: Yeah. Hi, Stefan Kafchuk.\\nStefan Krawczyk CEO DAGWorks Inc.: so super excited to to be here in terms of my background. I grew up in New Zealand, being out here in the bay since 2,007. So I live in San Francisco\\nStefan Krawczyk CEO DAGWorks Inc.: throughout my career. The only thing I haven't done is mobile development front end stuff, but effectively in the last kind of 10 years has been building on the data platform mlop side of things. And most recently, Gen. AI on the Lmops side of things.\\nStefan Krawczyk CEO DAGWorks Inc.: Specifically, I have been driving 2 open source projects, Hamilton and Burr. I'll put links in the chat if you're curious, but effectively have been trying to think about, how do you enable software engineers and have them transition to AI engineers? And then, conversely, how do you help\\nStefan Krawczyk CEO DAGWorks Inc.: the people on the data. Ml, side, take their skills and then apply them, build more software and product. Right? So very much interested in what is the new software development lifecycle shaping up to be since the agile sprint model doesn't really work when you're building something with Gen. AI as as it would as it did with traditional software, but otherwise, yeah, super excited for the amount of experience that's on here. I'm hopeful I can learn stuff from you guys as well\\nStefan Krawczyk CEO DAGWorks Inc.: but otherwise yeah, I will be, you know. Q will be driving most of this this course. I'll be kind of helping where I can with things, but otherwise\\nStefan Krawczyk CEO DAGWorks Inc.: Do you guys anything else to transition to? Otherwise?\"}, {\"id\": \"d845dba6-8bce-4a0d-92c0-e27a6a007330\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:13:17.160\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:13:17.160]\\nand when we go through the syllabus\\nhugo bowne-anderson: we'll see this play out. But we're going to have guest lectures from people really on the cutting edge. So I suppose I talked about the cutting edge of tech companies. There are also a handful of people I know who are on the cutting edge,\\n\\nand\\nhugo bowne-anderson: in some ways further ahead the curve of adoption and technology than myself and Stefan not necessarily settled technology. So this isn't stuff I'd take out and tell everyone to adopt immediately. But people such as Sean Swicks working with agents. Hamel Hussein's work on Llms in production is exceptional.\\n\\nI think him and Philip\\nhugo bowne-anderson: at Honeycomb they actually outside the vendor Apis. They were the 1st to put an Llm. In production. Essentially, it was text to, not SQL. But text to honeycomb query, language. Sander Schulhoff, who published,\\n\\nwhich is now like\\nhugo bowne-anderson: it's called the prompt report. But essentially it's a report written by 40 people about prompt engineering people from Openai Sand, a bunch of others coming and talking about prompt engineering Charles from Modal, where we've got a thousand dollars of credits for each of you to talk about hardware and Ravan, Kumar, Ravin,\\n\\nKumar from\\nhugo bowne-anderson: the AI labs at Google, where he worked on notebook. Lm, and now, mariner, and he's going to come and give a talk which I'm working on with him currently about end-to-end products. So how to design user experiences from machine learning models. And his work at AI labs.\\n\\nhugo bowne-anderson: Google, AI is going to inform a lot of lot of that. So I just want to make sure that you don't only get kind of the base foundational stuff. But you see what people are doing on the cutting edge as well.\\n\\nThe other thing is\\nhugo bowne-anderson: these types of courses. Of course Stefan and I are here to teach and offer as much value as as we can and and beyond. But sometimes these courses have a magic of their own,\"}, {\"id\": \"53cad1d3-227e-47a3-87d8-08dbe3b785db\", \"position\": 15, \"relevance\": 1.0, \"tokens\": 497, \"timestamp\": \"00:37:42.800\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:37:42.800]\\nThis is why\\nhugo bowne-anderson: Openai delegates a lot of their Rlhf stuff reinforcement learning via human feedback. If you don't know what that is, I'm happy to talk about it to developing nations like Kenya. And in fact, it's a huge problem to be clear. So I actually, I don't want to get too sociological on anyone now. But there'\\n\\ns an incredible book\\nhugo bowne-anderson: that I encourage everyone to check out called, ghost work? Almost. You know this is not the necessarily the fault, the place to be talking about this too much,\\n\\nbut it is about\\nhugo bowne-anderson: how a lot of tech companies are outsourcing in ways that aren't sustainable for global workforces and ties it very much to the gig economy as well. So, but I do think in the end we want to make sure that we're leveraging domain expertise as much as possible, and there are very clever ways to do that, but in the end I'\\n\\nm a firm believer that\\nhugo bowne-anderson:\\n\\nnearly everything\\nhugo bowne-anderson: a huge part of the value of any organization at any point in time doesn't exist in Wikis or in Apis. It exists in human minds and individuals and network connections. Right?\\n\\nSo any organization wants to be able to leverage\\nhugo bowne-anderson: what any individual can can provide.\\n\\nhugo bowne-anderson: So I just want to say one more thing. Then I'm going to get you to fill out a quick survey. And of course, today's a bit slow, because we're getting onboarded and and running up, and that type of stuff. But the truth is, I'\\n\\nm\\nhugo bowne-anderson: I'm not always the most organized person, but when I am organized things go way better. So what we've done is kind of set up a system where we're trying to make sure everyone's on the same page with all the logistics and all of that. So before starting to go into technical material, I just wanted to let you know the tools we're using throughout the course. So we're using zoom, right, we're on a zoom call right now. We're using it for live sessions and workshops. And any live discussions. Okay, the lessons happen here.\"}, {\"id\": \"8242bbe6-89f2-428b-b193-b6bdc87ac42a\", \"position\": 31, \"relevance\": 1.0, \"tokens\": 486, \"timestamp\": \"01:03:25.470\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:03:25.470]\\nhugo bowne-anderson: 10% aren't familiar. 57% understand the basics. I really, I wanted to ask that question before showing the slides. I wonder whether this slice of the pie is people like, Oh, yeah, I understand it now, because you just said something about it. But 30% regularly applying an Sdlc at work.\\n\\nhugo bowne-anderson: we can go through the rest of these. But it's the same story. We've got the same kind of amount of variance across all these dimensions, which is a significant variance, but it's the same across all the dimensions. So I think that that makes for a really really nice course from my experience. So we want people want to learn how to implement Llm apps, basic assistant type agents that can help a user achieve a set of predefined tasks, logging tracing inputs, outputs,\\n\\nsetting up evals for Llm apps great\\nhugo bowne-anderson: evals, evaluation, building, monitoring and evals, agents, observability.\\n\\nhugo bowne-anderson: end-to-end development test driven Gen. AI development. So we'll be doing all these things. The one other thing I'll add to Tdd test. Driven development is Edd evaluation, driven development which we're going to be doing a bunch of as well. But what I'm seeing here is we want to know about logging and evaluation and looking at your data and observability and productionizing, which is all the things we're we're here for,\\n\\nwhich is\\nhugo bowne-anderson: super exciting.\\n\\nSo\\nhugo bowne-anderson: we've been here for an hour, and I'm really itching to start to execute some code and playing with some apps. I've got way. Too many tabs open now. So I'\\n\\nm going to\\nhugo bowne-anderson: close them judiciously now, actually, Stefan, because I've already started a code. Space.\\n\\nWould you mind\\nhugo bowne-anderson: sharing your screen, and we can walk 3 people through how to spin up a codespace.\\n\\nhugo bowne-anderson: and then I'll go back to screen sharing, and I'll.\\nStefan Krawczyk CEO DAGWorks Inc.: And.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "correct",
        "feedback_notes": null,
        "feedback_user": "hugoi",
        "llm_judge_verdict": "FAIL",
        "llm_judge_reason": "The response does not provide any information related to the question asked, making it unhelpful and irrelevant."
    },
    {
        "id": "ba525c22-c2b4-4e57-8246-4639eb6b754c",
        "timestamp": "2025-04-11T22:55:24.904578",
        "question": "Who are the instructors?",
        "response": "The instructors are Hugo Bowne-Anderson and Stefan Krawczyk.",
        "num_chunks": 5,
        "context_tokens": 2470,
        "completion_tokens": 17,
        "embedding_tokens": 7680,
        "total_tokens": 10167,
        "latency": 0.845344066619873,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"d845dba6-8bce-4a0d-92c0-e27a6a007330\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:13:17.160\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:13:17.160]\\nand when we go through the syllabus\\nhugo bowne-anderson: we'll see this play out. But we're going to have guest lectures from people really on the cutting edge. So I suppose I talked about the cutting edge of tech companies. There are also a handful of people I know who are on the cutting edge,\\n\\nand\\nhugo bowne-anderson: in some ways further ahead the curve of adoption and technology than myself and Stefan not necessarily settled technology. So this isn't stuff I'd take out and tell everyone to adopt immediately. But people such as Sean Swicks working with agents. Hamel Hussein's work on Llms in production is exceptional.\\n\\nI think him and Philip\\nhugo bowne-anderson: at Honeycomb they actually outside the vendor Apis. They were the 1st to put an Llm. In production. Essentially, it was text to, not SQL. But text to honeycomb query, language. Sander Schulhoff, who published,\\n\\nwhich is now like\\nhugo bowne-anderson: it's called the prompt report. But essentially it's a report written by 40 people about prompt engineering people from Openai Sand, a bunch of others coming and talking about prompt engineering Charles from Modal, where we've got a thousand dollars of credits for each of you to talk about hardware and Ravan, Kumar, Ravin,\\n\\nKumar from\\nhugo bowne-anderson: the AI labs at Google, where he worked on notebook. Lm, and now, mariner, and he's going to come and give a talk which I'm working on with him currently about end-to-end products. So how to design user experiences from machine learning models. And his work at AI labs.\\n\\nhugo bowne-anderson: Google, AI is going to inform a lot of lot of that. So I just want to make sure that you don't only get kind of the base foundational stuff. But you see what people are doing on the cutting edge as well.\\n\\nThe other thing is\\nhugo bowne-anderson: these types of courses. Of course Stefan and I are here to teach and offer as much value as as we can and and beyond. But sometimes these courses have a magic of their own,\"}, {\"id\": \"e712fdca-89a7-4b2d-98c1-c23b7abcb01d\", \"position\": 1, \"relevance\": 1.0, \"tokens\": 454, \"timestamp\": \"00:02:17.182\", \"speaker\": \"Unknown\", \"text\": \"[TIMESTAMP: 00:02:17.182]\\nhugo bowne-anderson: Looking at data and figuring out how you evaluate your systems. Incredibly important. So that's a brief introduction to me touching on what's in in the course as well, Stefan, maybe you can introduce yourself also.\\nStefan Krawczyk CEO DAGWorks Inc.: Yeah. Hi, Stefan Kafchuk.\\nStefan Krawczyk CEO DAGWorks Inc.: so super excited to to be here in terms of my background. I grew up in New Zealand, being out here in the bay since 2,007. So I live in San Francisco\\nStefan Krawczyk CEO DAGWorks Inc.: throughout my career. The only thing I haven't done is mobile development front end stuff, but effectively in the last kind of 10 years has been building on the data platform mlop side of things. And most recently, Gen. AI on the Lmops side of things.\\nStefan Krawczyk CEO DAGWorks Inc.: Specifically, I have been driving 2 open source projects, Hamilton and Burr. I'll put links in the chat if you're curious, but effectively have been trying to think about, how do you enable software engineers and have them transition to AI engineers? And then, conversely, how do you help\\nStefan Krawczyk CEO DAGWorks Inc.: the people on the data. Ml, side, take their skills and then apply them, build more software and product. Right? So very much interested in what is the new software development lifecycle shaping up to be since the agile sprint model doesn't really work when you're building something with Gen. AI as as it would as it did with traditional software, but otherwise, yeah, super excited for the amount of experience that's on here. I'm hopeful I can learn stuff from you guys as well\\nStefan Krawczyk CEO DAGWorks Inc.: but otherwise yeah, I will be, you know. Q will be driving most of this this course. I'll be kind of helping where I can with things, but otherwise\\nStefan Krawczyk CEO DAGWorks Inc.: Do you guys anything else to transition to? Otherwise?\"}, {\"id\": \"34750af0-f6b8-4b37-8678-552de7049bbb\", \"position\": 60, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"01:50:39.550\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:50:39.550]\\nh\\nhugo bowne-anderson: a work outside a week, you'll get significantly more. If you do. 4\\u00a0h outside per week you'll probably get like way way more. So of course it's January. We've all got a bunch of stuff on, but definitely leverage myself, Stefan, and the community we're building as well.\\n\\nWhat I\\nhugo bowne-anderson: also want to say we didn't get round to this, and we'll do it next time you can deploy this app on Gradio. And I've actually got a video here of me doing.\\nStefan Krawczyk CEO DAGWorks Inc.: Tomorrow.\\n\\nhugo bowne-anderson: Yes, sorry on Modal. Exactly. And you need to have we need to have given you credentials, and so we'll get those, and so we'll get that sorted.\\n\\nhugo bowne-anderson: Everything we need in the modal form.\\n\\nhugo bowne-anderson: And I'll do that next time.\\n\\nAnd then\\nhugo bowne-anderson: the final thing I would very much appreciate. If you all took 3\\u00a0min now, I don't know why it has this big gap here. We'd love feedback on this session, so I'd like to know? How do you rate the pace? What did you like most? What could we improve anything unclear or confusing? If so, what this will help us create the best course going forward for all of you, and and both of us as well. To be honest. The other thing I'm not sure I mentioned. But this is the 1\\n\\nst time\\nhugo bowne-anderson:\\n\\nStefan and I are teaching this long version of\\nhugo bowne-anderson: of this material. We actually taught a 3\\u00a0h version of it recently in Austin, at the generative AI summit to 100 people, which was just so wonderful to do that in person, and Stefan and I have been teaching and working on these things for a long time, but this course, as it exists, it is the 1st cohort of it, so there may be rough edges. I'd be very surprised I'd be concerned if there weren'\"}, {\"id\": \"8669bb0b-9583-4617-940e-865c335a1600\", \"position\": 4, \"relevance\": 1.0, \"tokens\": 451, \"timestamp\": \"00:09:56.800\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:09:56.800]\\nt\\nhugo bowne-anderson: been added yet. If you cannot access this, please message me your github handle on zoom, and this is the way we're going to do things. All course, all correspondence during sessions will be on zoom otherwise on discord. Okay.\\n\\nhugo bowne-anderson: so please do. Message me your github handle and we'\\n\\nll get started on that in\\nhugo bowne-anderson: I'll add all of those once we have a look at this 1st notebook.\\n\\nhugo bowne-anderson:\\n\\nSo\\nhugo bowne-anderson: I wanted to start just by saying once again welcome to the course. Stefan and I are deeply excited about building Llm applications, leveraging modern technology to build robust software and helping other people build Llm applications. I've been educating data scientists and machine learning engineers and Ml people.\\n\\nMachine learners quote unquote\\nhugo bowne-anderson: for over a decade now, and I haven't had a strong opening to be able to educate software engineers to to be honest about the data stuff. And I think with Llms, it's an incredible opportunity for a lot of people from the software side and product side in all honesty to come in and start learning a lot more about data, science and machine learning. And AI. So that's why we frame this as being very valuable for software engineers as well.\\n\\nhugo bowne-anderson: I do want to say what this course is about and what it isn't. I think we all have a sense of what it's about. But I just want to make clear to manage expectations. So we're going to be providing a practical 1st principles. Approach to building Llm. Powered apps. So focusing on all the 1st principles which I'll get to in a second, but workflows iteration and hands-on development. This is a space to talk about and to build production grade systems that scale beyond Pocs, proof of concepts and purgatories.\\n\\nhugo bowne-anderson: And it's also an opportunity not only to learn from practitioners such as myself and Stefan, but you may have seen,\"}, {\"id\": \"ed0366ed-45eb-4dcc-8d89-6f183c1e46b2\", \"position\": 20, \"relevance\": 1.0, \"tokens\": 480, \"timestamp\": \"00:47:10.640\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:47:10.640]\\nhugo bowne-anderson: then in week 4, we're gonna jump into from customization to deployment. So there are a lot of different paths. We can go down. And this is what we'll figure out with you what you want to learn the most from advanced prompt optimization to fine tuning, to preparing data sets synthetically generating data, sets multi agent workflows talking through future trends. So over the next couple of weeks we'll get a sense of what you what would help you the most to learn out of these things.\\n\\nhugo bowne-anderson: and we'll be building more and more guest lectures that week will be Hamel Hussein, who's a good friend of ours, and he's going to give a talk on basic data literacy for debugging and evaluating Llms. He's been running office hours for the past year where people come with Llm. Application problems. And they'll say I've got these like multi agent multi-turn conversations and these complex rag pipelines.\\n\\nAnd\\nhugo bowne-anderson: I need to evaluate them. And he'll say, just look at your data. And he actually says people still don't understand what he means by that.\\n\\nhugo bowne-anderson: And people may not have the data literacy skills to. As I was saying before, jump into, look at the traces internally within an agentic pipeline, and you'll see the failure modes emerge. And we'll see examples of this today. And actually, so I'm really excited for this session. It will be outside class time. It'll be on. Oh, this is hilarious. It'\\n\\ns actually going to be on\\nhugo bowne-anderson: Tuesday, Tuesday. At this time I wrote Wednesday because it is Wednesday for me again.\\n\\nBut a recording will be\\nhugo bowne-anderson: available, and we may even release it as a podcast so you'll have access to that session whether you can make it or not. And Sean swicks from the latent space podcast and small AI, AI engineer will be talking about engineering, AI agents in 2025.\\n\\nhugo bowne-anderson: Eric has a great question. I heard that AI. Agents is the future. Is this a reasonable statement? I will answer that. And this is something we'll go through.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "perf",
        "feedback_notes": "slow",
        "feedback_user": "hugo",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "1dae0362-b563-4f14-92c7-a53ba06a4a31",
        "timestamp": "2025-04-11T22:47:45.456991",
        "question": "What is the main topic of this workshop?",
        "response": "The main topic of this workshop is Llm software development, specifically focusing on workflows, evaluation, and building software with generative AI Apps and Llms.",
        "num_chunks": 5,
        "context_tokens": 2527,
        "completion_tokens": 33,
        "embedding_tokens": 7680,
        "total_tokens": 10240,
        "latency": 1.051680088043213,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"bf8d4bf1-7d96-4ee4-bfd1-d07cba52fb8c\", \"position\": 6, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:15:16.300\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:15:16.300]\\nand people\\nhugo bowne-anderson: communicate and learn from each other, and I've already seen hints of this on discord before our 1st session. I've seen people chatting who are both in DC. And may meet up. I've corresponded with a couple of people in Sydney about meeting up. I've been seeing people ask each other about each other's work. Just go to the introductions Channel. If you haven't, and see what everyone's working on, and the variance of what everyone's working on. And it's incredibly exciting to me.\\n\\nhugo bowne-anderson: So I think that's something we can get out of this course as well.\\n\\nSo\\nhugo bowne-anderson: what this course isn't. It is not a deep dive into every Llm. Tool or trend. Of course we'll be talking about rag and agents and embeddings. But the focus is on workflows, not an exhaustive tool coverage. And actually, on top of that, in today's session, we use Lama Index gradio sqlite, a tool by Salem and Willison, called dataset. We may even get to modal for deployment. We'll use one or 2 vendor Apis. So this isn't to say we won't be using tools all the time.\\n\\nBut the focus will not\\nhugo bowne-anderson: not be on tool thinking. And I actually, this is maybe a provocation, and I'\\n\\nd be happy to discuss this\\nhugo bowne-anderson: with all of you. But almost an assumption we're going in with is that tools should not be the focus and tools themselves will come and go. Ways of working with tools will come and go. We're in the early days. This is the infancy of the Llm. Powered app space right?\\n\\nSo\\nhugo bowne-anderson: even processes. Well, no, I'm certain some big processes will change right. But what our bet is, what won't change is a bunch of 1st principles and 1st principle, thinking for how to build software with generative AI Apps and Llms. So we'll go through those 1st principles. But that really is what this, what this course is about.\"}, {\"id\": \"cca9587f-b9cb-469c-bb1a-f2a059bde8f9\", \"position\": 18, \"relevance\": 1.0, \"tokens\": 488, \"timestamp\": \"00:43:32.890\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:43:32.890]\\nhugo bowne-anderson: Also. Additionally, this kind of mirrors, real world development environments where teams work across multiple platforms. And I'm sure we've all been. I don't know how many of you have like worked in. I've worked in several startups that go like from 4 people to 150, and seeing the amount of tools introduced in that type of growth is mind boggling. I actually think that may be why startups fail because they don't adopt tools mindfully, but that's for another day.\\n\\nhugo bowne-anderson: I'll say a bit about the high level structure, and then I'll get you to complete a survey, and then we'll jump into executing some code together. So this is week one. Clearly, it's foundations of Llm software development. So we'\\n\\nre going to introduce you to Genai and Llm development\\nhugo bowne-anderson: give an overview of the software development lifecycle. Use some key tools and frameworks for Llm.\\n\\nBased applications and set up the foundational app which is querying Pdfs and generating responses\\nhugo bowne-anderson: today will be introductory and building this app. Then, on Wednesday or Thursday, depending what time zone you're in, I'm in Australia. So it's actually Tuesday morning here, soon to be Tuesday afternoon. But I was in America recently, which is why I'm saying Tuesday and not Tuesday.\\n\\nhugo bowne-anderson: We have several guest lectures, as you're aware.\\n\\nhugo bowne-anderson: the final part of our second session this week will be Charles Fry, from modal talking about hardware for Llm. Developers. And I recently did a podcast with him. And he's he'\\n\\ns just\\nhugo bowne-anderson: super wonderful and bright on this. Next week we'll be doing iteration, evaluation and observability. And the 1st lesson will be evaluation and feedback loops the second one on observability and debugging next week next. So we'll be doing a lot of prompt engineering in the second session this week in the 1st session next week, Sander Schulhoff, from learnprompting.org,\\n\\nand the prompt report will give a guest lecture on prompt engineering in the Llm software development lifecycle\\nhugo bowne-anderson: Week 3, we'\"}, {\"id\": \"acf7aa3d-b389-4fa7-b74d-58f154cb7517\", \"position\": 1, \"relevance\": 1.0, \"tokens\": 454, \"timestamp\": \"00:02:17.182\", \"speaker\": \"Unknown\", \"text\": \"[TIMESTAMP: 00:02:17.182]\\nhugo bowne-anderson: Looking at data and figuring out how you evaluate your systems. Incredibly important. So that's a brief introduction to me touching on what's in in the course as well, Stefan, maybe you can introduce yourself also.\\nStefan Krawczyk CEO DAGWorks Inc.: Yeah. Hi, Stefan Kafchuk.\\nStefan Krawczyk CEO DAGWorks Inc.: so super excited to to be here in terms of my background. I grew up in New Zealand, being out here in the bay since 2,007. So I live in San Francisco\\nStefan Krawczyk CEO DAGWorks Inc.: throughout my career. The only thing I haven't done is mobile development front end stuff, but effectively in the last kind of 10 years has been building on the data platform mlop side of things. And most recently, Gen. AI on the Lmops side of things.\\nStefan Krawczyk CEO DAGWorks Inc.: Specifically, I have been driving 2 open source projects, Hamilton and Burr. I'll put links in the chat if you're curious, but effectively have been trying to think about, how do you enable software engineers and have them transition to AI engineers? And then, conversely, how do you help\\nStefan Krawczyk CEO DAGWorks Inc.: the people on the data. Ml, side, take their skills and then apply them, build more software and product. Right? So very much interested in what is the new software development lifecycle shaping up to be since the agile sprint model doesn't really work when you're building something with Gen. AI as as it would as it did with traditional software, but otherwise, yeah, super excited for the amount of experience that's on here. I'm hopeful I can learn stuff from you guys as well\\nStefan Krawczyk CEO DAGWorks Inc.: but otherwise yeah, I will be, you know. Q will be driving most of this this course. I'll be kind of helping where I can with things, but otherwise\\nStefan Krawczyk CEO DAGWorks Inc.: Do you guys anything else to transition to? Otherwise?\"}, {\"id\": \"2401463e-e6b0-4e1c-b45a-f104028d4552\", \"position\": 31, \"relevance\": 1.0, \"tokens\": 486, \"timestamp\": \"01:03:25.470\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:03:25.470]\\nhugo bowne-anderson: 10% aren't familiar. 57% understand the basics. I really, I wanted to ask that question before showing the slides. I wonder whether this slice of the pie is people like, Oh, yeah, I understand it now, because you just said something about it. But 30% regularly applying an Sdlc at work.\\n\\nhugo bowne-anderson: we can go through the rest of these. But it's the same story. We've got the same kind of amount of variance across all these dimensions, which is a significant variance, but it's the same across all the dimensions. So I think that that makes for a really really nice course from my experience. So we want people want to learn how to implement Llm apps, basic assistant type agents that can help a user achieve a set of predefined tasks, logging tracing inputs, outputs,\\n\\nsetting up evals for Llm apps great\\nhugo bowne-anderson: evals, evaluation, building, monitoring and evals, agents, observability.\\n\\nhugo bowne-anderson: end-to-end development test driven Gen. AI development. So we'll be doing all these things. The one other thing I'll add to Tdd test. Driven development is Edd evaluation, driven development which we're going to be doing a bunch of as well. But what I'm seeing here is we want to know about logging and evaluation and looking at your data and observability and productionizing, which is all the things we're we're here for,\\n\\nwhich is\\nhugo bowne-anderson: super exciting.\\n\\nSo\\nhugo bowne-anderson: we've been here for an hour, and I'm really itching to start to execute some code and playing with some apps. I've got way. Too many tabs open now. So I'\\n\\nm going to\\nhugo bowne-anderson: close them judiciously now, actually, Stefan, because I've already started a code. Space.\\n\\nWould you mind\\nhugo bowne-anderson: sharing your screen, and we can walk 3 people through how to spin up a codespace.\\n\\nhugo bowne-anderson: and then I'll go back to screen sharing, and I'll.\\nStefan Krawczyk CEO DAGWorks Inc.: And.\"}, {\"id\": \"b07c26c0-d38e-467d-98cf-9dc764a5470f\", \"position\": 20, \"relevance\": 1.0, \"tokens\": 480, \"timestamp\": \"00:47:10.640\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:47:10.640]\\nhugo bowne-anderson: then in week 4, we're gonna jump into from customization to deployment. So there are a lot of different paths. We can go down. And this is what we'll figure out with you what you want to learn the most from advanced prompt optimization to fine tuning, to preparing data sets synthetically generating data, sets multi agent workflows talking through future trends. So over the next couple of weeks we'll get a sense of what you what would help you the most to learn out of these things.\\n\\nhugo bowne-anderson: and we'll be building more and more guest lectures that week will be Hamel Hussein, who's a good friend of ours, and he's going to give a talk on basic data literacy for debugging and evaluating Llms. He's been running office hours for the past year where people come with Llm. Application problems. And they'll say I've got these like multi agent multi-turn conversations and these complex rag pipelines.\\n\\nAnd\\nhugo bowne-anderson: I need to evaluate them. And he'll say, just look at your data. And he actually says people still don't understand what he means by that.\\n\\nhugo bowne-anderson: And people may not have the data literacy skills to. As I was saying before, jump into, look at the traces internally within an agentic pipeline, and you'll see the failure modes emerge. And we'll see examples of this today. And actually, so I'm really excited for this session. It will be outside class time. It'll be on. Oh, this is hilarious. It'\\n\\ns actually going to be on\\nhugo bowne-anderson: Tuesday, Tuesday. At this time I wrote Wednesday because it is Wednesday for me again.\\n\\nBut a recording will be\\nhugo bowne-anderson: available, and we may even release it as a podcast so you'll have access to that session whether you can make it or not. And Sean swicks from the latent space podcast and small AI, AI engineer will be talking about engineering, AI agents in 2025.\\n\\nhugo bowne-anderson: Eric has a great question. I heard that AI. Agents is the future. Is this a reasonable statement? I will answer that. And this is something we'll go through.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "accurate and precise",
        "feedback_notes": "slow",
        "feedback_user": "hugo",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    },
    {
        "id": "7cfde731-c42a-4dbe-814c-7a42aec6aa99",
        "timestamp": "2025-04-11T22:47:20.066084",
        "question": "Who are the instructors?",
        "response": "The instructors are Hugo Bowne-Anderson and Stefan Krawczyk.",
        "num_chunks": 5,
        "context_tokens": 2470,
        "completion_tokens": 17,
        "embedding_tokens": 7680,
        "total_tokens": 10167,
        "latency": 0.9657480716705322,
        "model": "gpt-3.5-turbo-16k",
        "sources": "[{\"id\": \"19ca078f-3d07-4ba7-aebd-736052f11f25\", \"position\": 5, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"00:13:17.160\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:13:17.160]\\nand when we go through the syllabus\\nhugo bowne-anderson: we'll see this play out. But we're going to have guest lectures from people really on the cutting edge. So I suppose I talked about the cutting edge of tech companies. There are also a handful of people I know who are on the cutting edge,\\n\\nand\\nhugo bowne-anderson: in some ways further ahead the curve of adoption and technology than myself and Stefan not necessarily settled technology. So this isn't stuff I'd take out and tell everyone to adopt immediately. But people such as Sean Swicks working with agents. Hamel Hussein's work on Llms in production is exceptional.\\n\\nI think him and Philip\\nhugo bowne-anderson: at Honeycomb they actually outside the vendor Apis. They were the 1st to put an Llm. In production. Essentially, it was text to, not SQL. But text to honeycomb query, language. Sander Schulhoff, who published,\\n\\nwhich is now like\\nhugo bowne-anderson: it's called the prompt report. But essentially it's a report written by 40 people about prompt engineering people from Openai Sand, a bunch of others coming and talking about prompt engineering Charles from Modal, where we've got a thousand dollars of credits for each of you to talk about hardware and Ravan, Kumar, Ravin,\\n\\nKumar from\\nhugo bowne-anderson: the AI labs at Google, where he worked on notebook. Lm, and now, mariner, and he's going to come and give a talk which I'm working on with him currently about end-to-end products. So how to design user experiences from machine learning models. And his work at AI labs.\\n\\nhugo bowne-anderson: Google, AI is going to inform a lot of lot of that. So I just want to make sure that you don't only get kind of the base foundational stuff. But you see what people are doing on the cutting edge as well.\\n\\nThe other thing is\\nhugo bowne-anderson: these types of courses. Of course Stefan and I are here to teach and offer as much value as as we can and and beyond. But sometimes these courses have a magic of their own,\"}, {\"id\": \"acf7aa3d-b389-4fa7-b74d-58f154cb7517\", \"position\": 1, \"relevance\": 1.0, \"tokens\": 454, \"timestamp\": \"00:02:17.182\", \"speaker\": \"Unknown\", \"text\": \"[TIMESTAMP: 00:02:17.182]\\nhugo bowne-anderson: Looking at data and figuring out how you evaluate your systems. Incredibly important. So that's a brief introduction to me touching on what's in in the course as well, Stefan, maybe you can introduce yourself also.\\nStefan Krawczyk CEO DAGWorks Inc.: Yeah. Hi, Stefan Kafchuk.\\nStefan Krawczyk CEO DAGWorks Inc.: so super excited to to be here in terms of my background. I grew up in New Zealand, being out here in the bay since 2,007. So I live in San Francisco\\nStefan Krawczyk CEO DAGWorks Inc.: throughout my career. The only thing I haven't done is mobile development front end stuff, but effectively in the last kind of 10 years has been building on the data platform mlop side of things. And most recently, Gen. AI on the Lmops side of things.\\nStefan Krawczyk CEO DAGWorks Inc.: Specifically, I have been driving 2 open source projects, Hamilton and Burr. I'll put links in the chat if you're curious, but effectively have been trying to think about, how do you enable software engineers and have them transition to AI engineers? And then, conversely, how do you help\\nStefan Krawczyk CEO DAGWorks Inc.: the people on the data. Ml, side, take their skills and then apply them, build more software and product. Right? So very much interested in what is the new software development lifecycle shaping up to be since the agile sprint model doesn't really work when you're building something with Gen. AI as as it would as it did with traditional software, but otherwise, yeah, super excited for the amount of experience that's on here. I'm hopeful I can learn stuff from you guys as well\\nStefan Krawczyk CEO DAGWorks Inc.: but otherwise yeah, I will be, you know. Q will be driving most of this this course. I'll be kind of helping where I can with things, but otherwise\\nStefan Krawczyk CEO DAGWorks Inc.: Do you guys anything else to transition to? Otherwise?\"}, {\"id\": \"cf833dce-f030-4df5-9950-7c7fbd453d20\", \"position\": 60, \"relevance\": 1.0, \"tokens\": 469, \"timestamp\": \"01:50:39.550\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 01:50:39.550]\\nh\\nhugo bowne-anderson: a work outside a week, you'll get significantly more. If you do. 4\\u00a0h outside per week you'll probably get like way way more. So of course it's January. We've all got a bunch of stuff on, but definitely leverage myself, Stefan, and the community we're building as well.\\n\\nWhat I\\nhugo bowne-anderson: also want to say we didn't get round to this, and we'll do it next time you can deploy this app on Gradio. And I've actually got a video here of me doing.\\nStefan Krawczyk CEO DAGWorks Inc.: Tomorrow.\\n\\nhugo bowne-anderson: Yes, sorry on Modal. Exactly. And you need to have we need to have given you credentials, and so we'll get those, and so we'll get that sorted.\\n\\nhugo bowne-anderson: Everything we need in the modal form.\\n\\nhugo bowne-anderson: And I'll do that next time.\\n\\nAnd then\\nhugo bowne-anderson: the final thing I would very much appreciate. If you all took 3\\u00a0min now, I don't know why it has this big gap here. We'd love feedback on this session, so I'd like to know? How do you rate the pace? What did you like most? What could we improve anything unclear or confusing? If so, what this will help us create the best course going forward for all of you, and and both of us as well. To be honest. The other thing I'm not sure I mentioned. But this is the 1\\n\\nst time\\nhugo bowne-anderson:\\n\\nStefan and I are teaching this long version of\\nhugo bowne-anderson: of this material. We actually taught a 3\\u00a0h version of it recently in Austin, at the generative AI summit to 100 people, which was just so wonderful to do that in person, and Stefan and I have been teaching and working on these things for a long time, but this course, as it exists, it is the 1st cohort of it, so there may be rough edges. I'd be very surprised I'd be concerned if there weren'\"}, {\"id\": \"ffeb9f21-dea8-4c4e-9bf1-61e5d09d0567\", \"position\": 4, \"relevance\": 1.0, \"tokens\": 451, \"timestamp\": \"00:09:56.800\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:09:56.800]\\nt\\nhugo bowne-anderson: been added yet. If you cannot access this, please message me your github handle on zoom, and this is the way we're going to do things. All course, all correspondence during sessions will be on zoom otherwise on discord. Okay.\\n\\nhugo bowne-anderson: so please do. Message me your github handle and we'\\n\\nll get started on that in\\nhugo bowne-anderson: I'll add all of those once we have a look at this 1st notebook.\\n\\nhugo bowne-anderson:\\n\\nSo\\nhugo bowne-anderson: I wanted to start just by saying once again welcome to the course. Stefan and I are deeply excited about building Llm applications, leveraging modern technology to build robust software and helping other people build Llm applications. I've been educating data scientists and machine learning engineers and Ml people.\\n\\nMachine learners quote unquote\\nhugo bowne-anderson: for over a decade now, and I haven't had a strong opening to be able to educate software engineers to to be honest about the data stuff. And I think with Llms, it's an incredible opportunity for a lot of people from the software side and product side in all honesty to come in and start learning a lot more about data, science and machine learning. And AI. So that's why we frame this as being very valuable for software engineers as well.\\n\\nhugo bowne-anderson: I do want to say what this course is about and what it isn't. I think we all have a sense of what it's about. But I just want to make clear to manage expectations. So we're going to be providing a practical 1st principles. Approach to building Llm. Powered apps. So focusing on all the 1st principles which I'll get to in a second, but workflows iteration and hands-on development. This is a space to talk about and to build production grade systems that scale beyond Pocs, proof of concepts and purgatories.\\n\\nhugo bowne-anderson: And it's also an opportunity not only to learn from practitioners such as myself and Stefan, but you may have seen,\"}, {\"id\": \"b07c26c0-d38e-467d-98cf-9dc764a5470f\", \"position\": 20, \"relevance\": 1.0, \"tokens\": 480, \"timestamp\": \"00:47:10.640\", \"speaker\": \"hugo bowne-anderson\", \"text\": \"[TIMESTAMP: 00:47:10.640]\\nhugo bowne-anderson: then in week 4, we're gonna jump into from customization to deployment. So there are a lot of different paths. We can go down. And this is what we'll figure out with you what you want to learn the most from advanced prompt optimization to fine tuning, to preparing data sets synthetically generating data, sets multi agent workflows talking through future trends. So over the next couple of weeks we'll get a sense of what you what would help you the most to learn out of these things.\\n\\nhugo bowne-anderson: and we'll be building more and more guest lectures that week will be Hamel Hussein, who's a good friend of ours, and he's going to give a talk on basic data literacy for debugging and evaluating Llms. He's been running office hours for the past year where people come with Llm. Application problems. And they'll say I've got these like multi agent multi-turn conversations and these complex rag pipelines.\\n\\nAnd\\nhugo bowne-anderson: I need to evaluate them. And he'll say, just look at your data. And he actually says people still don't understand what he means by that.\\n\\nhugo bowne-anderson: And people may not have the data literacy skills to. As I was saying before, jump into, look at the traces internally within an agentic pipeline, and you'll see the failure modes emerge. And we'll see examples of this today. And actually, so I'm really excited for this session. It will be outside class time. It'll be on. Oh, this is hilarious. It'\\n\\ns actually going to be on\\nhugo bowne-anderson: Tuesday, Tuesday. At this time I wrote Wednesday because it is Wednesday for me again.\\n\\nBut a recording will be\\nhugo bowne-anderson: available, and we may even release it as a podcast so you'll have access to that session whether you can make it or not. And Sean swicks from the latent space podcast and small AI, AI engineer will be talking about engineering, AI agents in 2025.\\n\\nhugo bowne-anderson: Eric has a great question. I heard that AI. Agents is the future. Is this a reasonable statement? I will answer that. And this is something we'll go through.\"}]",
        "success": 1,
        "feedback_rating": "PASS",
        "feedback_reason": "accurate and precise",
        "feedback_notes": "slow",
        "feedback_user": "hugo",
        "llm_judge_verdict": "PASS",
        "llm_judge_reason": "The response directly addresses the user's question by providing a clear and relevant summary of the key differences in evaluating LLM apps as mentioned in the workshop transcript."
    }
]